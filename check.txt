diff --git a/benchmark/.gitignore b/benchmark/.gitignore
new file mode 100644
index 0000000..2e655b8
--- /dev/null
+++ b/benchmark/.gitignore
@@ -0,0 +1,7 @@
+log
+**/__pycache__
+*.ipynb
+*.zip
+jdt-ls
+.env
+dev
\ No newline at end of file
diff --git a/benchmark/CrossCodeEval/.gitignore b/benchmark/CrossCodeEval/.gitignore
new file mode 100644
index 0000000..c96a04f
--- /dev/null
+++ b/benchmark/CrossCodeEval/.gitignore
@@ -0,0 +1,2 @@
+*
+!.gitignore
\ No newline at end of file
diff --git a/benchmark/Dockerfile b/benchmark/Dockerfile
new file mode 100644
index 0000000..a14dd92
--- /dev/null
+++ b/benchmark/Dockerfile
@@ -0,0 +1,3 @@
+FROM ubuntu:noble
+WORKDIR /workspace
+COPY benchmark_continue.zip /workspace/
\ No newline at end of file
diff --git a/benchmark/NOTE.md b/benchmark/NOTE.md
new file mode 100644
index 0000000..2d6dfbe
--- /dev/null
+++ b/benchmark/NOTE.md
@@ -0,0 +1,54 @@
+# Note
+
+- LSP can not get definition for import * in java, only for import package.AClass
+
+- Continue wrong implement constructAutocompletePrompt
+
+```js
+finalSnippets = fillPromptWithSnippets(
+    scoredSnippets,
+    helper.maxSnippetTokens,
+    helper.modelName,
+);
+```
+
+`scoredSnippets` should be `finalSnippets`
+
+- Continue wrong implement mergeSnippetsByRange
+
+```js
+const merged: Required<AutocompleteSnippet>[] = [];
+
+while (sorted.length > 0) {
+    const next = sorted.shift()!;
+    const last = merged[merged.length - 1];
+```
+
+merged is initial empty list, so last is undefined
+=> It still work in typescript
+
+- Continue formatExternalSnippet
+
+```js
+export function formatExternalSnippet(
+  filepath: string,
+  snippet: string,
+  language: AutocompleteLanguageInfo,
+) {
+  const comment = language.singleLineComment;
+  const lines = [
+    `${comment} Path: ${getBasename(filepath)}`,
+    ...snippet
+      .trim()
+      .split("\n")
+      .map((line) => `${comment} ${line}`),
+    comment,
+  ];
+  return lines.join("\n");
+}
+```
+
+Why need to getBaseName?
+
+- Need to install Language Server for Java extension in VSCode to use additional context
+
diff --git a/benchmark/README.md b/benchmark/README.md
new file mode 100644
index 0000000..b8301bd
--- /dev/null
+++ b/benchmark/README.md
@@ -0,0 +1,6 @@
+# Benchmark for continue autocomplete feature
+
+## Setup
+
+- Run `clone.py` to download repositories
+- Run `setup_repo_state.py` to set up projects to right commit as in benchmark
diff --git a/benchmark/TODO.md b/benchmark/TODO.md
new file mode 100644
index 0000000..5d2262c
--- /dev/null
+++ b/benchmark/TODO.md
@@ -0,0 +1,13 @@
+# Plan
+
+## Setup benchmark for CrossCodeEval/Java
+
+- 14/239 projects can not be found at 25/10/2024 => 225 projects
+- project CHRISL7--android_device_xiaomi_sm6225-common--ed8a1e0 commit not found => 224 projects
+
+## TODO
+
+- [x] Recheck class/function node tree sitter
+- [x] Import query
+- [x] get_definition_for_node
+- [x] get_snippet_for_node
diff --git a/benchmark/benchmark.py b/benchmark/benchmark.py
new file mode 100644
index 0000000..b8eb1a2
--- /dev/null
+++ b/benchmark/benchmark.py
@@ -0,0 +1,32 @@
+import argparse
+import pandas as pd
+from prompt import get_completion
+from eval import cal_edit_sim, cal_exactly_match
+
+def main(args):
+    df = pd.read_json(args.input, lines=True)
+    df["task_id"] = df["metadata"].apply(lambda x: x["task_id"])
+    prefixes = df["prefix"].tolist()
+    suffixes = df["suffix"].tolist()
+    prompts = df["build_prompt"].tolist()
+    preds = get_completion(prefixes, suffixes, prompts, args.model)
+    df["response"] = preds
+    df.to_json(args.output, orient="records", lines=True)
+    references = df["groundtruth"].tolist()
+    preds = df["response"].fillna("").tolist()
+    em = cal_exactly_match(references, preds)
+    edit_sim = cal_edit_sim(references, preds)
+    print("==========RESULT==========")
+    print("EM:", "{:.2f}".format(em))
+    print("ES:", "{:.2f}".format(edit_sim))
+    print("==========================")
+
+
+
+if __name__ == "__main__":
+    parser = argparse.ArgumentParser()
+    parser.add_argument("-i", "--input", type=str, dest="input")
+    parser.add_argument("-o", "--output", type=str, dest="output")
+    parser.add_argument("-m", "--model", type=str, dest="model", default="deepseek-coder")
+    args = parser.parse_args()
+    main(args)
diff --git a/benchmark/clone.py b/benchmark/clone.py
new file mode 100644
index 0000000..3ebeba9
--- /dev/null
+++ b/benchmark/clone.py
@@ -0,0 +1,43 @@
+#   Author: masterSunflowers
+#   Github: https://github.com/masterSunflowers/masterSunflowers
+#   Date:   01/11/2024
+#   Desc:   This file aim to clone github repositories in CrossCodeEval benchmark for Java
+import argparse
+import logging
+import os
+import subprocess
+
+import pandas as pd
+from tqdm import tqdm
+
+CWD = os.path.abspath(os.path.dirname(__file__))
+
+logger = logging.Logger("clone", level=logging.INFO)
+logger.addHandler(logging.FileHandler(os.path.join(CWD, "log", "clone.log")))
+
+
+def main(args):
+    save_dir = os.path.join(args.data_storage)
+    if os.path.exists(save_dir):
+        os.system(f"rm -rf {save_dir}")
+    os.makedirs(save_dir, exist_ok=True)
+    df = pd.read_json(args.input, lines=True)
+    df.drop_duplicates(subset=["encode"], ignore_index=True, inplace=True)
+    for _, row in tqdm(df.iterrows(), total=len(df), desc="Cloning"):
+        encode = row["encode"]
+        username, repo, commit = encode.split("--")
+        repo_url = f"https://github.com/{username}/{repo}.git"
+        cmd = f"cd {save_dir} && git clone {repo_url} && mv {repo} {encode}"
+        res = subprocess.run(cmd, shell=True, capture_output=True, text=True)
+        if res.returncode == 0:
+            logger.info(f"Clone {repo_url} successfully!")
+        else:
+            logger.error(f"Error when clone {repo_url}!")
+
+
+if __name__ == "__main__":
+    parser = argparse.ArgumentParser()
+    parser.add_argument("-i", dest="input")
+    parser.add_argument("-s", dest="data_storage")
+    args = parser.parse_args()
+    main(args)
diff --git a/continue-0.8.66-vscode/core/autocomplete/context/root-path-context/test/files/__init__.py b/benchmark/continue_dev/__init__.py
similarity index 100%
rename from continue-0.8.66-vscode/core/autocomplete/context/root-path-context/test/files/__init__.py
rename to benchmark/continue_dev/__init__.py
diff --git a/benchmark/continue_dev/common_funcs.py b/benchmark/continue_dev/common_funcs.py
new file mode 100644
index 0000000..9e0148e
--- /dev/null
+++ b/benchmark/continue_dev/common_funcs.py
@@ -0,0 +1,213 @@
+import re
+from typing import Optional, List
+
+import tree_sitter
+import tree_sitter_java as tsjava
+import tree_sitter_python as tspython
+from transformers import LlamaTokenizerFast
+from tree_sitter import Node, Point, Tree
+from pydantic import BaseModel
+
+JAVA = tree_sitter.Language(tsjava.language())
+PYTHON = tree_sitter.Language(tspython.language())
+LANG_EXTENSIONS = {"java": ".java", "python": ".py"}
+FUNCTION_DECLARATION_NODE_TYPES = [
+    "method_definition",
+    "function_definition",
+    "function_item",
+    "function_declaration",
+    "method_declaration",
+]
+TREE_SITTER_NODE_TYPES = {
+    "method": FUNCTION_DECLARATION_NODE_TYPES,
+    "type": [
+        "class_declaration",
+        "class_definition",
+        "interface_declaration",
+        "enum_declaration",
+        "record_declaration",
+    ],
+}
+LANGUAGE_COMMENT_SYMBOL = {
+    "java": "//",
+    "python": "#",
+    "javascript": "//",
+    "typescript": "//",
+    "csharp": "//",
+}
+COMMON_STOPS = ["/src", "#- coding: utf-8", "```"]
+FUNCTION_BLOCK_NODE_TYPES = ["block", "statement_block"]
+JAVA_PARSER = tree_sitter.Parser(language=JAVA)
+PYTHON_PARSER = tree_sitter.Parser(language=PYTHON)
+TOP_LEVEL_KEY_WORDS = {"java": ["class", "function"], "python": ["def", "class"]}
+TOKENIZER = LlamaTokenizerFast.from_pretrained("hf-internal-testing/llama-tokenizer")
+TYPES_TO_USE = {"program", "function_declaration", "method_definition"}
+QUERIES = {
+    "java": {
+        "import_query": "(import_declaration\n  (scoped_identifier\n    (identifier) @import))",
+        "method_declaration": """; Method parameters\n(method_declaration\n  (formal_parameters\n    (formal_parameter\n    \t(type_identifier) @a\n    )\n  )\n)\n\n; Return type\n(method_declaration\n  (type_identifier) @b\n)"""
+    },
+    
+    "python": {
+        "import_query": """(import_from_statement\n  (dotted_name) ; skip the first (this is the module)\n  (dotted_name\n    (identifier) @importa))\n\n(import_statement\n    (dotted_name\n        (identifier) @importb ))""",
+        "function_declartion": """(\n    (function_definition\n        (parameters \n            (_ \n                (type) @a\n                (#not-match? @a "^(str|int|float|bool|list|dict|tuple)$")\n            )\n        )\n    )\n)\n\n(\n    (function_definition\n        (type) @b\n        (#not-match? @b "^(str|int|float|bool|list|dict|tuple)$")\n    )\n)"""
+    }
+}
+SEP_REGEX = r"[\\/]"
+
+# Checked
+class IRange(BaseModel):
+    start_point: Point
+    end_point: Point
+
+
+# Checked
+def get_ast(content, language):
+    if language == "java":
+        parser = JAVA_PARSER
+    elif language == "python":
+        parser = PYTHON_PARSER
+    else:
+        raise NotImplementedError("Language is not currently supported")
+    try:
+        ast = parser.parse(bytes(content, encoding="utf-8"))
+        return ast
+    except Exception as e:
+        print(e)
+        return None
+
+
+# Checked
+def get_symbols_for_snippet(text):
+    symbols = set(
+        filter(
+            lambda s: s != "",
+            map(
+                lambda s: s.strip(),
+                re.split(r"[\s.,/#!$%^&*;:{}=\-_`~()\[\]]", text),
+            ),
+        )
+    )
+    return symbols
+
+
+# Checked
+def get_tree_sitter_query(language: str, query_type: str):
+    if language == "java":
+        return JAVA.query(QUERIES[language][query_type])
+    elif language == "python":
+        return PYTHON.query(QUERIES[language][query_type])
+
+
+def get_tree_path_at_cursor(ast: Tree, cursor_index: Point):
+    path = [ast.root_node]
+    while path[-1].child_count > 0:
+        found_child = False
+        for child in path[-1].children:
+            if child.start_point <= cursor_index <= child.end_point:
+                path.append(child)
+                found_child = True
+                break
+        if not found_child:
+            break
+    return path
+
+
+# Checked
+def find_children(node: Node, predicate, first_n: Optional[int] = None):
+    matching_nodes = []
+    if first_n and first_n <= 0:
+        return []
+
+    # Check if the current node's type is in the list of types we're interested in
+    if predicate(node):
+        matching_nodes.append(node)
+
+    # Recursively search for matching types in all children of the current node
+    for child in node.children:
+        matching_nodes.extend(
+            find_children(
+                child, predicate, first_n - len(matching_nodes) if first_n else None
+            )
+        )
+
+    return matching_nodes
+
+
+# Checked
+def read_range_in_file(file_path: str, range: IRange):
+    with open(file_path, "r") as f:
+        lines = f.read().splitlines()
+
+    content = ""
+    for line in lines[range.start_point.row : range.end_point.row]:
+        content += line + "\n"
+    content += lines[range.end_point.row][: range.end_point.column]
+    return content
+
+
+def find_type_identifiers(root_node: Node) -> List[Node]:
+    return find_children(
+        root_node,
+        lambda node: node.type == "type_identifier"
+        or (
+            node.parent
+            and node.parent.type == "ERROR"
+            and node.type == "identifier"
+            and node.text.decode("utf-8")[0].isupper()
+        ),
+    )
+
+
+def point2index(content: str, point: Point) -> int:
+    content = content.replace("\r\n", "\n")
+    lines = content.splitlines()
+    index = 0
+    for i in range(point.row):
+        index += len(lines[i]) + 1
+    index += point.column
+    return index
+
+
+def lsprange2irange(lsprange: dict) -> IRange:
+    return IRange(
+        start_point=Point(
+            row=lsprange["start"]["line"],
+            column=lsprange["start"]["character"],
+        ),
+        end_point=Point(
+            row=lsprange["end"]["line"], column=lsprange["end"]["character"]
+        ),
+    )
+
+
+# Checked
+def intersection(a: IRange, b: IRange) -> Optional[IRange]:
+    start_row = max(a.start_point.row, b.start_point.row)
+    end_row = min(a.end_point.row, b.end_point.row)
+    if start_row > end_row:
+        return None
+
+    if start_row == end_row:
+        start_column = max(a.start_point.column, b.start_point.column)
+        end_column = min(a.end_point.column, b.end_point.column)
+
+        if start_column > end_column:
+            return None
+
+        return IRange(
+            start_point=Point(row=start_row, column=start_column),
+            end_point=Point(row=end_row, column=end_column),
+        )
+
+    start_column = (
+        a.start_point.column if start_row == a.start_point.row else b.start_point.column
+    )
+    end_column = (
+        a.end_point.column if end_row == a.end_point.row else b.end_point.column
+    )
+
+    return IRange(
+        start_point=Point(row=start_row, column=start_column),
+        end_point=Point(row=end_row, column=end_column),
+    )
diff --git a/benchmark/continue_dev/helper.py b/benchmark/continue_dev/helper.py
new file mode 100644
index 0000000..9d0ab47
--- /dev/null
+++ b/benchmark/continue_dev/helper.py
@@ -0,0 +1,110 @@
+from typing import NamedTuple
+from tree_sitter import Point
+import os
+from continue_dev.common_funcs import get_tree_path_at_cursor, get_ast
+from continue_dev.utils import count_tokens
+from continue_dev.lsp_service import point2index
+
+
+class Options(NamedTuple):
+    prefix_percentage: float
+    max_prompt_tokens: int
+    max_suffix_percentage: float
+    sliding_window_size: int
+    sliding_window_prefix_percentage: float
+    recently_edited_similarity_threshold: float
+    max_snippet_percentage: float
+    use_import: bool
+    use_root_path_context: bool
+
+
+class Helper:
+    tree_path = None
+    file_content = None
+    file_lines = None
+    full_prefix = None
+    full_suffix = None
+    pruned_prefix = None
+    pruned_suffix = None
+
+    options = Options(
+        prefix_percentage=0.85,
+        max_prompt_tokens=1024,
+        max_suffix_percentage=0.25,
+        sliding_window_size=500,
+        sliding_window_prefix_percentage=0.75,
+        recently_edited_similarity_threshold=0.3,
+        max_snippet_percentage=0.6,
+        use_import=True,
+        use_root_path_context=False,
+    )
+
+    def __init__(
+        self,
+        repo_dir: str,
+        relative_path: str,
+        cursor_index: Point,
+        language_server,
+        language: str = "java",
+        model_name: str = "deepseek-coder",
+    ):
+        self.repo_dir = repo_dir
+        self.language = language
+        self.relative_path = relative_path
+        self.file_path = os.path.join(self.repo_dir, self.relative_path)
+        self.cursor_index = cursor_index
+        self.model_name = model_name
+        self.language_server = language_server
+        with open(self.file_path, "r") as f:
+            self.file_content = f.read()
+
+        self.file_lines = self.file_content.splitlines()
+        ast = get_ast(self.file_content, self.language)
+        self.tree_path = get_tree_path_at_cursor(ast, self.cursor_index)
+
+        index = point2index(self.file_content, self.cursor_index)
+        self.full_prefix = self.file_content[:index]
+        self.full_suffix = self.file_content[index:]
+        self.max_snippet_tokens = int(
+            self.options.max_prompt_tokens * self.options.max_snippet_percentage
+        )
+        self.pruned_prefix, self.pruned_suffix = self.prune_prefix_suffix()
+        self.pruned_caret_window = self.pruned_prefix + self.pruned_suffix
+
+    def prune_prefix_suffix(self):
+        max_prefix_tokens = (
+            self.options.max_prompt_tokens * self.options.prefix_percentage
+        )
+        pruned_prefix = self.prune_lines_from_top(
+            self.full_prefix, max_prefix_tokens
+        )
+
+        max_suffix_tokens = min(
+            self.options.max_prompt_tokens
+            - count_tokens(pruned_prefix),
+            self.options.max_suffix_percentage * self.options.max_prompt_tokens,
+        )
+
+        pruned_suffix = self.prune_lines_from_bottom(
+            self.full_suffix, max_suffix_tokens
+        )
+
+        return pruned_prefix, pruned_suffix
+
+    @staticmethod
+    def prune_lines_from_top(text: str, max_tokens: int):
+        total_tokens = count_tokens(text)
+        lines = text.splitlines()
+        while total_tokens > max_tokens and lines:
+            removed_line = lines.pop(0)
+            total_tokens -= count_tokens(removed_line)
+        return "\n".join(lines)
+
+    @staticmethod
+    def prune_lines_from_bottom(text: str, max_tokens: int):
+        total_tokens = count_tokens(text)
+        lines = text.splitlines()
+        while total_tokens > max_tokens and lines:
+            removed_line = lines.pop()
+            total_tokens -= count_tokens(removed_line)
+        return "\n".join(lines)
diff --git a/benchmark/continue_dev/import_service.py b/benchmark/continue_dev/import_service.py
new file mode 100644
index 0000000..dd82099
--- /dev/null
+++ b/benchmark/continue_dev/import_service.py
@@ -0,0 +1,66 @@
+import os
+from continue_dev.lsp_service import LSPService
+from continue_dev.common_funcs import (
+    get_ast,
+    get_tree_sitter_query,
+    TOP_LEVEL_KEY_WORDS,
+    get_symbols_for_snippet,
+)
+
+
+class ImportService:
+    # Checked
+    def __init__(self, repo_dir: str, language_server, language: str = "java"):
+        self.repo_dir = repo_dir
+        self.lsp = LSPService(
+            repo_dir=self.repo_dir,
+            language_server=language_server,
+            language=language,
+        )
+        self.language = language
+        self.import_query = get_tree_sitter_query(self.language, "import_query")
+
+    # Checked
+    def get_file_info(self, relative_path: str):
+        try:
+            absolute_path = os.path.join(self.repo_dir, relative_path)
+            with open(absolute_path, "r", encoding="utf-8") as f:
+                content = f.read()
+
+            ast = get_ast(content, self.language)
+            results = self.import_query.captures(ast.root_node)
+            file_info = {"imports": {}}
+            for var in results:
+                for node in results[var]:
+                    type_def = self.lsp.execute_goto_provider(
+                        relative_path, node.start_point
+                    )
+                    if type_def:
+                        file_info["imports"][node.text.decode("utf-8")] = type_def
+            return file_info
+        except Exception as e:
+            print(e)
+            return None
+
+    # Checked
+    def get_snippet_by_import(self, relative_path, full_prefix, full_suffix):
+        import_snippets = []
+        file_info = self.get_file_info(relative_path)
+        if file_info and file_info["imports"]:
+            imports = file_info["imports"]
+            # Look for imports of any symbols around the current range
+            text_around_cursor = "\n".join(full_prefix.splitlines()[-5:]) + "\n".join(
+                full_suffix.splitlines()[:3]
+            )
+            symbols = list(
+                filter(
+                    lambda symbol: symbol not in TOP_LEVEL_KEY_WORDS[self.language],
+                    get_symbols_for_snippet(text_around_cursor),
+                )
+            )
+            for symbol in symbols:
+                if symbol in imports:
+                    if imports[symbol]:
+                        import_snippets.append(imports[symbol])
+
+        return import_snippets
diff --git a/benchmark/continue_dev/language_server.py b/benchmark/continue_dev/language_server.py
new file mode 100644
index 0000000..959b4aa
--- /dev/null
+++ b/benchmark/continue_dev/language_server.py
@@ -0,0 +1,174 @@
+# import json
+# import os
+# import socket
+# import subprocess
+# from subprocess import PIPE
+#
+#
+# class LanguageServer:
+#     def __init__(self, repository_root_path: str, port: int = 9211):
+#         self.repository_root_path = repository_root_path
+#         self.port = port
+#         self.id = -1
+#         self.data = "/home/lvdthieu/Documents/Projects/benchmark_continue/jdt-ls/data"
+#         self.config = (
+#             "/home/lvdthieu/Documents/Projects/benchmark_continue/jdt-ls/config_linux"
+#         )
+#         self.jar = "/home/lvdthieu/Documents/Projects/benchmark_continue/jdt-ls/plugins/org.eclipse.equinox.launcher_1.6.900.v20240613-2009.jar"
+#         self.open_file_cache = set()
+#
+#     def start_server(self):
+#         env = os.environ.copy()
+#         env["CLIENT_PORT"] = f"{self.port}"
+#         cmd = [
+#             "java",
+#             "--add-modules=ALL-SYSTEM",
+#             "--add-opens",
+#             "java.base/java.util=ALL-UNNAMED",
+#             "--add-opens",
+#             "java.base/java.lang=ALL-UNNAMED",
+#             "--add-opens",
+#             "java.base/sun.nio.fs=ALL-UNNAMED",
+#             "-Declipse.application=org.eclipse.jdt.ls.core.id1",
+#             "-Dosgi.bundles.defaultStartLevel=4",
+#             "-Declipse.product=org.eclipse.jdt.ls.core.product",
+#             "-Djava.import.generatesMetadataFilesAtProjectRoot=false",
+#             "-Dfile.encoding=utf8",
+#             "-noverify",
+#             "-XX:+UseParallelGC",
+#             "-XX:GCTimeRatio=4",
+#             "-XX:AdaptiveSizePolicyWeight=90",
+#             "-Dsun.zip.disableMemoryMapping=true",
+#             "-Djava.lsp.joinOnCompletion=true",
+#             "-Xmx3G",
+#             "-Xms100m",
+#             "-Xlog:disable",
+#             "-Dlog.level=ALL",
+#             "-jar",
+#             f"{self.jar}",
+#             "-configuration",
+#             f"{self.config}",
+#             "-data",
+#             f"{self.data}",
+#         ]
+#         proc = subprocess.Popen(cmd, env=env, stdin=PIPE, stdout=PIPE, stderr=PIPE)
+#         return proc
+#
+#     def create_connection(self):
+#         self.sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
+#         self.sock.bind(("localhost", self.port))
+#         print(f"Listening on port {self.port}")
+#         self.sock.listen(1)
+#         print("Waiting for connection...")
+#         self.proc = self.start_server()
+#         while True:
+#             self.conn, addr = self.sock.accept()
+#             if self.conn:
+#                 break
+#         print(f"Connection from {addr}")
+#
+#     def close_connection(self):
+#         subprocess.Popen.kill(self.proc)
+#         self.conn.close()
+#         self.sock.close()
+#
+#     def get_id(self):
+#         self.id += 1
+#         return self.id
+#
+#     def read_lsp_message(self):
+#         header = b""
+#         while True:
+#             try:
+#                 data = self.conn.recv(1)
+#             except Exception as e:
+#                 raise e
+#             header += data
+#             if header.endswith(b"\r\n\r\n"):
+#                 break
+#
+#         content_length = int(header.split(b"Content-Length: ")[1].split(b"\r\n")[0])
+#         payload = self.conn.recv(content_length)
+#         message = json.loads(payload.decode("utf-8"))
+#         return message
+#
+#     def send_lsp_message(self, message):
+#         payload = json.dumps(message).encode("utf-8")
+#         header = f"Content-Length: {len(payload)}\r\n\r\n".encode("utf-8")
+#         self.conn.sendall(header + payload)
+#
+#     def init(self):
+#         self.start_server()
+#         self.create_connection()
+#         self.initialize()
+#
+#     def initialize(self):
+#         request = {
+#             "jsonrpc": "2.0",
+#             "id": self.get_id(),
+#             "method": "initialize",
+#             "params": {
+#                 "processId": None,
+#                 "rootPath": self.repository_root_path,
+#                 "rootUri": f"file://{self.repository_root_path}",
+#             },
+#         }
+#         self.send_lsp_message(request)
+#         response = self.get_lsp_response(request)
+#         if response.get("error"):
+#             raise Exception(f"Error initializing LSP server: {response['error']}")
+#
+#     def get_lsp_response(self, request):
+#         while True:
+#             response = self.read_lsp_message()
+#             if response.get("id", -1) == request["id"]:
+#                 return response
+#             else:
+#                 print(response)
+#                 print(request["id"])
+#                 print("=" * 100)
+#                 continue
+#
+#     def request_definition(self, file_path, position):
+#         if file_path not in self.open_file_cache:
+#             notify = {
+#                 "jsonrpc": "2.0",
+#                 "method": "textDocument/didOpen",
+#                 "params": {
+#                     "textDocument": {
+#                         "uri": f"file://{file_path}",
+#                         "languageId": "java",
+#                         "version": 1,
+#                         "text": self.get_file_content(file_path),
+#                     }
+#                 },
+#             }
+#             self.send_lsp_message(notify)
+#             self.open_file_cache.add(file_path)
+#
+#         while True:
+#             message = self.read_lsp_message()
+#             if message.get("method") == "textDocument/publishDiagnostics":
+#                 break
+#
+#         request = {
+#             "jsonrpc": 2.0,
+#             "id": self.get_id(),
+#             "method": "textDocument/definition",
+#             "params": {
+#                 "textDocument": {
+#                     "uri": f"file://{file_path}",
+#                 },
+#                 "position": position,
+#             },
+#         }
+#         self.send_lsp_message(request)
+#         response = self.get_lsp_response(request)
+#         return response
+#
+#     def get_file_content(self, file_path):
+#         with open(file_path, "r") as file:
+#             return file.read()
+#
+#     def destroy(self):
+#         self.close_connection()
diff --git a/benchmark/continue_dev/lsp_service.py b/benchmark/continue_dev/lsp_service.py
new file mode 100644
index 0000000..e167498
--- /dev/null
+++ b/benchmark/continue_dev/lsp_service.py
@@ -0,0 +1,225 @@
+#   Author: masterSunflowers
+#   Github: https://github.com/masterSunflowers/masterSunflowers
+#   Date:   01/12/2024
+#   Desc:   This file implements code to simulate getting context using LSP in Continue autocomplete feature.
+
+import time
+
+from multilspy import SyncLanguageServer
+from multilspy.multilspy_logger import MultilspyLogger
+from tree_sitter import Node, Point
+
+from continue_dev.common_funcs import (
+    FUNCTION_BLOCK_NODE_TYPES,
+    FUNCTION_DECLARATION_NODE_TYPES,
+    find_children,
+    find_type_identifiers,
+    get_ast,
+    get_tree_path_at_cursor,
+    intersection,
+    lsprange2irange,
+    point2index,
+    read_range_in_file,
+)
+
+multilspy_logger = MultilspyLogger()
+
+
+class LSPService:
+    def __init__(
+        self, repo_dir: str, language_server: SyncLanguageServer, language: str = "java"
+    ):
+        self.repo_dir = repo_dir
+        self.language = language
+        self.language_server = language_server
+
+    # Checked
+    def get_definition_from_lsp(
+        self, rev_file_path: str, prefix: str, suffix: str, cursor_index: Point
+    ):
+        content = prefix + ")" + suffix if prefix.endswith("(") else prefix + suffix
+        try:
+            ast = get_ast(content, self.language)
+
+            if not ast:
+                return []
+            tree_path = get_tree_path_at_cursor(ast, cursor_index)
+
+            if not tree_path:
+                return []
+            results = []
+            for node in reversed(tree_path):
+                definitions = self.get_definition_for_node(rev_file_path, node)
+                results.extend(definitions)
+            return list(map(lambda result: {**result, "score": 0.8}, results))
+        except Exception as e:
+            print("Error getting definitions from LSP: ", e)
+            return []
+
+    # Checked
+    def get_definition_for_node(self, uri: str, node: Node):
+        ranges = []
+        try:
+            match node.type:
+                case "call_expression" | "method_invocation" | "call":
+                    # print("Node content")
+                    # print(node.text.decode("utf-8"))
+                    # print("start point of node")
+                    # print(uri)
+                    # print(node.start_point)
+                    func_def = self.execute_goto_provider(uri, node.start_point)
+                    # print("func definition")
+                    # print(func_def)
+                    if not func_def:
+                        return []
+                    # Don't display a function of more than 15 lines
+                    # We can of course do something smarter here eventually
+                    if len(func_def["content"].splitlines()) > 15:
+                        truncated = False
+                        func_root_ast = get_ast(func_def["content"], self.language)
+                        if func_root_ast:
+                            func_node = find_children(
+                                func_root_ast.root_node,
+                                lambda node: node.type
+                                in FUNCTION_DECLARATION_NODE_TYPES,
+                                1,
+                            )
+                            if func_node:
+                                func_node = func_node[0]
+                                statement_block_node = find_children(
+                                    func_node,
+                                    lambda node: node.type in FUNCTION_BLOCK_NODE_TYPES,
+                                    1,
+                                )
+                                if statement_block_node:
+                                    statement_block_node = statement_block_node[0]
+                                    start_index = point2index(
+                                        func_def["content"],
+                                        statement_block_node.start_point,
+                                    )
+                                    func_def["content"] = (
+                                        func_root_ast.root_node.text.decode("utf-8")[
+                                            :start_index
+                                        ].strip()
+                                    )
+                                    truncated = True
+                        if not truncated:
+                            func_def["content"] = func_def["content"].splitlines()[0]
+
+                    ranges.append(func_def)
+
+                    type_defs = self.crawl_types(func_def)
+                    ranges.extend(type_defs)
+                case "new_expression" | "object_creation_expression" | "call":
+                    # In 'new MyClass(...)', "MyClass" is the classNameNode
+                    class_name_node = None
+                    for child in node.children:
+                        if child.type == "type_identifier":
+                            class_name_node = child
+
+                    class_def = self.execute_goto_provider(
+                        uri, class_name_node.start_point
+                    )
+                    if not class_def:
+                        return []
+                    ranges.append(class_def)
+
+                    new_type_defs = self.crawl_types(class_def)
+                    ranges.extend(new_type_defs)
+                case _:
+                    pass
+        except Exception as e:
+            print(e)
+            return []
+        return ranges
+
+    # Checked
+    def crawl_types(
+        self, definition, depth: int = 1, results=None, searched_labels=None
+    ):
+        # Parse AST
+        if searched_labels is None:
+            searched_labels = set()
+        if results is None:
+            results = []
+        ast = get_ast(definition["content"], self.language)
+        if not ast:
+            return results
+        ast_line_count = len(ast.root_node.text.decode("utf-8").splitlines())
+
+        # Find type identifiers
+        identifier_nodes = list(
+            filter(
+                lambda node: node.text.decode("utf-8") not in searched_labels,
+                find_type_identifiers(ast.root_node),
+            )
+        )
+
+        # Don't search for the same type definition more than one
+        # We duplicate below to be sure, but this save calls to the LSP
+        for node in identifier_nodes:
+            searched_labels.add(node.text.decode("utf-8"))
+
+        # Use LSP to get the definitions of those types
+        new_definitions = []
+        for node in identifier_nodes:
+            type_def = self.execute_goto_provider(
+                file_path=definition["relative_path"],
+                # TODO: tree-sitter is zero-indexed, but there seems to be an off-by-one
+                # error at least with the .ts parser sometimes
+                position=Point(
+                    row=definition["range"].start_point.row
+                    + min(node.start_point.row, ast_line_count - 1),
+                    column=definition["range"].start_point.column
+                    + node.start_point.column,
+                ),
+            )
+            if not type_def:
+                continue
+            new_definitions.append(type_def)
+
+        # TODO: Filter out if not in our code?
+
+        # Filter out duplicates
+        for new_definition in new_definitions:
+            if not new_definition or any(
+                [
+                    result["relative_path"] == new_definition["relative_path"]
+                    and intersection(result["range"], new_definition["range"])
+                    for result in results
+                ]
+            ):
+                continue
+
+            results.append(new_definition)
+
+        # Recurse
+        if depth > 0:
+            for result in results:
+                self.crawl_types(result, depth - 1, results, searched_labels)
+
+        return results
+
+    # Checked
+    def execute_goto_provider(self, file_path, position):
+        start = time.time()
+
+        lsf = self.language_server.request_definition(
+            file_path, position.row, position.column
+        )
+        print("Language Server tooks:", time.time() - start, "s")
+        # print("Language Serve Feedback:")
+        # print(lsf)
+        # Check if language server feedback is empty
+        if not lsf:
+            return None
+        else:
+            lsf = lsf[0]
+        definition_name_range = lsprange2irange(lsf["range"])
+        content = read_range_in_file(lsf["absolutePath"], definition_name_range)
+        definition_info = {
+            "relative_path": lsf["relativePath"],
+            "range": definition_name_range,
+            "content": content,
+        }
+        return definition_info
diff --git a/benchmark/continue_dev/root_path_context_service.py b/benchmark/continue_dev/root_path_context_service.py
new file mode 100644
index 0000000..739439c
--- /dev/null
+++ b/benchmark/continue_dev/root_path_context_service.py
@@ -0,0 +1,54 @@
+from continue_dev.lsp_service import LSPService
+from tree_sitter import Node
+from continue_dev.common_funcs import get_tree_sitter_query, TYPES_TO_USE
+
+
+class RootPathContextService:
+    # Checked
+    def __init__(self, repo_dir: str, language_server, language: str):
+        self.repo_dir = repo_dir
+        self.language = language
+        self.lsp_service = LSPService(
+            repo_dir=repo_dir, language_server=language_server, language=language
+        )
+
+    # Checked
+    def get_snippet_for_node(self, relative_path: str, node: Node):
+        snippets = []
+        query = None
+        match node.type:
+            case "program":
+                pass
+            case "function_declaration":
+                query = get_tree_sitter_query(self.language, "function_declaration")
+            case "method_declaration":
+                query = get_tree_sitter_query(self.language, "method_declaration")
+            case "function_definition":
+                query = get_tree_sitter_query(self.language, "function_definition")
+            case "method_definition":
+                query = get_tree_sitter_query(self.language, "method_definition")
+            case _:
+                pass
+
+        if not query:
+            return snippets
+
+        results = query.captures(node)
+        for var in results:
+            for node in results[var]:
+                type_def = self.lsp_service.execute_goto_provider(
+                    relative_path, position=node.end_point
+                )
+                if type_def:
+                    snippets.append(type_def)
+        return snippets
+
+    # Checked
+    def get_snippet_by_root_path(self, relative_path, tree_path):
+        snippets = []
+        print("Tree Path:")
+        print(tree_path)
+        for ast_node in list(filter(lambda node: node.type in TYPES_TO_USE, tree_path)):
+            new_snippets = self.get_snippet_for_node(relative_path, ast_node)
+            snippets.extend(new_snippets)
+        return snippets
diff --git a/benchmark/continue_dev/utils.py b/benchmark/continue_dev/utils.py
new file mode 100644
index 0000000..936e25f
--- /dev/null
+++ b/benchmark/continue_dev/utils.py
@@ -0,0 +1,520 @@
+import os
+from typing import List, NamedTuple
+
+from tree_sitter import Point
+
+from continue_dev.common_funcs import (
+    COMMON_STOPS,
+    LANGUAGE_COMMENT_SYMBOL,
+    SEP_REGEX,
+    TOKENIZER,
+    IRange,
+    get_symbols_for_snippet,
+    read_range_in_file,
+)
+from continue_dev.import_service import ImportService
+from continue_dev.lsp_service import LSPService
+from continue_dev.root_path_context_service import RootPathContextService
+
+Snippet = NamedTuple("Snippet")
+
+
+# Checked
+def get_extra_snippets(helper):
+    lsp_service = LSPService(
+        repo_dir=helper.repo_dir,
+        language_server=helper.language_server,
+        language=helper.language,
+    )
+    extra_snippets = lsp_service.get_definition_from_lsp(
+        rev_file_path=helper.relative_path,
+        prefix=helper.full_prefix,
+        suffix=helper.full_suffix,
+        cursor_index=helper.cursor_index,
+    )
+    return extra_snippets
+
+
+# Checked
+def get_snippet_from_import_definitions(helper):
+    import_service = ImportService(
+        repo_dir=helper.repo_dir,
+        language_server=helper.language_server,
+        language=helper.language,
+    )
+    import_snippets = import_service.get_snippet_by_import(
+        relative_path=helper.relative_path,
+        full_prefix=helper.full_prefix,
+        full_suffix=helper.full_suffix,
+    )
+    return import_snippets
+
+
+# Checked
+def get_context_for_path(helper):
+    root_path_context_service = RootPathContextService(
+        repo_dir=helper.repo_dir,
+        language_server=helper.language_server,
+        language=helper.language,
+    )
+    snippets = root_path_context_service.get_snippet_by_root_path(
+        relative_path=helper.relative_path, tree_path=helper.tree_path
+    )
+
+    return snippets
+
+
+# Checked
+def retrieve_candidate_snippets(helper):
+    lsp_snippets = get_extra_snippets(helper)
+    import_snippets = get_snippet_from_import_definitions(helper)
+    if helper.options.use_root_path_context:
+        root_path_context_snippets = get_context_for_path(helper)
+        snippets = [*lsp_snippets, *import_snippets, *root_path_context_snippets]
+        return lsp_snippets, import_snippets, root_path_context_snippets, snippets
+    else:
+        snippets = [*lsp_snippets, *import_snippets]
+        return lsp_snippets, import_snippets, [], snippets
+
+
+# Checked
+def construct_autocomplete_prompt(helper):
+    lsp_snippets, import_snippets, root_path_context_snippets, snippets = (
+        retrieve_candidate_snippets(helper)
+    )
+    snippets = filter_snippets_already_in_caret_window(
+        snippets, helper.pruned_caret_window
+    )
+    scored_snippets = rank_and_order_snippets(helper, snippets)
+    final_snippets = remove_range_from_snippets(
+        snippets=scored_snippets,
+        file_path=helper.file_path,
+        relative_path=helper.relative_path,
+        range=get_range_of_prefix_and_suffix_with_buffer(
+            helper.pruned_prefix, helper.pruned_suffix, helper.cursor_index
+        ),
+    )
+    final_snippets = list(
+        filter(
+            lambda snippet: snippet["score"]
+            >= helper.options.recently_edited_similarity_threshold,
+            snippets,
+        )
+    )
+    final_snippets = fill_prompt_with_snippets(
+        scored_snippets, helper.max_snippet_tokens
+    )
+    return lsp_snippets, import_snippets, root_path_context_snippets, final_snippets
+
+
+# Checked
+def filter_snippets_already_in_caret_window(snippets: List[Snippet], caret_window: str):
+    return list(
+        filter(
+            lambda s: s["content"].strip() != ""
+            and s["content"].strip() not in caret_window,
+            snippets,
+        )
+    )
+
+
+# Checked
+def rank_and_order_snippets(helper, snippets: List[Snippet]):
+    """Rank code snippets to be used in tab-autocomplete prompt.
+    Returns a sorted version of the snippet array."""
+    window_around_cursor = (
+        helper.full_prefix[
+            : int(
+                -helper.options.sliding_window_size
+                * helper.options.sliding_window_prefix_percentage
+            )
+        ]
+        + helper.full_suffix[
+            : int(
+                helper.options.sliding_window_size
+                * (1 - helper.options.sliding_window_prefix_percentage)
+            )
+        ]
+    )
+    for snippet in snippets:
+        if "score" not in snippet:
+            snippet["score"] = jaccard_similarity(
+                snippet["content"], window_around_cursor
+            )
+
+    snippets = deduplicate_snippets(snippets)
+    snippets = sorted(snippets, key=lambda s: s["score"])
+    return snippets
+
+
+# Checked
+def remove_range_from_snippets(
+    snippets: List[Snippet], file_path: str, relative_path: str, range: IRange
+):
+    final_snippet = []
+    for snippet in snippets:
+        if snippet["relative_path"] != relative_path:
+            final_snippet.append(snippet)
+            continue
+
+        intersection = range_intersection_by_lines(range, snippet["range"])
+        if not intersection:
+            final_snippet.append(snippet)
+        else:
+            different_ranges = range_different_by_lines(snippet["range"], intersection)
+            for diff_range in different_ranges:
+                final_snippet.append(
+                    {
+                        **snippet,
+                        "range": diff_range,
+                        "content": read_range_in_file(file_path, diff_range),
+                    }
+                )
+    return final_snippet
+
+
+# Checked
+def jaccard_similarity(a: str, b: str) -> float:
+    a_set = get_symbols_for_snippet(a)
+    b_set = get_symbols_for_snippet(b)
+    union = len(a_set.union(b_set))
+    if union == 0:
+        return 0
+    return len(a_set.intersection(b_set)) / union
+
+
+# Checked
+def deduplicate_snippets(snippets: List[Snippet]) -> List[Snippet]:
+    """Deduplicate code snippets by merging overlapping ranges into a single range."""
+    # Group snippets by file path
+    file_groups = {}
+    for snippet in snippets:
+        file_groups[snippet["relative_path"]] = file_groups.get(
+            snippet["relative_path"], []
+        ) + [snippet]
+
+    # Merge overlapping ranges
+    all_ranges = []
+
+    for file in file_groups:
+        all_ranges.extend(merge_snippet_by_range(file_groups[file]))
+
+    return all_ranges
+
+
+# Checked
+def merge_snippet_by_range(snippets: List[Snippet]) -> List[Snippet]:
+    if len(snippets) <= 1:
+        return snippets
+
+    sorted_snippets = sorted(snippets, key=lambda x: x["range"].start_point.row)
+    merged = []
+    while len(sorted_snippets) > 0:
+        next_snippet = sorted_snippets.pop(0)
+        if (
+            len(merged) > 0
+            and merged[-1]["range"].end_point.row
+            > next_snippet["range"].start_point.row
+        ):
+            last_merged = merged[-1]
+            # Merge with previous snippet
+            last_merged["score"] = max(last_merged["score"], next_snippet["score"])
+            try:
+                last_merged["range"].end_point = next_snippet["range"].end_point
+            except Exception as e:
+                print("Error merging ranges", e)
+            last_merged["content"] = merge_overlapping_range_content(
+                last_merged, next_snippet
+            )
+        else:
+            merged.append(next_snippet)
+    return merged
+
+
+# Checked
+def merge_overlapping_range_content(first: Snippet, second: Snippet) -> str:
+    first_lines = first["content"].splitlines()
+    num_overlapping = first["range"].end_point.row - second["range"].start_point.row
+    return "\n".join(first_lines[:-num_overlapping] + second["content"].splitlines())
+
+
+# Checked
+def range_intersection_by_lines(range1: IRange, range2: IRange) -> IRange:
+    start_line = max(range1.start_point.row, range2.start_point.row)
+    end_line = min(range1.end_point.row, range2.end_point.row)
+    if start_line >= end_line:
+        return None
+
+    return IRange(
+        start_point=Point(row=start_line, column=0),
+        end_point=Point(row=end_line, column=0),
+    )
+
+
+# Checked
+def range_different_by_lines(orig: IRange, remove: IRange) -> List[IRange]:
+    if (
+        orig.start_point.row >= remove.start_point.row
+        and orig.end_point.row <= remove.end_point.row
+    ):
+        return []
+
+    if (
+        orig.start_point.row <= remove.start_point.row
+        and orig.end_point.row >= remove.end_point.row
+    ):
+        return [
+            IRange(
+                start_point=orig.start_point,
+                end_point=remove.start_point,
+            ),
+            IRange(
+                start_point=remove.end_point,
+                end_point=orig.end_point,
+            ),
+        ]
+
+    if (
+        orig.start_point.row >= remove.start_point.row
+        and orig.end_point.row >= remove.end_point.row
+    ):
+        return [
+            IRange(
+                start_point=remove.end_point,
+                end_point=orig.end_point,
+            )
+        ]
+    if (
+        orig.start_point.row <= remove.start_point.row
+        and orig.end_point.row <= remove.end_point.row
+    ):
+        return [
+            IRange(
+                start_point=orig.start_point,
+                end_point=remove.start_point,
+            )
+        ]
+
+    return [orig]
+
+
+# Checked
+def get_range_of_prefix_and_suffix_with_buffer(
+    prefix: str, suffix: str, cursor_index: int
+) -> IRange:
+    prefix_lines = len(prefix.splitlines())
+    suffix_lines = len(suffix.splitlines())
+
+    buffer = 8
+    prefix_suffix_range_with_buffer = IRange(
+        start_point=Point(row=cursor_index.row - prefix_lines - buffer, column=0),
+        end_point=Point(row=cursor_index.row + suffix_lines + buffer, column=0),
+    )
+
+    return prefix_suffix_range_with_buffer
+
+
+# Checked
+def fill_prompt_with_snippets(
+    snippets: List[Snippet], max_snippet_tokens: int
+) -> List[Snippet]:
+    tokens_remaining = max_snippet_tokens
+    kept_snippets = []
+    for snippet in snippets:
+        token_count = count_tokens(snippet["content"])
+        if tokens_remaining - token_count >= 0:
+            tokens_remaining -= token_count
+            kept_snippets.append(snippet)
+        else:
+            continue
+    return kept_snippets
+
+
+# Checked
+def count_tokens(content: str) -> int:
+    return len(TOKENIZER(content)["input_ids"])
+
+
+def deepseek_render_prompt(snippets: List[Snippet], helper):
+    prefix = helper.pruned_prefix
+    suffix = helper.pruned_suffix
+    deepseek_fim_template = {
+        "template": "<｜fim▁begin｜>{prefix}<｜fim▁hole｜>{suffix}<｜fim▁end｜>",
+        "completionOptions": {
+            "stop": [
+                "<｜fim▁begin｜>",
+                "<｜fim▁hole｜>",
+                "<｜fim▁end｜>",
+                "//",
+                "<｜end▁of▁sentence｜>",
+            ],
+        },
+    }
+    template = deepseek_fim_template["template"]
+    completion_options = deepseek_fim_template["completionOptions"]
+    prompt, prefix = render_string_template(
+        template, prefix, suffix, snippets, helper.language, helper.relative_path
+    )
+
+    stop_tokens = get_stop_tokens(completion_options)
+
+    completion_options = {
+        **completion_options,
+        "stop": stop_tokens,
+    }
+
+    return prompt, prefix, suffix, completion_options
+
+
+def codestral_render_prompt(snippets: List[Snippet], helper):
+    prefix = helper.pruned_prefix
+    suffix = helper.pruned_suffix
+
+    def compile_prefix_suffix(
+        prefix: str, suffix: str, filepath: str, snippets: List[Snippet]
+    ):
+        if len(snippets) == 0:
+            if len(suffix.strip()) == 0 and len(prefix.strip()) == 0:
+                return [f"+++++ {get_last_n_path_parts(filepath, 2)}\n{prefix}", suffix]
+            else:
+                return [prefix, suffix]
+        relative_paths = shortest_relative_paths(
+            [snippet["relative_path"] for snippet in snippets] + [filepath]
+        )
+        other_files = "\n\n".join(
+            [
+                f"+++++ {relative_paths[i]}\n{snippet['content']}"
+                for i, snippet in enumerate(snippets)
+            ]
+        )
+        return [f"{other_files}\n\n+++++ {relative_paths[-1]}\n{prefix}", suffix]
+
+    def template(prefix: str, suffix: str):
+        return f"[SUFFIX]{suffix}[PREFIX]{prefix}"
+
+    completion_options = {
+        "stop": ["[PREFIX]", "[SUFFIX]", "/src/", "#- coding: utf-8", "```"],
+    }
+    prefix, suffix = compile_prefix_suffix(
+        prefix, suffix, helper.relative_path, snippets
+    )
+    prompt = template(prefix, suffix)
+    return prompt, prefix, suffix, completion_options
+
+
+def shortest_relative_paths(paths: List[str]) -> List[str]:
+    if len(paths) == 0:
+        return []
+
+    parts_lengths = [len(path.split(SEP_REGEX)) for path in paths]
+    current_relative_paths = [os.path.basename(path) for path in paths]
+    current_num_parts = [1 for _ in paths]
+    is_duplicated = []
+    for i, x in enumerate(current_relative_paths):
+        is_duplicated.append(
+            len(
+                [
+                    (j, y)
+                    for j, y in enumerate(current_relative_paths)
+                    if x == y and paths[i] != paths[j]
+                ]
+            )
+            > 1
+        )
+
+    while any(is_duplicated):
+        for i, is_dup in enumerate(is_duplicated):
+            if is_dup:
+                first_duplicated_path = current_relative_paths[i]
+                break
+        else:
+            break
+
+        for i, x in current_relative_paths:
+            if x == first_duplicated_path:
+                current_num_parts[i] += 1
+                current_relative_paths[i] = get_last_n_path_parts(
+                    paths[i], current_num_parts[i]
+                )
+
+        for i, x in is_duplicated:
+            if x:
+                is_duplicated[i] = (
+                    current_num_parts[i] < parts_lengths[i]
+                    and len(
+                        list(
+                            filter(
+                                lambda y: y == current_relative_paths[i],
+                                current_relative_paths,
+                            )
+                        )
+                    )
+                    > 1
+                )
+    return current_relative_paths
+
+
+# Checked
+def render_prompt(snippets, helper):
+    print("Snippets:")
+    print(snippets)
+    print("=" * 100)
+    print("=" * 100)
+
+    match helper.model_name:
+        case "deepseek-coder":
+            return deepseek_render_prompt(snippets, helper)
+        case "codestral-latest":
+            return codestral_render_prompt(snippets, helper)
+
+
+# Checked
+def render_string_template(template, prefix, suffix, snippets, language, relative_path):
+    # Format snippets as comments and prepend to prefix
+    formatted_snippets = "\n".join(
+        list(
+            map(
+                lambda snippet: format_external_snippet(
+                    snippet["relative_path"], snippet["content"], language
+                ),
+                snippets,
+            )
+        )
+    )
+
+    if len(formatted_snippets) > 0:
+        prefix = f"{formatted_snippets}\n\n{prefix}"
+    elif len(prefix.strip()) == 0 and len(suffix.strip()) == 0:
+        # If it's an empty file, include the file name as a comment
+        prefix = f"{LANGUAGE_COMMENT_SYMBOL[language]} {get_last_n_path_parts(relative_path, 2)}\n{prefix}"
+
+    prompt = compile_template(prefix, suffix, template)
+    return prompt, prefix
+
+
+# Checked
+def format_external_snippet(relative_path, content, language):
+    comment = LANGUAGE_COMMENT_SYMBOL[language]
+    lines = [
+        f"{comment} Path: {os.path.basename(relative_path)}",
+        *map(lambda line: f"{comment} {line}", content.strip().splitlines()),
+        comment,
+    ]
+    return "\n".join(lines)
+
+
+# Checked
+def get_last_n_path_parts(file_path, n):
+    return os.path.join(os.path.split(file_path)[-n:])
+
+
+# Checked
+def compile_template(prefix: str, suffix: str, template: str):
+    return template.format(prefix=prefix, suffix=suffix)
+
+
+# Checked
+def get_stop_tokens(completion_options):
+    stop_tokens = completion_options["stop"] if "stop" in completion_options else []
+    stop_tokens += COMMON_STOPS
+    return stop_tokens
diff --git a/benchmark/crosscodeeval.py b/benchmark/crosscodeeval.py
new file mode 100644
index 0000000..0b0c655
--- /dev/null
+++ b/benchmark/crosscodeeval.py
@@ -0,0 +1,259 @@
+#!/usr/bin/env python
+# coding: utf-8
+
+# # Check, make and clean dataset
+
+# In[1]:
+
+
+import pandas as pd
+
+df = pd.read_json("CrossCodeEval/typescript/line_completion.jsonl", lines=True)
+df.info()
+
+
+# In[2]:
+
+
+for col in df.columns:
+    print(df.loc[0, col])
+
+
+# In[23]:
+
+
+df["repo"] = df["metadata"].apply(lambda x: x["repository"])
+
+
+# In[24]:
+
+
+df["repo"].unique()
+
+
+# In[25]:
+
+
+lst_repo = df["repo"].unique().tolist()
+lst_repo
+
+
+# In[26]:
+
+
+df["commit"] = df["repo"].apply(lambda name: name.split('-')[-1])
+
+
+# In[27]:
+
+
+lst_candidate = []
+for repo in lst_repo:
+    lst = repo.split('-')[:-1]
+    for i in range(0, len(lst) - 1):
+        username = '-'.join(lst[:i + 1])
+        repo = '-'.join(lst[i + 1:])
+        lst_candidate.append({"username": username, "repo": repo})
+print(len(lst_candidate))
+
+
+# In[ ]:
+
+
+import requests
+import time
+from tqdm import tqdm
+HEADER = {
+    'Authorization': '<TOKEN>', 
+    'Accept': 'application/vnd.github.v3+json'
+}
+for i, candidate in tqdm(enumerate(lst_candidate), total=len(lst_candidate), desc="Querying"):
+    try:
+        url = f"https://api.github.com/repos/{candidate['username']}/{candidate['repo']}"
+        response = requests.get(url, headers=HEADER)
+        if response.status_code == 404:
+            lst_candidate[i]["exists"] = False
+        elif response.status_code == 200:
+            lst_candidate[i]["exists"] = True
+        else:
+            print(response.status_code)
+    except Exception as e:
+        print(candidate)
+        print(e)
+        print('-' * 100)
+    time.sleep(0.72)
+
+
+# In[39]:
+
+
+lst_candidate[0]
+
+
+# In[37]:
+
+
+lst_candate_filter = list(filter(lambda candidate: candidate["exists"], lst_candidate))
+len(lst_candate_filter)
+
+
+# In[32]:
+
+
+df["repo"]
+
+
+# In[38]:
+
+
+for i in range(len(lst_candate_filter)):
+    lst_candate_filter[i]["origin"] = lst_candate_filter[i]["username"] + '-' + lst_candate_filter[i]["repo"]
+
+lst_candate_filter
+
+
+# In[40]:
+
+
+def repo_to_encode(repo: str):
+    commit = repo.split('-')[-1]
+    origin = '-'.join(repo.split('-')[:-1])
+    for candidate in lst_candate_filter:
+        if origin == candidate["origin"]:
+            encode = candidate["username"] + "--" + candidate["repo"] + "--" + commit
+            return encode
+    return None
+
+
+# In[44]:
+
+
+i = 75
+print(df.loc[i, "repo"])
+repo_to_encode(df.loc[i, "repo"])
+
+
+# In[45]:
+
+
+df["encode"] = df["repo"].apply(lambda repo: repo_to_encode(repo))
+
+
+# In[47]:
+
+
+df["encode"].info()
+
+
+# In[48]:
+
+
+df.info()
+
+
+# In[49]:
+
+
+new_df = df.dropna(axis=0, how="any", ignore_index=True)
+
+
+# In[50]:
+
+
+new_df.info()
+
+
+# In[51]:
+
+
+new_df.to_json("dataset.jsonl", lines=True, orient="records")
+
+
+# In[53]:
+
+
+new_df["encode"].nunique()
+
+
+# In[54]:
+
+
+lst_encode = new_df["encode"].unique().tolist()
+
+
+# In[ ]:
+
+
+import collections
+repo = [encode.split("--")[1] for encode in lst_encode]
+collections.Counter(repo)
+
+
+# In[58]:
+
+
+import subprocess
+tmp_df = new_df.drop_duplicates(subset=["encode"], ignore_index=True)
+save_dir="/home/lvdthieu/Documents/Projects/benchmark_continue/github_repos"
+for _, row in tqdm(tmp_df.iterrows(), total=len(tmp_df), desc="Cloning"):
+    encode = row["encode"]
+    username, repo, commit = encode.split("--")
+    cmd = f"cd {save_dir} && mv {repo} {encode}"
+    res = subprocess.run(cmd, shell=True, capture_output=True, text=True)
+
+
+# In[62]:
+
+
+for row in tmp_df[tmp_df["encode"].str.contains("android_device_xiaomi_sm6225-common")]["encode"]:
+    print(row)
+
+
+# In[65]:
+
+
+new_new_df = new_df[new_df["encode"] != "CHRISL7--android_device_xiaomi_sm6225-common--ed8a1e0"]
+new_new_df.info()
+
+
+# In[66]:
+
+
+new_new_df.reset_index(drop=True, inplace=True)
+new_new_df.info()
+
+
+# In[67]:
+
+
+new_new_df.to_json("dataset_cleaned.jsonl", lines=True, orient="records")
+
+
+# # New
+
+# In[14]:
+
+
+import pandas as pd
+df = pd.read_json("data/dataset_cleaned.jsonl", lines=True)
+df.info()
+
+
+# In[15]:
+
+
+sampled = df.sample(n=200, random_state=42)
+sampled
+
+
+# In[16]:
+
+
+sampled.to_json("data/dataset_sampled.jsonl", lines=True, orient="records")
+
+
+# In[ ]:
+
+
+
+
diff --git a/benchmark/data/.gitignore b/benchmark/data/.gitignore
new file mode 100644
index 0000000..c96a04f
--- /dev/null
+++ b/benchmark/data/.gitignore
@@ -0,0 +1,2 @@
+*
+!.gitignore
\ No newline at end of file
diff --git a/benchmark/eval.py b/benchmark/eval.py
new file mode 100644
index 0000000..d392d7e
--- /dev/null
+++ b/benchmark/eval.py
@@ -0,0 +1,17 @@
+from fuzzywuzzy import fuzz
+
+
+def cal_edit_sim(references, hypotheses):
+    total = len(references)
+    edit_sim = 0.0
+    for pred, gt in zip(hypotheses, references):
+        pred = pred.strip()
+        gt = gt.strip()
+        edit_sim += fuzz.ratio(pred, gt)
+    return edit_sim / total
+
+
+def cal_exactly_match(references, hypotheses):
+    total = len(references)
+    em = sum([pred.strip() == gt.strip() for pred, gt in zip(hypotheses, references)])
+    return em / total
diff --git a/benchmark/java_repos/.gitignore b/benchmark/java_repos/.gitignore
new file mode 100644
index 0000000..c96a04f
--- /dev/null
+++ b/benchmark/java_repos/.gitignore
@@ -0,0 +1,2 @@
+*
+!.gitignore
\ No newline at end of file
diff --git a/benchmark/java_repos_tmp/.gitignore b/benchmark/java_repos_tmp/.gitignore
new file mode 100644
index 0000000..c96a04f
--- /dev/null
+++ b/benchmark/java_repos_tmp/.gitignore
@@ -0,0 +1,2 @@
+*
+!.gitignore
\ No newline at end of file
diff --git a/benchmark/normalize_dataset.py b/benchmark/normalize_dataset.py
new file mode 100644
index 0000000..2049f5e
--- /dev/null
+++ b/benchmark/normalize_dataset.py
@@ -0,0 +1,84 @@
+import argparse
+import os
+import time
+from typing import Dict, List
+import json
+import dotenv
+import pandas as pd
+import requests
+from tqdm import tqdm
+from pydantic import BaseModel
+
+dotenv.load_dotenv(override=True)
+
+HEADER = {
+    "Authorization": f"token {os.getenv('GITHUB_TOKEN')}",
+    "Accept": "application/vnd.github.v3+json",
+}
+
+class Repository(BaseModel):
+    username: str
+    repo: str
+    __hash__ = object.__hash__
+
+def check_candidate_exist(lst_candidate: List[Repository]) -> Dict[Repository, bool]:
+    result = {}
+    for i, candidate in tqdm(
+        enumerate(lst_candidate), total=len(lst_candidate), desc="Querying"
+    ):
+        try:
+            url = f"https://api.github.com/repos/{candidate.username}/{candidate.repo}"
+            response = requests.get(url, headers=HEADER)
+            if response.status_code == 404:
+                result[lst_candidate[i]] = False
+            elif response.status_code == 200:
+                result[lst_candidate[i]] = True
+            else:
+                print(response.status_code)
+                print(response.text)
+        except Exception as e:
+            print(candidate)
+            print(e)
+            print("-" * 100)
+        time.sleep(0.72)
+    return result
+
+
+def repo_to_encode(repo: str, list_candidate_filter: List[Repository]) -> str:
+    commit = repo.split("-")[-1]
+    origin = "-".join(repo.split("-")[:-1])
+    for candidate in list_candidate_filter:
+        if origin == candidate.username + "-" + candidate.repo:
+            encode = candidate.username + "--" + candidate.repo + "--" + commit
+            return encode
+    raise ValueError(f"There is no candidate satisfy for repo {repo}")
+
+
+def main(args):
+    df = pd.read_json(args.input, lines=True)
+    df["repo"] = df["metadata"].apply(lambda x: x["repository"])
+    df["commit"] = df["repo"].apply(lambda name: name.split("-")[-1])
+    lst_candidate = []
+    lst_repo = df["repo"].unique()
+    for repo in lst_repo:
+        lst = repo.split("-")[:-1]
+        for i in range(0, len(lst) - 1):
+            username = "-".join(lst[: i + 1])
+            repo = "-".join(lst[i + 1 :])
+            lst_candidate.append(Repository(username=username, repo=repo))
+    lst_candidate = check_candidate_exist(lst_candidate)
+    lst_candidate_filter = [
+        candidate for candidate, exist in lst_candidate.items() if exist
+    ]
+    with open("log/list_repository.json", "w") as f:
+        json.dump([candidate.dict() for candidate in lst_candidate_filter], f)
+    df["encode"] = df["repo"].apply(lambda x: repo_to_encode(x, lst_candidate_filter))
+    df.to_json(args.output, orient="records", lines=True)
+
+
+if __name__ == "__main__":
+    parser = argparse.ArgumentParser()
+    parser.add_argument("-i", "--input", dest="input")
+    parser.add_argument("-o", "--output", dest="output")
+    args = parser.parse_args()
+    main(args)
\ No newline at end of file
diff --git a/benchmark/output/.gitignore b/benchmark/output/.gitignore
new file mode 100644
index 0000000..c96a04f
--- /dev/null
+++ b/benchmark/output/.gitignore
@@ -0,0 +1,2 @@
+*
+!.gitignore
\ No newline at end of file
diff --git a/benchmark/parse_project.py b/benchmark/parse_project.py
new file mode 100644
index 0000000..7248d89
--- /dev/null
+++ b/benchmark/parse_project.py
@@ -0,0 +1,232 @@
+#   Author: masterSunflowers
+#   Github: https://github.com/masterSunflowers/masterSunflowers
+#   Date:   25/11/2024
+#   Desc:   This file aims to parse a Java project and extract relevant information (class, method)
+import argparse
+import json
+import os
+
+import tree_sitter
+import tree_sitter_java as tsjava
+from tqdm import tqdm
+
+JAVA = tree_sitter.Language(tsjava.language())
+PARSER = tree_sitter.Parser(JAVA)
+
+
+def normalize_code(code: str):
+    lines_of_code = code.splitlines()
+    redundant_space = len(lines_of_code[-1]) - 1
+    for i in range(1, len(lines_of_code)):
+        lines_of_code[i] = lines_of_code[i][redundant_space:]
+    return "\n".join(lines_of_code)
+
+
+def get_class_node_path(root_node: tree_sitter.Node, node: tree_sitter.Node):
+    path = [node.child_by_field_name("name").text.decode("utf-8")]
+    cur_node = node
+    while cur_node.parent and cur_node.parent != root_node:
+        cur_node = cur_node.parent
+        if cur_node.type == "class_declaration":
+            path.append(
+                cur_node.child_by_field_name("name").text.decode("utf-8")
+            )
+    return ".".join(reversed(path))
+
+
+def parse_java_files(directory: str):
+    for root, _, files in os.walk(directory):
+        for file in files:
+            if file.endswith(".java"):
+                file_path = os.path.join(root, file)
+                with open(file_path, "r", encoding="utf-8") as f:
+                    code = f.read()
+                    tree = PARSER.parse(bytes(code, "utf-8"))
+                    yield file_path, tree
+
+
+def get_definitions(file_path: str, tree: tree_sitter.Tree):
+    root_node = tree.root_node
+    lst_class_info = []
+    lst_method_info = []
+    package_name = None
+
+    # Get package of file
+    for node in root_node.children:
+        if node.type == "package_declaration":
+            package_name = node.text.decode("utf-8")
+
+    # Traverse root node children recursively to get class and method definitions
+    stack = []
+    for child in root_node.children:
+        if child.type == "class_declaration":
+            stack.append(child)
+    while stack:
+        node = stack.pop(0)
+        if node.type == "class_declaration":
+            tree_path = get_class_node_path(root_node, node)
+            class_info = {
+                "file_path": file_path,
+                "definition": normalize_code(node.text.decode("utf-8")),
+                "package": package_name,
+                "tree_path": tree_path,
+                "name": None,
+                "modifiers": None,
+                "superclass": None,
+                "super_interfaces": None,
+                "body": None,
+            }
+            class_body = None
+
+            for child in node.named_children:
+                if child.type == "identifier":
+                    class_info["name"] = child.text.decode("utf-8")
+                elif child.type == "modifiers":
+                    class_info["modifiers"] = child.text.decode("utf-8")
+                elif child.type == "superclass":
+                    class_info["superclass"] = child.text.decode("utf-8")
+                elif child.type == "super_interfaces":
+                    class_info["super_interfaces"] = child.text.decode("utf-8")
+                elif child.type == "class_body":
+                    class_info["body"] = normalize_code(
+                        child.text.decode("utf-8")
+                    )
+                    class_body = child
+
+            lst_class_info.append(class_info)
+            if class_body:
+                for child in class_body.named_children:
+                    if child.type == "method_declaration":
+                        method_info = {
+                            "file_path": file_path,
+                            "definition": normalize_code(
+                                child.text.decode("utf-8")
+                            ),
+                            "package": package_name,
+                            "tree_path": tree_path,
+                            "name": None,
+                            "modifiers": None,
+                            "return_type": None,
+                            "parameters": [],
+                            "body": None,
+                        }
+                        for c in child.named_children:
+                            if c.type == "modifiers":
+                                method_info["modifiers"] = c.text.decode(
+                                    "utf-8"
+                                )
+                            elif c.type == "type_identifier":
+                                method_info["return_type"] = c.text.decode(
+                                    "utf-8"
+                                )
+                            elif c.type == "identifier":
+                                method_info["name"] = c.text.decode("utf-8")
+                                method_info["tree_path"] = (
+                                    method_info["tree_path"]
+                                    + ":"
+                                    + method_info["name"]
+                                )
+                            elif c.type == "formal_parameters":
+                                for param in c.named_children:
+                                    if param.type == "formal_parameter":
+                                        param_type = param.named_children[
+                                            0
+                                        ].text.decode("utf-8")
+                                        param_name = param.named_children[
+                                            1
+                                        ].text.decode("utf-8")
+                                        method_info["parameters"].append(
+                                            {
+                                                "type": param_type,
+                                                "name": param_name,
+                                            }
+                                        )
+                            elif c.type == "block":
+                                method_info["body"] = normalize_code(
+                                    c.text.decode("utf-8")
+                                )
+                        lst_method_info.append(method_info)
+                    elif child.type == "class_declaration":
+                        stack.append(child)
+                    elif child.type == "constructor_declaration":
+                        constructor_info = {
+                            "file_path": file_path,
+                            "definition": normalize_code(
+                                child.text.decode("utf-8")
+                            ),
+                            "package": package_name,
+                            "tree_path": tree_path,
+                            "name": None,
+                            "modifiers": None,
+                            "parameters": [],
+                            "body": None,
+                            "constructor": True,
+                        }
+                        for c in child.named_children:
+                            if c.type == "modifiers":
+                                constructor_info["modifiers"] = c.text.decode(
+                                    "utf-8"
+                                )
+                            elif c.type == "identifier":
+                                constructor_info["name"] = c.text.decode(
+                                    "utf-8"
+                                )
+                                constructor_info["tree_path"] = (
+                                    constructor_info["tree_path"]
+                                    + ":"
+                                    + constructor_info["name"]
+                                )
+                            elif c.type == "formal_parameters":
+                                for param in c.named_children:
+                                    if param.type == "formal_parameter":
+                                        param_type = param.named_children[
+                                            0
+                                        ].text.decode("utf-8")
+                                        param_name = param.named_children[
+                                            1
+                                        ].text.decode("utf-8")
+                                        constructor_info["parameters"].append(
+                                            {
+                                                "type": param_type,
+                                                "name": param_name,
+                                            }
+                                        )
+                            elif c.type == "constructor_body":
+                                constructor_info["body"] = normalize_code(
+                                    c.text.decode("utf-8")
+                                )
+                        lst_method_info.append(constructor_info)
+    return lst_class_info, lst_method_info
+
+
+def main(args):
+    lst_repo = os.listdir(args.repos_dir)
+    print(lst_repo)
+    for repo in tqdm(lst_repo):
+        repo_dir = os.path.join(args.repos_dir, repo)
+        all_class = []
+        all_method = []
+        for file_path, tree in parse_java_files(repo_dir):
+            rev_path = os.path.relpath(file_path, repo_dir)
+            lst_class_info, lst_method_info = get_definitions(rev_path, tree)
+            all_class.extend(lst_class_info)
+            all_method.extend(lst_method_info)
+        if not os.path.exists(os.path.join(args.output_dir, repo)):
+            os.makedirs(os.path.join(args.output_dir, repo))
+        with open(
+            os.path.join(args.output_dir, repo, "class_info.json"), "w"
+        ) as f:
+            json.dump(all_class, f, indent=4)
+        with open(
+            os.path.join(args.output_dir, repo, "method_info.json"), "w"
+        ) as f:
+            json.dump(all_method, f, indent=4)
+
+
+if __name__ == "__main__":
+    parser = argparse.ArgumentParser()
+    parser.add_argument("--repos-dir", dest="repos_dir")
+    parser.add_argument("--output-dir", dest="output_dir")
+    args = parser.parse_args()
+
+    main(args)
\ No newline at end of file
diff --git a/benchmark/prompt.py b/benchmark/prompt.py
new file mode 100644
index 0000000..52db54b
--- /dev/null
+++ b/benchmark/prompt.py
@@ -0,0 +1,123 @@
+from openai import OpenAI
+from tqdm import tqdm
+import dotenv
+import os
+import concurrent.futures
+from typing import List
+import requests
+import time
+
+END_OF_LINE = {"python": [], "java": [";"]}
+
+dotenv.load_dotenv(override=True)
+
+
+def filter_new_line(string):
+    new_line_index = string.find("\n")
+    if new_line_index == -1:
+        return string
+    else:
+        return string[:new_line_index]
+
+
+def deepseek_coder(prefix: str, suffix: str):
+    try:
+        client = OpenAI(
+            api_key=os.getenv("DEEPSEEK_API"),
+            base_url="https://api.deepseek.com/beta/",
+        )
+
+        response = client.completions.create(
+            model="deepseek-coder",
+            prompt=prefix,
+            suffix=suffix,
+            max_tokens=2048,
+            temperature=0.01,
+            stop=[
+                "<｜fim▁begin｜>",
+                "<｜fim▁hole｜>",
+                "<｜fim▁end｜>",
+                "//",
+                "<｜end▁of▁sentence｜>",
+                "\n\n",
+                "\r\n\r\n",
+                "/src/",
+                "#- coding: utf-8",
+                "```",
+                "\nclass",
+                "\nfunction",
+            ],
+        )
+        code = response.choices[0].text
+        if not code:
+            return ""
+        return filter_new_line(code)
+    except Exception as e:
+        print(e)
+        return None
+
+
+def costral_latest(prefix: str, suffix: str):
+    try:
+        time.sleep(0.5)
+        body = {
+            "prompt": prefix,
+            "suffix": suffix,
+            "model": "codestral-latest",
+            "max_tokens": 2048,
+            "temperature": 0.01,
+            "stop": [
+                "[PREFIX]",
+                "[SUFFIX]",
+                "\n\n",
+                "\r\n\r\n",
+                "/src/",
+                "#- coding: utf-8",
+                "```",
+                "\nclass",
+                "\nfunction",
+            ],
+        }
+        headers = {
+            "Content-Type": "application/json",
+            "Accept": "application/json",
+            "Authorization": f"Bearer {os.getenv('CODESTRAL_API')}",
+        }
+        url = "https://codestral.mistral.ai/v1/fim/completions"
+        response = requests.post(url=url, json=body, headers=headers)
+        code = response.json()["choices"][0]["message"]["content"]
+        if not code:
+            return ""
+        return filter_new_line(code)
+    except Exception as e:
+        print(e)
+        return None
+
+    
+def get_response(prefix: str, suffix: str, model: str):
+    match model:
+        case "deepseek-coder":
+            return deepseek_coder(prefix, suffix)
+        case "codestral-latest":
+            return costral_latest(prefix, suffix)
+        case _:
+            raise NotImplementedError(f"Model {model} not implemented")
+
+def prompt(prefixes: List[str], suffixes: List[str], model: str):
+    responses = {}
+    with concurrent.futures.ProcessPoolExecutor(max_workers=3) as executor:
+        futures = {
+            executor.submit(get_response, prefix, suffix, model): idx
+            for idx, (prefix, suffix) in enumerate(zip(prefixes, suffixes))
+        }
+        for future in tqdm(
+            concurrent.futures.as_completed(futures), total=len(futures)
+        ):
+            idx = futures[future]
+            code = future.result()
+            print(idx)
+            print(code)
+            print("=" * 100)
+            responses[idx] = code
+    responses = [responses[idx] for idx in range(len(responses))]
+    return responses
diff --git a/benchmark/prompt_builder.py b/benchmark/prompt_builder.py
new file mode 100644
index 0000000..8aecc60
--- /dev/null
+++ b/benchmark/prompt_builder.py
@@ -0,0 +1,180 @@
+import argparse
+import os
+import sys
+
+from tqdm import tqdm
+
+sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
+import logging
+from typing import List, Optional, Dict, Any
+
+import pandas as pd
+from multilspy.language_server import SyncLanguageServer
+from multilspy.multilspy_config import MultilspyConfig
+from multilspy.multilspy_logger import MultilspyLogger
+from pydantic import BaseModel
+from tree_sitter import Point
+
+from continue_dev.helper import Helper
+from continue_dev.utils import construct_autocomplete_prompt, render_prompt
+
+multilspy_logger = MultilspyLogger()
+logger = logging.Logger(name="prompt_builder", level=logging.DEBUG)
+logger.addHandler(logging.FileHandler(filename="log/prompt_builder.log"))
+
+class BuilderOutput(BaseModel):
+    model_name: str
+    built_prompt: Optional[str]
+    lsp_snippets: Optional[List[Any]]
+    import_snippets: Optional[List[Any]]
+    root_path_context_snippets: Optional[List[Any]]
+    prefix: Optional[str]
+    suffix: Optional[str]
+    completion_options: Optional[Dict[str, List[str]]]
+
+
+class PromptBuilder:
+    def __init__(
+        self,
+        dataset_jsonl_path: str,
+        repos_storage: str,
+        output_path: str,
+        log_path: str,
+        language: str,
+        model_name: str,
+        log_steps: int = 1,
+    ):
+        self.df = pd.read_json(dataset_jsonl_path, lines=True)
+        # self.df["condition"] = self.df["metadata"].apply(lambda x: x["task_id"] == "project_cc_python/207")
+        # self.df = self.df[self.df["condition"]]
+        self.df = self.df[35:36]
+        self.repos_storage = repos_storage
+        self.output_path = output_path
+        self.log_path = log_path
+        self.log_steps = log_steps
+        self.language = language
+        self.model_name = model_name
+
+    def setup_test_state(self, test_case):
+        root_path = os.path.join(self.repos_storage, test_case["encode"])
+        file_path = os.path.join(root_path, test_case["metadata"]["file"])
+        with open(file_path, "r") as f:
+            orig_file_content = f.read()
+
+        new_file_content = test_case["prompt"] + test_case["right_context"]
+        with open(file_path, "w") as f:
+            f.write(new_file_content)
+        row = len(test_case["prompt"].splitlines()) - 1
+        col = len(test_case["prompt"].splitlines()[-1])
+        cursor_index = Point(row=row, column=col)
+
+        config = MultilspyConfig.from_dict({"code_language": self.language})
+        language_server = SyncLanguageServer.create(
+            config, multilspy_logger, repository_root_path=root_path
+        )
+        return file_path, orig_file_content, cursor_index, language_server
+
+    def build_prompt(self):
+        outputs = []
+        for idx, row in tqdm(
+            self.df.iterrows(), total=len(self.df), desc="Building prompt"
+        ):
+            file_path, orig_file_content, cursor_index, language_server = (
+                self.setup_test_state(row)
+            )
+            try:
+                helper = Helper(
+                    repo_dir=os.path.join(self.repos_storage, row["encode"]),
+                    relative_path=row["metadata"]["file"],
+                    cursor_index=cursor_index,
+                    language_server=language_server,
+                    language=self.language,
+                    model_name=self.model_name,
+                )
+                print("Helper is ready")
+                print(row["encode"])
+
+                with helper.language_server.start_server():
+                    print("Init server success!!!")
+                    (
+                        lsp_snippets,
+                        import_snippets,
+                        root_path_context_snippets,
+                        snippets,
+                    ) = construct_autocomplete_prompt(helper)
+                    prompt, prefix, suffix, completion_options = render_prompt(
+                        snippets, helper
+                    )
+                    if prompt is None:
+                        logger.warning(f"Encounter outlier at index {idx}")
+                    outputs.append(
+                        BuilderOutput(
+                            model_name=self.model_name,
+                            built_prompt=prompt,
+                            lsp_snippets=lsp_snippets,
+                            import_snippets=import_snippets,
+                            root_path_context_snippets=root_path_context_snippets,
+                            prefix=prefix,
+                            suffix=suffix,
+                            completion_options=completion_options,
+                        )
+                    )
+            except Exception as e:
+                logger.error(f"Error occurs when handling {idx}")
+                logger.error(str(e))
+                logger.error("=" * 100)
+                outputs.append(
+                    BuilderOutput(
+                        model_name=self.model_name,
+                        built_prompt=None,
+                        lsp_snippets=None,
+                        import_snippets=None,
+                        root_path_context_snippets=None,
+                        prefix=None,
+                        suffix=None,
+                        completion_options=None,
+                    )
+                )
+            finally:
+                with open(file_path, "w") as f:
+                    f.write(orig_file_content)
+            if len(outputs) % self.log_steps == 0:
+                self.store_df(outputs, self.log_path)
+
+        self.store_df(outputs, self.output_path)
+
+    def store_df(self, updates, path):
+        df = self.df.copy()[: len(updates)]
+        df.reset_index(drop=True, inplace=True)
+        additional_col = pd.DataFrame([item.dict() for item in updates])
+        df = pd.concat([df, additional_col], axis=1)
+        dir_path = os.path.dirname(path)
+        if not os.path.exists(dir_path):
+            os.makedirs(dir_path, exist_ok=True)
+        df.to_json(path, orient="records", lines=True)
+
+
+def main(args):
+    prompt_builder = PromptBuilder(
+        dataset_jsonl_path=args.input_path,
+        repos_storage=args.repos_storage,
+        output_path=args.output_path,
+        log_path=args.log_path,
+        language=args.language,
+        model_name=args.model_name,
+        log_steps=args.log_steps
+    )
+    prompt_builder.build_prompt()
+
+
+if __name__ == "__main__":
+    parser = argparse.ArgumentParser()
+    parser.add_argument("-i", "--input", dest="input_path")
+    parser.add_argument("-r", "--repo-storage", dest="repos_storage")
+    parser.add_argument("-o", "--output", dest="output_path")
+    parser.add_argument("-l", "--log", dest="log_path")
+    parser.add_argument("-m", "--model", dest="model_name")
+    parser.add_argument("-lang", "--language", dest="language", default="java")
+    parser.add_argument("-lg", "--log-steps", dest="log_steps", type=int, default=1)
+    args = parser.parse_args()
+    main(args)
diff --git a/benchmark/python_repos/.gitignore b/benchmark/python_repos/.gitignore
new file mode 100644
index 0000000..c96a04f
--- /dev/null
+++ b/benchmark/python_repos/.gitignore
@@ -0,0 +1,2 @@
+*
+!.gitignore
\ No newline at end of file
diff --git a/benchmark/python_repos_tmp/.gitignore b/benchmark/python_repos_tmp/.gitignore
new file mode 100644
index 0000000..c96a04f
--- /dev/null
+++ b/benchmark/python_repos_tmp/.gitignore
@@ -0,0 +1,2 @@
+*
+!.gitignore
\ No newline at end of file
diff --git a/benchmark/requirements.txt b/benchmark/requirements.txt
new file mode 100644
index 0000000..f546202
--- /dev/null
+++ b/benchmark/requirements.txt
@@ -0,0 +1,121 @@
+aiohappyeyeballs==2.4.4
+aiohttp==3.11.10
+aiosignal==1.3.1
+anyio==4.7.0
+asttokens==2.4.1
+attrs==24.2.0
+beautifulsoup4==4.12.3
+bidict==0.23.1
+bleach==6.2.0
+cattrs==24.1.2
+certifi==2024.8.30
+charset-normalizer==3.4.0
+comm==0.2.2
+debugpy==1.6.7
+decorator==5.1.1
+defusedxml==0.7.1
+distro==1.9.0
+docstring-to-markdown==0.15
+exceptiongroup==1.2.2
+executing==2.1.0
+fastjsonschema==2.21.1
+filelock==3.16.1
+frozenlist==1.5.0
+fsspec==2024.10.0
+fuzzywuzzy==0.18.0
+h11==0.14.0
+httpcore==1.0.7
+httpx==0.28.1
+huggingface-hub==0.26.3
+idna==3.10
+importlib_metadata==8.5.0
+iniconfig==2.0.0
+ipykernel==6.29.5
+ipython==8.28.0
+jedi==0.19.1
+jedi-language-server==0.41.1
+Jinja2==3.1.4
+jiter==0.8.2
+joblib==1.4.2
+jsonrpcserver==5.0.9
+jsonschema==4.23.0
+jsonschema-specifications==2024.10.1
+jupyter_client==8.6.3
+jupyter_core==5.7.2
+jupyterlab_pygments==0.3.0
+Levenshtein==0.26.1
+lsprotocol==2023.0.1
+MarkupSafe==3.0.2
+matplotlib-inline==0.1.7
+mistune==3.0.2
+multidict==6.1.0
+multilspy==0.0.1
+nbclient==0.10.1
+nbconvert==7.16.4
+nbformat==5.10.4
+nest_asyncio==1.6.0
+numpy==2.1.2
+openai==1.57.4
+OSlash==0.6.3
+packaging==24.1
+pandas==2.2.3
+pandocfilters==1.5.1
+parso==0.8.4
+pexpect==4.9.0
+pickleshare==0.7.5
+pip==24.2
+platformdirs==4.3.6
+pluggy==1.5.0
+prompt_toolkit==3.0.48
+propcache==0.2.1
+protobuf==5.29.1
+psutil==5.9.0
+ptyprocess==0.7.0
+pure_eval==0.2.3
+pydantic==1.10.5
+pygls==1.3.1
+Pygments==2.18.0
+pytest==8.3.4
+pytest-asyncio==0.24.0
+python-dateutil==2.9.0
+python-dotenv==1.0.1
+python-engineio==4.10.1
+python-Levenshtein==0.26.1
+python-lsp-jsonrpc==1.1.2
+python-lsp-server==1.12.0
+python-socketio==5.11.4
+pytz==2024.2
+PyYAML==6.0.2
+pyzmq==25.1.2
+RapidFuzz==3.11.0
+referencing==0.35.1
+regex==2024.11.6
+requests==2.32.3
+rpds-py==0.22.3
+safetensors==0.4.5
+setuptools==75.1.0
+simple-websocket==1.1.0
+six==1.16.0
+sniffio==1.3.1
+soupsieve==2.6
+stack-data==0.6.2
+tinycss2==1.4.0
+tokenizers==0.20.3
+tornado==6.4.1
+tqdm==4.66.5
+traitlets==5.14.3
+transformers==4.46.3
+tree-sitter==0.23.2
+tree-sitter-java==0.23.2
+tree-sitter-python==0.23.2
+typing_extensions==4.12.2
+tzdata==2024.2
+ujson==5.10.0
+urllib3==2.2.3
+wcwidth==0.2.13
+webencodings==0.5.1
+websockets==14.1
+wheel==0.44.0
+wsproto==1.2.0
+yarl==1.18.3
+zipp==3.20.2
diff --git a/benchmark/script.sh b/benchmark/script.sh
new file mode 100644
index 0000000..93b6700
--- /dev/null
+++ b/benchmark/script.sh
@@ -0,0 +1,9 @@
+# prompt_builder.py
+python prompt_builder.py \
+    -i data/java_sampled.jsonl \
+    -r /home/lvdthieu/Documents/Projects/benchmark_continue/java_repos_tmp \
+    -o dev/test.jsonl \
+    -l dev/log.jsonl \
+    -m deepseek-coder \
+    -lang java \
+    -lg 1
\ No newline at end of file
diff --git a/benchmark/setup_repo_state.py b/benchmark/setup_repo_state.py
new file mode 100644
index 0000000..ba2f57a
--- /dev/null
+++ b/benchmark/setup_repo_state.py
@@ -0,0 +1,48 @@
+#   Author: masterSunflowers
+#   Github: https://github.com/masterSunflowers/masterSunflowers
+#   Date:   01/11/2024
+#   Desc:   This file aim to set all repositories that have cloned to specific 
+#           commit as in CrossCodeEval benchmark
+
+import argparse
+import logging
+import os
+import subprocess
+
+import pandas as pd
+from tqdm import tqdm
+
+CWD = os.path.abspath(os.path.dirname(__file__))
+
+logger = logging.Logger("setup_commit", level=logging.INFO)
+logger.addHandler(
+    logging.FileHandler(os.path.join(CWD, "log", "setup_commit.log"))
+)
+
+
+def main(args):
+    save_dir = os.path.join(args.data_storage)
+    df = pd.read_json(args.input, lines=True)
+    df.drop_duplicates(subset=["encode"], ignore_index=True, inplace=True)
+    for _, row in tqdm(df.iterrows(), total=len(df), desc="Setup repo state"):
+        encode = row["encode"]
+        _, _, commit = encode.split("--")
+        cmd = (
+            f"cd {os.path.join(save_dir, encode)} && git reset --hard {commit}"
+        )
+        res = subprocess.run(cmd, shell=True, capture_output=True, text=True)
+        if res.returncode == 0:
+            logger.info(f"Setup state for {encode} successfully!")
+            logger.info(f"Output:\n{res.stdout}\n")
+            logger.info("-" * 100)
+        else:
+            logger.error(f"Error when setup state for {encode}")
+            logger.info("-" * 100)
+
+
+if __name__ == "__main__":
+    parser = argparse.ArgumentParser()
+    parser.add_argument("-i", "--input", dest="input")
+    parser.add_argument("-s", "--data-storage", dest="data_storage")
+    args = parser.parse_args()
+    main(args)
\ No newline at end of file
diff --git a/benchmark/test.py b/benchmark/test.py
new file mode 100644
index 0000000..3cefa9c
--- /dev/null
+++ b/benchmark/test.py
@@ -0,0 +1,42 @@
+import pandas as pd
+from eval import cal_edit_sim, cal_exactly_match
+# df = pd.read_json("data/python_dataset_cleaned.jsonl", lines=True)
+# print(df.info())
+df = pd.read_json("output/python_sampled_deepseek.jsonl", lines=True)
+print(df.info())
+references = df["groundtruth"].tolist()
+preds = df["response"].fillna("").tolist()
+em = cal_exactly_match(references, preds)
+edit_sim = cal_edit_sim(references, preds)
+print("==========RESULT==========")
+print("EM:", "{:.2f}".format(em))
+print("ES:", "{:.2f}".format(edit_sim))
+print("==========================")
+# for _, row in log0.iterrows():
+#     for col in ["lsp_snippets", "import_snippets", "root_path_context_snippets"]:
+#         if len(row[col]) > 0:
+#             print(col)
+# log1 = pd.read_json("log/java_sampled_prompt1.jsonl", lines=True)
+#
+# total = pd.concat([log0, log1], axis=0)
+# total.info()
+# total.reset_index(drop=True, inplace=True)
+# # from pprint import pprint
+# # pprint(total[total["built_prompt"].isnull()].index)
+# # pprint(dict(total.loc[126]))
+# # print("=" * 100)
+# # pprint(dict(total.loc[304]))
+# error = total[total["built_prompt"].isnull()]
+# error.dropna(axis="columns", inplace=True, how="any")
+# error.drop(columns=["model_name"], inplace=True)
+# error.to_json("error.jsonl", orient="records", lines=True)
+# done = total[~total["built_prompt"].isnull()]
+# done.to_json("done.jsonl", orient="records", lines=True)
+
+# done = pd.read_json("done.jsonl", lines=True)
+# error = pd.read_json("error_prompt.jsonl", lines=True)
+#
+# complete = pd.concat([done, error], axis=0)
+# complete.reset_index(drop=True, inplace=True)
+# complete.info()
+# complete.to_json("output/java_sampled_prompt.jsonl", orient="records", lines=True)
\ No newline at end of file
diff --git a/benchmark/test/test_get_def.py b/benchmark/test/test_get_def.py
new file mode 100644
index 0000000..f6deb4c
--- /dev/null
+++ b/benchmark/test/test_get_def.py
@@ -0,0 +1,30 @@
+import pandas as pd
+import os
+import sys
+import tree_sitter
+sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))
+from continue_dev.lsp_service import LSPService
+
+
+# df = pd.read_json("data/dataset_cleaned.jsonl", lines=True)
+
+# sample = dict(df.loc[30])
+# repos_storage = os.path.abspath(os.path.join(os.path.dirname(__file__), "..", "github_repos_tmp"))
+# print(df.loc[40, "prompt"])
+# for col in df.columns:
+#     print(df.loc[30, col])
+lsp = LSPService(repo_dir="/home/lvdthieu/Documents/Projects/continue/manual-testing-sandbox", language="java")
+
+# cursor_row = len(sample["prompt"].splitlines()) - 1
+# cursor_col = len(sample["prompt"].splitlines()[-1])
+
+with open("/home/lvdthieu/Documents/Projects/continue/manual-testing-sandbox/thieulvd/test/Calculator.java", "r") as f:
+    content = f.read()
+    
+print(lsp.get_definition_from_lsp(
+    rev_file_path="thieulvd/test/Calculator.java",
+    content=content,
+    cursor_index=tree_sitter.Point(row=21, column=28)
+))
+
+
diff --git a/benchmark/test/test_indexing.py b/benchmark/test/test_indexing.py
new file mode 100644
index 0000000..d771c86
--- /dev/null
+++ b/benchmark/test/test_indexing.py
@@ -0,0 +1,11 @@
+# from transformers import LlamaTokenizer
+# import sqlite3
+
+# conn = sqlite3.connect("/home/lvdthieu/.continue/index/index.sqlite")
+# cur = conn.cursor()
+
+# tokenizer = LlamaTokenizer.from_pretrained("meta-llama/Llama-2-7b-chat-hf")
+
+# res = cur.execute("SELECT content FROM chunks WHERE INSTR(path, '/home/lvdthieu/Documents/Projects/UET-thesis') > 0").fetchall()
+# for r in res:
+#     print(len(tokenizer.tokenize(r[0])))
diff --git a/benchmark/test/test_lsp.py b/benchmark/test/test_lsp.py
new file mode 100644
index 0000000..d50eba4
--- /dev/null
+++ b/benchmark/test/test_lsp.py
@@ -0,0 +1,25 @@
+import logging
+import time
+
+from multilspy import SyncLanguageServer
+from multilspy.multilspy_config import MultilspyConfig
+from multilspy.multilspy_logger import MultilspyLogger
+
+# logging.basicConfig(level=logging.DEBUG)
+config = MultilspyConfig.from_dict({"code_language": "java"})
+logger = MultilspyLogger()
+lsp = SyncLanguageServer.create(
+    config,
+    logger,
+    "/home/lvdthieu/Documents/Projects/benchmark_continue/java_repos_tmp/1754048656--FATJS--4b1e065",
+)
+start = time.time()
+with lsp.start_server():
+    started_server_time = time.time()
+    print("Time to start server", started_server_time - start, "s")
+    x = lsp.request_definition(
+        file_path="app/src/main/java/com/linsheng/FATJS/rpa/dingdingService/DingDingService.java",
+        line=65,
+        column=23,
+    )
+    print(x)
diff --git a/benchmark/test/test_tokenizer.py b/benchmark/test/test_tokenizer.py
new file mode 100644
index 0000000..118c467
--- /dev/null
+++ b/benchmark/test/test_tokenizer.py
@@ -0,0 +1,92 @@
+from transformers import LlamaTokenizerFast, AutoTokenizer
+
+code = """/*
+ * Copyright (c) 2022, Harald Kuhr
+ * All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are met:
+ *
+ * * Redistributions of source code must retain the above copyright notice,
+ *   this list of conditions and the following disclaimer.
+ *
+ * * Redistributions in binary form must reproduce the above copyright notice,
+ *   this list of conditions and the following disclaimer in the documentation
+ *   and/or other materials provided with the distribution.
+ *
+ * * Neither the name of the copyright holder nor the names of its
+ *   contributors may be used to endorse or promote products derived from
+ *   this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""
+ * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE
+ * LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+ * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+ * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+ * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+ * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
+ * POSSIBILITY OF SUCH DAMAGE.
+ */
+
+package net.burningtnt.webp.vp8l.huffman;
+
+import net.burningtnt.webp.utils.LSBBitInputStream;
+
+import java.io.IOException;
+import java.util.ArrayList;
+import java.util.Arrays;
+import java.util.List;
+
+/**
+ * Represents a single huffman tree as a table.
+ * <p>
+ * Decoding a symbol just involves reading bits from the input stream and using that read value to index into the
+ * lookup table.
+ * <p>
+ * Code length and the corresponding symbol are packed into one array element (int).
+ * This is done to avoid the overhead and the fragmentation over the whole heap involved with creating objects
+ * of a custom class. The upper 16 bits of each element are the code length and lower 16 bits are the symbol.
+ * <p>
+ * The max allowed code length by the WEBP specification is 15, therefore this would mean the table needs to have
+ * 2^15 elements. To keep a reasonable memory usage, instead the lookup table only directly holds symbols with code
+ * length up to {@code LEVEL1_BITS} (Currently 8 bits). For longer codes the lookup table stores a reference to a
+ * second level lookup table. This reference consists of an element with length as the max length of the level 2
+ * table and value as the index of the table in the list of level 2 tables.
+ * <p>
+ * Reading bits from the input is done in a least significant bit first way (LSB) way, therefore the prefix of the
+ * read value of length i is the lowest i bits in inverse order.
+ * The lookup table is directly indexed by the {@code LEVEL1_BITS} next bits read from the input (i.e. the bits
+ * corresponding to next code are inverse suffix of the read value/index).
+ * So for a code length of l all values with the lowest l bits the same need to decode to the same symbol
+ * regardless of the {@code (LEVEL1_BITS - l)} higher bits. So the lookup table needs to have the entry of this symbol
+ * repeated every 2^(l + 1) spots starting from the bitwise inverse of the code.
+ *
+ * @author Simon Kammermeier
+ */
+public final class HuffmanTable {
+    private static final int LEVEL1_BITS = 8;
+    /**
+     * Symbols of the L-code in the order they need to be read
+     */
+    private static final int[] L_CODE_ORDER = {17, 18, 0, 1, 2, 3, 4, 5, 16, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15};
+    private final int[] level1 = new int[1 << LEVEL1_BITS];
+    private final List<int[]> level2 = new ArrayList<>();
+
+    /**
+     * Build a Huffman table by reading the encoded symbol lengths from the reader
+     *
+     * @param lsbBitReader the reader to read from
+     * @param alphabetSize the number of symbols in the alphabet to be decoded by this huffman table
+     * @throws IOException when reading produces an exception
+     */
+    public HuffmanTable(LSBBitInputStream lsbBitReader, int alphabetSize) throws IOException {
+        boolean"""
+
+deepseek_tokenizer = AutoTokenizer.from_pretrained("deepseek-ai/deepseek-coder-6.7b-base")
+llama_tokenizer = LlamaTokenizerFast.from_pretrained("hf-internal-testing/llama-tokenizer")
+
+print(len(deepseek_tokenizer(code)["input_ids"]))
+print(len(llama_tokenizer(code)["input_ids"]))
\ No newline at end of file
diff --git a/benchmark/test/test_tree_sitter.py b/benchmark/test/test_tree_sitter.py
new file mode 100644
index 0000000..2e05637
--- /dev/null
+++ b/benchmark/test/test_tree_sitter.py
@@ -0,0 +1,68 @@
+import os
+import sys
+import tree_sitter
+import tree_sitter_java as tsjava
+import pandas as pd
+
+sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))
+JAVA = tree_sitter.Language(tsjava.language()) 
+CWD = os.path.abspath(os.path.dirname(__file__))
+df = pd.read_json(os.path.join(CWD, "..", "data", "dataset_cleaned.jsonl"), lines=True)
+
+
+def get_abs_path(repo_dir: str, repo_encode: str, rev_path: str):
+    return os.path.join(repo_dir, repo_encode, rev_path)
+
+
+file_path = get_abs_path(
+    os.path.join(CWD, "..", "github_repos_tmp"),
+    df.loc[0, "encode"],
+    df.loc[0]["metadata"]["file"],
+)
+
+file_path = "/home/lvdthieu/Documents/Projects/benchmark_continue/github_repos_tmp/akang943578--java-bard-api--7352c25/src/main/java/com/api/bard/BardClient.java"
+# file_path = "/home/lvdthieu/Documents/Projects/benchmark_continue/github_repos_tmp/AADevelops--JaGame--fc2ae51/jagame/GraphicsPanel.java"
+with open(file_path, "r") as f:
+    file_content = f.read()
+
+parser = tree_sitter.Parser(language=JAVA)
+file_content = """class LowercaseStringProperty{\n\tpublic LowercaseStringProperty(final String jsonName, final String dbName, final PropertyValidator<String>... validators)
+ {\n\n\tsuper(jsonName);\n\tthis.dbName = dbName;\n\n\tfor (PropertyValidator<String> validator : validators) {\n\t\taddValidator(validat
+or);\n\t}\n}\t}
+"""
+ast = parser.parse(bytes(file_content, encoding="utf-8"))
+root = ast.root_node
+CLASS_LIKE = ["class_declaration", "interface_declaration", "record_declaration"]
+class_node = None
+# print(root)
+for child in root.children:
+    if child.type == "class_declaration":
+        class_node = child
+        break
+# # print(class_node)
+for child in class_node.named_children:
+    if child.type == "class_body":
+        for c in child.named_children:
+            if c.type == "constructor_declaration":
+                print(c.child_by_field_name("parameters"))
+# print(root)
+
+            
+
+# file_path = "/home/lvdthieu/Documents/Projects/continue/manual-testing-sandbox/thieulvd/test/Calculator.java"
+# import_service = ImportService(
+#     # repo_dir="/home/lvdthieu/Documents/Projects/benchmark_continue/github_repos_tmp/AADevelops--JaGame--fc2ae51clear",
+#     repo_dir="/home/lvdthieu/Documents/Projects/continue/manual-testing-sandbox",
+#     language="java"
+# )
+
+# print(import_service.get_file_info(file_path))
+
+# file_path = "/home/lvdthieu/Documents/Projects/continue/manual-testing-sandbox/thieulvd/test/Calculator.java"
+# import_service = ImportService(
+#     # repo_dir="/home/lvdthieu/Documents/Projects/benchmark_continue/github_repos_tmp/AADevelops--JaGame--fc2ae51clear",
+#     repo_dir="/home/lvdthieu/Documents/Projects/benchmark_continue/github_repos_tmp/AADevelops--JaGame--fc2ae51",
+#     language="java"
+# )
+
+# print(import_service.get_file_info(file_path))
diff --git a/benchmark/test/test_utils.py b/benchmark/test/test_utils.py
new file mode 100644
index 0000000..e85f03d
--- /dev/null
+++ b/benchmark/test/test_utils.py
@@ -0,0 +1,38 @@
+# import os
+# import sys
+# from pprint import pprint
+
+# sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))
+# from continue_dev.helper import Helper
+# from tree_sitter import Point
+# from continue_dev.utils import construct_autocomplete_prompt, render_prompt
+
+# repo_dir = "/home/lvdthieu/Documents/Projects/continue/manual-testing-sandbox"
+# file_path = "/home/lvdthieu/Documents/Projects/continue/manual-testing-sandbox/thieulvd/test/Calculator.java"
+# cursor_index=Point(row=21, column=28)
+# helper = Helper(
+#     repo_dir=repo_dir,
+#     language="java",
+#     file_path=file_path,
+#     cursor_index=cursor_index
+# )
+# pprint(vars(helper))
+# snippets = construct_autocomplete_prompt(helper)
+# print(render_prompt(snippets, helper))
+
+print(repr("""; Method parameters
+(method_declaration
+  (formal_parameters
+    (formal_parameter
+    	(type_identifier) @a
+    )
+  )
+)
+
+; Return type
+(method_declaration
+  (type_identifier) @b
+)"""))
+
+
+
diff --git a/continue-0.8.66-vscode/.gitignore b/continue-0.8.66-vscode/.gitignore
index f331ec6..d51d1de 100644
--- a/continue-0.8.66-vscode/.gitignore
+++ b/continue-0.8.66-vscode/.gitignore
@@ -168,4 +168,5 @@ extensions/.continue-debug/
 
 *.vsix
 
-.continuerules
\ No newline at end of file
+.continuerules
+manual-testing-sandbox
diff --git a/continue-0.8.66-vscode/README.md b/continue-0.8.66-vscode/README.md
index 9751d61..2985a2f 100644
--- a/continue-0.8.66-vscode/README.md
+++ b/continue-0.8.66-vscode/README.md
@@ -1,3 +1,29 @@
+# Introduction
+
+This is the souce code of my thesis at University of Engineering and Technology (VNU). I leverage Continue (a open source project - Code assistant Extension for IDE like VSCode and Jetbrain's products). I develop my self research and improvement upon source code base.
+
+# Details
+
+Will be added soon
+
+# Known issues
+
+- If the Java project has multiple function with the same name within a file, the gotoDefinition function will return the first function that Language Server has parsed
+- Execute provider function (related to LSP) has cache machanism. Because the cache key is combined just only by position of cursor and uri of file, so if you move the cursor to the same position, the cache will be used even if the content of that position is changed.
+- Because incremental indexing for similar code chunk will save the chunks that has different different hash values so if a chunk is just changed a little bit, it will be indexed as a new chunk. This may cause a lot of "duplicate" chunks with almost same value if retrieval in this case -> the retrieval result will be not good.
+
+# Note
+
+- The base implementation don't sort the similarity of retrieval code to the complete window (may be because it only retrieves definition of class, function)
+
+- Sliding window size (128 tokens)
+
+# TODO
+- [ ] Run exist test cases for autocomplete feature
+- [ ] Handle getAllSnippets function correctly
+- [ ] Change racePromise to 100-200ms 
+# Continue
+
 <div align="center">
 
 ![Continue logo](media/readme.png)
diff --git a/continue-0.8.66-vscode/binary/package-lock.json b/continue-0.8.66-vscode/binary/package-lock.json
index c026c94..e607c79 100644
--- a/continue-0.8.66-vscode/binary/package-lock.json
+++ b/continue-0.8.66-vscode/binary/package-lock.json
@@ -69,6 +69,7 @@
         "fastest-levenshtein": "^1.0.16",
         "follow-redirects": "^1.15.5",
         "google-auth-library": "^9.14.2",
+        "gpt-tokenizer": "^2.8.1",
         "handlebars": "^4.7.8",
         "http-proxy-agent": "^7.0.1",
         "https-proxy-agent": "^7.0.3",
@@ -102,6 +103,7 @@
         "tree-sitter-wasms": "^0.1.11",
         "uuid": "^9.0.1",
         "vectordb": "^0.4.20",
+        "vscode": "^1.1.37",
         "web-tree-sitter": "^0.21.0",
         "win-ca": "^3.5.1",
         "wink-nlp-utils": "^2.1.0",
diff --git a/continue-0.8.66-vscode/core/autocomplete/CompletionProvider.ts b/continue-0.8.66-vscode/core/autocomplete/CompletionProvider.ts
index 479b906..edab077 100644
--- a/continue-0.8.66-vscode/core/autocomplete/CompletionProvider.ts
+++ b/continue-0.8.66-vscode/core/autocomplete/CompletionProvider.ts
@@ -3,7 +3,6 @@ import { TRIAL_FIM_MODEL } from "../config/onboarding.js";
 import { IDE, ILLM } from "../index.js";
 import OpenAI from "../llm/llms/OpenAI.js";
 import { DEFAULT_AUTOCOMPLETE_OPTS } from "../util/parameters.js";
-import { PosthogFeatureFlag, Telemetry } from "../util/posthog.js";
 
 import { shouldCompleteMultiline } from "./classification/shouldCompleteMultiline.js";
 import { ContextRetrievalService } from "./context/ContextRetrievalService.js";
@@ -177,13 +176,16 @@ export class CompletionProvider {
         }),
         this.ide.getWorkspaceDirs(),
       ]);
-
-      const { prompt, prefix, suffix, completionOptions } = renderPrompt({
+      
+      const { prompt, prefix, suffix, completionOptions } = await renderPrompt({
         snippetPayload,
         workspaceDirs,
         helper,
       });
 
+      // console.log("Prompt:", prompt);
+      // console.log("====================================================");
+
       // Completion
       let completion: string | undefined = "";
 
@@ -255,7 +257,6 @@ export class CompletionProvider {
         ...helper.options,
       };
 
-      //////////
 
       // Save to cache
       if (!outcome.cacheHit && helper.options.useCache) {
diff --git a/continue-0.8.66-vscode/core/autocomplete/context/ContextRetrievalService.ts b/continue-0.8.66-vscode/core/autocomplete/context/ContextRetrievalService.ts
index 72e061f..81ac69c 100644
--- a/continue-0.8.66-vscode/core/autocomplete/context/ContextRetrievalService.ts
+++ b/continue-0.8.66-vscode/core/autocomplete/context/ContextRetrievalService.ts
@@ -4,14 +4,18 @@ import {
   AutocompleteSnippetType,
 } from "../snippets/types";
 import { HelperVars } from "../util/HelperVars";
+import { GetLspDefinitionsFunction } from "../types.js"
 
 import { ImportDefinitionsService } from "./ImportDefinitionsService";
 import { getSymbolsForSnippet } from "./ranking";
-import { RootPathContextService } from "./root-path-context/RootPathContextService";
-
+import { RootPathContextService } from "./RootPathContextService";
+import { SimilarCodeContextService } from "./SimilarCodeContextService"; 
+import { SimilarUsageContextService } from "./SimilarUsageContextService"; 
 export class ContextRetrievalService {
   private importDefinitionsService: ImportDefinitionsService;
   private rootPathContextService: RootPathContextService;
+  private similarCodeContextService: SimilarCodeContextService;
+  private similarUsageContextService: SimilarUsageContextService;
 
   constructor(private readonly ide: IDE) {
     this.importDefinitionsService = new ImportDefinitionsService(this.ide);
@@ -19,6 +23,8 @@ export class ContextRetrievalService {
       this.importDefinitionsService,
       this.ide,
     );
+    this.similarCodeContextService = new SimilarCodeContextService(this.ide);
+    this.similarUsageContextService = new SimilarUsageContextService();
   }
 
   public async getSnippetsFromImportDefinitions(
@@ -70,4 +76,24 @@ export class ContextRetrievalService {
       helper.treePath,
     );
   }
+
+  public async getSimilarCodeSnippets(
+    helper: HelperVars
+  ): Promise<AutocompleteCodeSnippet[]> {
+    return this.similarCodeContextService.retrieve(helper.cursor, helper.fileLines);
+  }
+
+  public async getSimilarUsageSnippets(
+    helper: HelperVars,
+    getDefinitionsFromLsp: GetLspDefinitionsFunction,
+  ): Promise<AutocompleteCodeSnippet[]> {
+    return this.similarUsageContextService.retrieve(
+      helper.filepath,
+      helper.fullPrefix + helper.fullSuffix,
+      helper.fullPrefix.length,
+      this.ide,
+      helper.lang,
+      getDefinitionsFromLsp,
+    );
+  }
 }
diff --git a/continue-0.8.66-vscode/core/autocomplete/context/ImportDefinitionsService.ts b/continue-0.8.66-vscode/core/autocomplete/context/ImportDefinitionsService.ts
index 5528d22..837b098 100644
--- a/continue-0.8.66-vscode/core/autocomplete/context/ImportDefinitionsService.ts
+++ b/continue-0.8.66-vscode/core/autocomplete/context/ImportDefinitionsService.ts
@@ -29,6 +29,7 @@ export class ImportDefinitionsService {
     return this.cache.get(filepath);
   }
 
+  // This is implementation to get information of imported object to a file (functions, classes)
   private async _getFileInfo(filepath: string): Promise<FileInfo | null> {
     if (filepath.endsWith(".ipynb")) {
       // Commenting out this line was the solution to https://github.com/continuedev/continue/issues/1463
@@ -50,6 +51,8 @@ export class ImportDefinitionsService {
       return null;
     }
 
+    // Use tree-sitter to parse only 10000 first characters of a file or first 100 rows
+    // because import sentence normally is at the beginning of a file.
     const ast = parser.parse(fileContents, undefined, {
       includedRanges: [
         {
@@ -80,11 +83,20 @@ export class ImportDefinitionsService {
       const startPosition = match.captures[0].node.startPosition;
       const defs = await this.ide.gotoDefinition({
         filepath,
-        position: {
+        position: { 
           line: startPosition.row,
           character: startPosition.column,
         },
       });
+
+      for (const def of defs) {
+        console.log("A definition:");
+        console.log(def.filepath);
+        console.log(def.range.start.line, def.range.start.character);
+        console.log(def.range.end.line, def.range.end.character);
+        console.log("============")
+      }
+
       fileInfo.imports[match.captures[0].node.text] = await Promise.all(
         defs.map(async (def) => ({
           ...def,
diff --git a/continue-0.8.66-vscode/core/autocomplete/context/root-path-context/RootPathContextService.ts b/continue-0.8.66-vscode/core/autocomplete/context/RootPathContextService.ts
similarity index 94%
rename from continue-0.8.66-vscode/core/autocomplete/context/root-path-context/RootPathContextService.ts
rename to continue-0.8.66-vscode/core/autocomplete/context/RootPathContextService.ts
index 9364865..884dd84 100644
--- a/continue-0.8.66-vscode/core/autocomplete/context/root-path-context/RootPathContextService.ts
+++ b/continue-0.8.66-vscode/core/autocomplete/context/RootPathContextService.ts
@@ -3,20 +3,20 @@ import { createHash } from "crypto";
 import { LRUCache } from "lru-cache";
 import Parser from "web-tree-sitter";
 
-import { IDE } from "../../..";
+import { IDE } from "../..";
 import {
   getFullLanguageName,
   getQueryForFile,
   IGNORE_PATH_PATTERNS,
   LanguageName,
-} from "../../../util/treeSitter";
+} from "../../util/treeSitter";
 import {
   AutocompleteCodeSnippet,
   AutocompleteSnippetType,
-} from "../../snippets/types";
-import { AutocompleteSnippetDeprecated } from "../../types";
-import { AstPath } from "../../util/ast";
-import { ImportDefinitionsService } from "../ImportDefinitionsService";
+} from "../snippets/types";
+import { AutocompleteSnippetDeprecated } from "../types";
+import { AstPath } from "../util/ast";
+import { ImportDefinitionsService } from "./ImportDefinitionsService";
 
 function getSyntaxTreeString(
   node: Parser.SyntaxNode,
@@ -79,7 +79,6 @@ export class RootPathContextService {
   ): Promise<AutocompleteSnippetDeprecated[]> {
     const snippets: AutocompleteSnippetDeprecated[] = [];
     const language = getFullLanguageName(filepath);
-
     let query: Parser.Query | undefined;
     switch (node.type) {
       case "program":
@@ -164,6 +163,7 @@ export class RootPathContextService {
       RootPathContextService.TYPES_TO_USE.has(node.type),
     )) {
       const key = RootPathContextService.keyFromNode(parentKey, astNode);
+      
       // const type = astNode.type;
       // debugger;
 
diff --git a/continue-0.8.66-vscode/core/autocomplete/context/SimilarCodeContextService.ts b/continue-0.8.66-vscode/core/autocomplete/context/SimilarCodeContextService.ts
new file mode 100644
index 0000000..447a5e1
--- /dev/null
+++ b/continue-0.8.66-vscode/core/autocomplete/context/SimilarCodeContextService.ts
@@ -0,0 +1,61 @@
+
+import { Position } from "../..";
+import {
+    AutocompleteCodeSnippet,
+    AutocompleteSnippetType,
+} from "../snippets/types";
+import { IDE } from "../..";
+import { LlamaAsyncEncoder } from "../../llm/asyncEncoder";
+import { SqliteDb, DatabaseConnection } from "../../indexing/refreshIndex";
+import { jaccardSimilarity } from "./ranking";
+import { getWindowArroundCursor } from "./ranking";
+
+export class SimilarCodeContextService {
+    // I hashcode here for the early development stage, 128 is the max chunk size when Continue indexing (chunking code) for default
+    private maxChunkSize = 128;
+    // I hashcode here for the early development stage, get top 10 similar code snippets
+    private topK = 10;
+    private llamaTokenizer = new LlamaAsyncEncoder();
+
+    constructor(private ide: IDE) {
+        this.ide = ide;
+    }
+
+    async retrieve(cursor: Position, fileLines: string[]): Promise<AutocompleteCodeSnippet[]> {  
+        try {
+            const queryText = await getWindowArroundCursor(cursor, fileLines, this.llamaTokenizer, this.maxChunkSize);
+            const encodedQueryText = await this.llamaTokenizer.encode(queryText);
+            const candidateSnippets = await this.query();
+            const encodedCandidateSnippets = await Promise.all(candidateSnippets.map(async (snippet: any) => {
+                const encodedSnippet = await this.llamaTokenizer.encode(snippet.content);
+                const similarity = jaccardSimilarity(encodedQueryText, encodedSnippet);
+                return { ...snippet, encodedSnippet, similarity };
+            }));
+            
+            const ranking = encodedCandidateSnippets.sort((a: any, b: any) => b.similarity - a.similarity);
+            let result: AutocompleteCodeSnippet[] = [];
+            for (let i = 0; i < Math.min(ranking.length, this.topK); i++) {
+                result.push({
+                    filepath: ranking[i].path,
+                    content: ranking[i].content,
+                    type: AutocompleteSnippetType.Code,
+                });
+            }
+            return result;
+        } catch (error) {
+            console.error("Error in similar code retrieval:", error);
+            return [];
+        }
+
+    }
+
+    async query(): Promise<any> {
+        const db: DatabaseConnection = await SqliteDb.get();
+        const workspaceDirs = await this.ide.getWorkspaceDirs();
+        const workspaceDir = workspaceDirs[0];
+        const query = `SELECT path, startLine, endLine, content FROM chunks WHERE INSTR(path, ?) > 0`;
+        const params = [workspaceDir];
+        const result = await db.all(query, params);
+        return result;
+    }
+}
\ No newline at end of file
diff --git a/continue-0.8.66-vscode/core/autocomplete/context/SimilarUsageContextService.ts b/continue-0.8.66-vscode/core/autocomplete/context/SimilarUsageContextService.ts
new file mode 100644
index 0000000..a074a31
--- /dev/null
+++ b/continue-0.8.66-vscode/core/autocomplete/context/SimilarUsageContextService.ts
@@ -0,0 +1,49 @@
+import {
+    AutocompleteCodeSnippet,
+    AutocompleteSnippetType,
+} from "../snippets/types";
+import { IDE } from "../..";
+import { Range } from "../../index";
+import { GetLspDefinitionsFunction } from "../types";
+import { AutocompleteLanguageInfo } from "../constants/AutocompleteLanguageInfo";
+import { getWindowArroundCursor } from "./ranking";
+import { LlamaAsyncEncoder } from "../../llm/asyncEncoder";
+
+
+export class SimilarUsageContextService {
+    // I hashcode here for the early development stage, 128 is the max chunk size when Continue indexing (chunking code) for default
+    private maxChunkSize = 128;
+    private llamaTokenizer = new LlamaAsyncEncoder();
+
+    async retrieve(
+        filepath: string,
+        contents: string,
+        cursorIndex: number,
+        ide: IDE,
+        lang: AutocompleteLanguageInfo,
+        getLspDefinitions: GetLspDefinitionsFunction
+    ): Promise<AutocompleteCodeSnippet[]> {
+        const snippets: AutocompleteCodeSnippet[] = [];
+        const symbolUsages = await getLspDefinitions(filepath, contents, cursorIndex, ide, lang);
+        const fileLines = contents.split("\n");
+        for (const symbolUsage of symbolUsages) {
+            const { symbol, usages } = symbolUsage;
+            if (!symbol || !usages) continue;
+            // Get window around the usage of the function
+            for (const usage of usages) {
+                const window = await getWindowArroundCursor(usage.range.start, fileLines, this.llamaTokenizer, this.maxChunkSize);
+                snippets.push({
+                    filepath: usage.filepath,
+                    content: window,
+                    type: AutocompleteSnippetType.Code
+                });
+            }
+
+        }
+        for (const sp of snippets) {
+            console.log(sp);
+            console.log("-----------------------------");
+        }
+        return snippets;
+    }
+}
\ No newline at end of file
diff --git a/continue-0.8.66-vscode/core/autocomplete/context/chunking/parseProject.ts b/continue-0.8.66-vscode/core/autocomplete/context/chunking/parseProject.ts
new file mode 100644
index 0000000..eca9428
--- /dev/null
+++ b/continue-0.8.66-vscode/core/autocomplete/context/chunking/parseProject.ts
@@ -0,0 +1,142 @@
+import * as vscode from "vscode";
+
+interface FileMetadata {
+    filePath: string;
+    content: string;
+}
+
+export interface Window {
+    code: string;
+    metadata: {
+        filePath: string;
+        lineNo: number;
+        startLineNo: number;
+        endLineNo: number;
+        windowSize: number;
+        sliceSize: number;
+    }
+}
+
+export interface CodeChunk {
+    code: string;
+    metadataList: any;
+}
+
+async function getWorkspaceFiles(): Promise<FileMetadata[]> {
+    const filesMetadata: FileMetadata[] = [];
+
+    const workspaceFolder = vscode.workspace.workspaceFolders?.[0];
+    if (!workspaceFolder) {
+        vscode.window.showErrorMessage("No workspace folder is open.");
+        return [];
+    }
+    const files = await vscode.workspace.findFiles("**/*");
+    for (const file of files) {
+        try {
+            // @ts-ignore
+            const fileContent = await vscode.workspace.fs.readFile(file);
+            if (file.fsPath.endsWith(".py") || file.fsPath.endsWith(".java")) {
+                const metadata: FileMetadata = {
+                    filePath: file.fsPath,
+                    content: Buffer.from(fileContent).toString("utf8")
+                };
+                filesMetadata.push(metadata);
+            }
+            if (file.fsPath.endsWith(".ipynb")) {
+                const fileString = Buffer.from(fileContent).toString("utf8");
+                const jsonContent = JSON.parse(fileString);
+                const sourceCode: string[] = [];
+                const cells = jsonContent.cells;
+                for (const cell of cells) {
+                    if (cell.cell_type == "code" && Array.isArray(cell.source)) {
+                        sourceCode.push(cell.source.join(''));
+                    }
+                }
+                const metadata: FileMetadata = {
+                    filePath: file.fsPath,
+                    content: sourceCode.join('\n')
+                };
+                filesMetadata.push(metadata);
+            }
+        } catch (err: any) {
+            vscode.window.showErrorMessage(`Failed to read file ${file.fsPath}: ${err.message}`);
+        }
+    }
+    return filesMetadata;
+}
+
+export class RepoWindowMaker {
+    windowSize: number;
+    sliceSize: number;
+    sliceStep: number;
+    sourceCodeFiles: FileMetadata[] = [];
+
+    constructor(windowSize: number, sliceSize: number) {
+        this.windowSize = windowSize;
+        this.sliceSize = sliceSize;
+        if (Math.floor(windowSize / sliceSize) == 0) {
+            this.sliceStep = 1;
+        } else {
+            this.sliceStep = Math.floor(windowSize / sliceSize)
+        }
+    }
+    async setSourceCodeFiles() {
+        this.sourceCodeFiles = await getWorkspaceFiles();
+    }
+
+    buildWindowsForAFile(file: FileMetadata): Window[] {
+        let windows = [];
+        const codeLines = file.content.split('\n');
+        const deltaSize = Math.floor(this.windowSize / 2);
+        for (let lineNo = 0; lineNo < codeLines.length; lineNo += this.sliceStep) {
+            const startLineNo = Math.max(0, lineNo - deltaSize);
+            const endLineNo = Math.min(codeLines.length, lineNo + this.windowSize - deltaSize);
+            const windowLines = codeLines.slice(startLineNo, endLineNo);
+            if (!windowLines) {
+                continue;
+            }
+            const windowText = windowLines.join('\n');
+            windows.push({
+                code: windowText,
+                metadata: {
+                    filePath: file.filePath,
+                    lineNo: lineNo,
+                    startLineNo: startLineNo,
+                    endLineNo: endLineNo,
+                    windowSize: this.windowSize,
+                    sliceSize: this.sliceSize
+                }
+            });
+        }
+        return windows;
+    }
+
+    mergeWindowsWithSameContext(windows: Window[]): CodeChunk[] {
+        let dict: {[key: string]: any} = {};
+        for (const window of windows) {
+            if (window.code in dict) {
+                dict[window.code].push({...window.metadata});
+            } else {
+                dict[window.code] = [{...window.metadata}];
+            }
+        }
+        let result: CodeChunk[] = [];
+        for (const key in dict) {
+            result.push({
+                code: key,
+                metadataList: dict[key]
+            });
+        }
+        return result;
+    }
+
+    async buildWindows(): Promise<CodeChunk[]> {
+        await this.setSourceCodeFiles();
+        let windows: Window[] = [];
+        for (const file of this.sourceCodeFiles) {
+            const res = this.buildWindowsForAFile(file);
+            windows = windows.concat(res);
+        }
+        return this.mergeWindowsWithSameContext(windows);
+    }
+}
diff --git a/continue-0.8.66-vscode/core/autocomplete/context/ranking/index.ts b/continue-0.8.66-vscode/core/autocomplete/context/ranking/index.ts
index 1064fd2..2f78f9d 100644
--- a/continue-0.8.66-vscode/core/autocomplete/context/ranking/index.ts
+++ b/continue-0.8.66-vscode/core/autocomplete/context/ranking/index.ts
@@ -1,9 +1,7 @@
-import { RangeInFileWithContents } from "../../../";
-import { countTokens } from "../../../llm/countTokens";
-import { AutocompleteSnippetDeprecated } from "../../types";
-import { HelperVars } from "../../util/HelperVars";
-
+import { Position } from "../../..";
 const rx = /[\s.,\/#!$%\^&\*;:{}=\-_`~()\[\]]/g;
+
+
 export function getSymbolsForSnippet(snippet: string): Set<string> {
   const symbols = snippet
     .split(rx)
@@ -13,143 +11,46 @@ export function getSymbolsForSnippet(snippet: string): Set<string> {
 }
 
 /**
- * Calculate similarity as number of shared symbols divided by total number of unique symbols between both.
+ * Calculate similarity as number of shared tokens divided by total number of unique tokens between both.
  */
-function jaccardSimilarity(a: string, b: string): number {
-  const aSet = getSymbolsForSnippet(a);
-  const bSet = getSymbolsForSnippet(b);
-  const union = new Set([...aSet, ...bSet]).size;
+export function jaccardSimilarity(list1: number[], list2: number[]): number {
+  const set1 = new Set<number>(list1);
+  const set2 = new Set<number>(list2);
+  const union = new Set<number>([...set1, ...set2]);
 
-  // Avoid division by zero
-  if (union === 0) {
+  if (union.size === 0) {
     return 0;
   }
-
-  let intersection = 0;
-  for (const symbol of aSet) {
-    if (bSet.has(symbol)) {
-      intersection++;
-    }
-  }
-
-  return intersection / union;
-}
-
-/**
- * Rank code snippets to be used in tab-autocomplete prompt. Returns a sorted version of the snippet array.
- */
-export function rankAndOrderSnippets(
-  ranges: AutocompleteSnippetDeprecated[],
-  helper: HelperVars,
-): Required<AutocompleteSnippetDeprecated>[] {
-  const windowAroundCursor =
-    helper.fullPrefix.slice(
-      -helper.options.slidingWindowSize *
-        helper.options.slidingWindowPrefixPercentage,
-    ) +
-    helper.fullSuffix.slice(
-      helper.options.slidingWindowSize *
-        (1 - helper.options.slidingWindowPrefixPercentage),
-    );
-
-  const snippets: Required<AutocompleteSnippetDeprecated>[] = ranges.map(
-    (snippet) => ({
-      score:
-        snippet.score ??
-        jaccardSimilarity(snippet.contents, windowAroundCursor),
-      ...snippet,
-    }),
-  );
-  const uniqueSnippets = deduplicateSnippets(snippets);
-  return uniqueSnippets.sort((a, b) => a.score - b.score);
-}
-
-/**
- * Deduplicate code snippets by merging overlapping ranges into a single range.
- */
-function deduplicateSnippets(
-  snippets: Required<AutocompleteSnippetDeprecated>[],
-): Required<AutocompleteSnippetDeprecated>[] {
-  // Group by file
-  const fileGroups: {
-    [key: string]: Required<AutocompleteSnippetDeprecated>[];
-  } = {};
-  for (const snippet of snippets) {
-    if (!fileGroups[snippet.filepath]) {
-      fileGroups[snippet.filepath] = [];
-    }
-    fileGroups[snippet.filepath].push(snippet);
-  }
-
-  // Merge overlapping ranges
-  const allRanges = [];
-  for (const file of Object.keys(fileGroups)) {
-    allRanges.push(...mergeSnippetsByRange(fileGroups[file]));
-  }
-  return allRanges;
+  const intersection = new Set<number>([...set1].filter(x => set2.has(x)));
+  return intersection.size / union.size;
 }
 
-function mergeSnippetsByRange(
-  snippets: Required<AutocompleteSnippetDeprecated>[],
-): Required<AutocompleteSnippetDeprecated>[] {
-  if (snippets.length <= 1) {
-    return snippets;
-  }
-
-  const sorted = snippets.sort(
-    (a, b) => a.range.start.line - b.range.start.line,
-  );
-  const merged: Required<AutocompleteSnippetDeprecated>[] = [];
-
-  while (sorted.length > 0) {
-    const next = sorted.shift()!;
-    const last = merged[merged.length - 1];
-    if (merged.length > 0 && last.range.end.line >= next.range.start.line) {
-      // Merge with previous snippet
-      last.score = Math.max(last.score, next.score);
-      try {
-        last.range.end = next.range.end;
-      } catch (e) {
-        console.log("Error merging ranges", e);
+export async function getWindowArroundCursor(cursor: Position, fileLines: string[], tokenizer: any, chunkSize: number): Promise<string> {
+  // Recursive extend to two sides to reach `chunkSize`
+  let startLineNo = cursor.line;
+  let endLineNo = cursor.line + 1;
+  let queryText = "";
+  while (startLineNo >= 0 && endLineNo <= fileLines.length) {
+      queryText = fileLines.slice(startLineNo, endLineNo).join("\n");
+      const encodedQueryText = await tokenizer.encode(queryText);
+      if (encodedQueryText.length > chunkSize) {
+          break;
       }
-      last.contents = mergeOverlappingRangeContents(last, next);
-    } else {
-      merged.push(next);
-    }
+      startLineNo--;
+      endLineNo++;
   }
-
-  return merged;
-}
-
-function mergeOverlappingRangeContents(
-  first: RangeInFileWithContents,
-  second: RangeInFileWithContents,
-): string {
-  const firstLines = first.contents.split("\n");
-  const numOverlapping = first.range.end.line - second.range.start.line;
-  return `${firstLines.slice(-numOverlapping).join("\n")}\n${second.contents}`;
-}
-
-/**
- * Fill the allowed space with snippets.
- * It is assumed that the snippets are sorted by score.
- */
-export function fillPromptWithSnippets(
-  snippets: Required<AutocompleteSnippetDeprecated>[],
-  maxSnippetTokens: number,
-  modelName: string,
-): Required<AutocompleteSnippetDeprecated>[] {
-  let tokensRemaining = maxSnippetTokens;
-  const keptSnippets: Required<AutocompleteSnippetDeprecated>[] = [];
-  for (let i = 0; i < snippets.length; i++) {
-    const snippet = snippets[i];
-    const tokenCount = countTokens(snippet.contents, modelName);
-    if (tokensRemaining - tokenCount >= 0) {
-      tokensRemaining -= tokenCount;
-      keptSnippets.push(snippet);
-    } else {
-    }
+  queryText = fileLines.slice(startLineNo + 1, endLineNo - 1).join("\n");
+  while (true) {
+      const encodedQueryText = await tokenizer.encode(queryText);
+      if (encodedQueryText.length >= chunkSize || startLineNo < 0) break;
+      queryText = fileLines[startLineNo] + "\n" + queryText;
+      startLineNo--;
   }
-
-  return keptSnippets;
+  while (true) {
+      const encodedQueryText = await tokenizer.encode(queryText);
+      if (encodedQueryText.length >= chunkSize || endLineNo >= fileLines.length) break;
+      queryText = queryText + "\n" + fileLines[endLineNo];
+      endLineNo++;
+  }
+  return queryText;
 }
diff --git a/continue-0.8.66-vscode/core/autocomplete/context/root-path-context/test/RootPathContextService.test.ts b/continue-0.8.66-vscode/core/autocomplete/context/root-path-context/test/RootPathContextService.test.ts
deleted file mode 100644
index a954dda..0000000
--- a/continue-0.8.66-vscode/core/autocomplete/context/root-path-context/test/RootPathContextService.test.ts
+++ /dev/null
@@ -1,56 +0,0 @@
-import { PYTHON_TEST_CASES, TYPESCRIPT_TEST_CASES } from "./testCases";
-import { testRootPathContext } from "./testUtils";
-
-const TEST_CASES = [
-  ...PYTHON_TEST_CASES,
-  ...TYPESCRIPT_TEST_CASES,
-  {
-    nodeType: "function_definition",
-    fileName: "file1.php",
-    language: "PHP",
-    cursorPosition: { line: 12, character: 32 },
-    definitionPositions: [
-      { row: 10, column: 26 }, // Person
-      { row: 10, column: 44 }, // Address
-    ],
-  },
-  {
-    nodeType: "method_declaration",
-    fileName: "file1.php",
-    language: "PHP",
-    cursorPosition: { line: 26, character: 35 },
-    definitionPositions: [
-      { row: 15, column: 29 }, // BaseClass
-      { row: 15, column: 55 }, // FirstInterface
-      { row: 15, column: 72 }, // SecondInterface
-      { row: 25, column: 43 }, // Person
-      { row: 25, column: 61 }, // Address
-    ],
-  },
-  {
-    nodeType: "function_declaration",
-    fileName: "file1.go",
-    language: "Go",
-    cursorPosition: { line: 7, character: 21 },
-    definitionPositions: [
-      { row: 6, column: 33 }, // models.User
-      { row: 6, column: 50 }, // models.Address
-    ],
-  },
-];
-
-describe("RootPathContextService", () => {
-  describe("should look for correct type definitions", () => {
-    test.each(TEST_CASES)(
-      "$language: $nodeType",
-      async ({ fileName, cursorPosition, definitionPositions }) => {
-        await testRootPathContext(
-          "files",
-          fileName,
-          cursorPosition,
-          definitionPositions,
-        );
-      },
-    );
-  });
-});
diff --git a/continue-0.8.66-vscode/core/autocomplete/context/root-path-context/test/files/base_module.py b/continue-0.8.66-vscode/core/autocomplete/context/root-path-context/test/files/base_module.py
deleted file mode 100644
index cf0dc0a..0000000
--- a/continue-0.8.66-vscode/core/autocomplete/context/root-path-context/test/files/base_module.py
+++ /dev/null
@@ -1,26 +0,0 @@
-# File: base_module.py
-
-class BaseClass:
-    def __init__(self):
-        print("BaseClass initialized")
-
-class Collection:
-    def __init__(self):
-        print("Collection initialized")
-
-class Address:
-    def __init__(self, street: str, city: str, zip_code: str):
-        self.street = street
-        self.city = city
-        self.zip_code = zip_code
-
-    def __str__(self):
-        return f"{self.street}, {self.city}, {self.zip_code}"
-
-class Person:
-    def __init__(self, name: str, address: Address):
-        self.name = name
-        self.address = address
-
-    def __str__(self):
-        return f"{self.name} lives at {self.address}"
diff --git a/continue-0.8.66-vscode/core/autocomplete/context/root-path-context/test/files/file1.go b/continue-0.8.66-vscode/core/autocomplete/context/root-path-context/test/files/file1.go
deleted file mode 100644
index 94eec17..0000000
--- a/continue-0.8.66-vscode/core/autocomplete/context/root-path-context/test/files/file1.go
+++ /dev/null
@@ -1,9 +0,0 @@
-package main
-
-import (
-	"core/autocomplete/context/root-path-context/test/files/models"
-)
-
-func getAddress(user *models.User) *models.Address {
-	return user.Address
-}
\ No newline at end of file
diff --git a/continue-0.8.66-vscode/core/autocomplete/context/root-path-context/test/files/file1.php b/continue-0.8.66-vscode/core/autocomplete/context/root-path-context/test/files/file1.php
deleted file mode 100644
index a72f805..0000000
--- a/continue-0.8.66-vscode/core/autocomplete/context/root-path-context/test/files/file1.php
+++ /dev/null
@@ -1,32 +0,0 @@
-<?php
-
-namespace BaseNamespace;
-
-use BaseNamespace\BaseClass;
-use BaseNamespace\Interfaces\FirstInterface;
-use BaseNamespace\Interfaces\SecondInterface;
-use BaseNamespace\Person;
-use BaseNamespace\Address;
-
-function getAddress(Person $person): Address
-{
-    return $person->getAddress();
-}
-
-class Group extends BaseClass implements FirstInterface, SecondInterface
-{
-    private array $people;
-
-    public function __construct(array $people)
-    {
-        parent::__construct();
-        $this->people = $people;
-    }
-
-    public function getPersonAddress(Person $person): Address
-    {
-        return getAddress($person);
-    }
-}
-
-?>
\ No newline at end of file
diff --git a/continue-0.8.66-vscode/core/autocomplete/context/root-path-context/test/files/python/classes.py b/continue-0.8.66-vscode/core/autocomplete/context/root-path-context/test/files/python/classes.py
deleted file mode 100644
index d752d84..0000000
--- a/continue-0.8.66-vscode/core/autocomplete/context/root-path-context/test/files/python/classes.py
+++ /dev/null
@@ -1,11 +0,0 @@
-class Group(BaseClass, Person):
-    pass
-
-class Group(metaclass=MetaGroup):
-    pass
-
-class Group(BaseClass[Address], Gathering[Person]):
-    pass
-
-class Group(List[Address], Person[str]):
-    pass
\ No newline at end of file
diff --git a/continue-0.8.66-vscode/core/autocomplete/context/root-path-context/test/files/python/functions.py b/continue-0.8.66-vscode/core/autocomplete/context/root-path-context/test/files/python/functions.py
deleted file mode 100644
index 74a9d8b..0000000
--- a/continue-0.8.66-vscode/core/autocomplete/context/root-path-context/test/files/python/functions.py
+++ /dev/null
@@ -1,42 +0,0 @@
-from typing import List, Union, TypeVar, Generic
-
-T = TypeVar('T')
-
-class Address:
-    pass
-
-class Person:
-    pass
-
-class PersonWithGeneric(Generic[T]):
-    pass
-
-
-def get_address(person: Person) -> Address:
-    pass
-
-def get_group_address(people: Group[Person]) -> Group[Address]:
-    pass
-
-def log_person(person: Person) -> None:
-    pass
-
-def get_hardcoded_address() -> Address:
-    pass
-
-def log_person_or_address(value: Union[Person, Address]) -> Union[Person, Address]:
-    pass
-
-def log_person_and_address(person: Person, address: Address) -> None:
-    pass
-
-def get_address_generator(person: Person) -> Generator[Address, None, None]:
-    yield
-
-
-class Group:
-    def log_person_and_address(self, person: Person, address: Address) -> None:
-        pass
-
-async def get_person(address: Address) -> Person:
-    pass
\ No newline at end of file
diff --git a/continue-0.8.66-vscode/core/autocomplete/context/root-path-context/test/files/typescript/arrowFunctions.ts b/continue-0.8.66-vscode/core/autocomplete/context/root-path-context/test/files/typescript/arrowFunctions.ts
deleted file mode 100644
index aadffe0..0000000
--- a/continue-0.8.66-vscode/core/autocomplete/context/root-path-context/test/files/typescript/arrowFunctions.ts
+++ /dev/null
@@ -1,29 +0,0 @@
-// @ts-nocheck
-
-const getAddress = (person: Person): Address => {
-  // TODO
-};
-
-const logPerson = (person: Person) => {
-  // TODO
-};
-
-const getHardcodedAddress = (): Address => {
-  // TODO
-};
-
-const getAddresses = (people: Person[]): Address[] => {
-  // TODO
-};
-
-const logPersonWithAddres = (person: Person<Address>): Person<Address> => {
-  // TODO
-};
-
-const logPersonOrAddress = (person: Person | Address): Person | Address => {
-  // TODO
-};
-
-const logPersonAndAddress = (person: Person, address: Address) => {
-  // TODO
-};
diff --git a/continue-0.8.66-vscode/core/autocomplete/context/root-path-context/test/files/typescript/classMethods.ts b/continue-0.8.66-vscode/core/autocomplete/context/root-path-context/test/files/typescript/classMethods.ts
deleted file mode 100644
index 08f7506..0000000
--- a/continue-0.8.66-vscode/core/autocomplete/context/root-path-context/test/files/typescript/classMethods.ts
+++ /dev/null
@@ -1,35 +0,0 @@
-// @ts-nocheck
-
-class Group {
-  getPersonAddress(person: Person): Address {
-    // TODO
-  }
-
-  getHardcodedAddress(): Address {
-    // TODO
-  }
-
-  addPerson(person: Person) {
-    // TODO
-  }
-
-  addPeople(people: Person[]) {
-    // TODO
-  }
-
-  getAddresses(people: Person[]): Address[] {
-    // TODO
-  }
-
-  logPersonWithAddress(person: Person<Address>): Person<Address> {
-    // TODO
-  }
-
-  logPersonOrAddress(person: Person | Address): Person | Address {
-    // TODO
-  }
-
-  logPersonAndAddress(person: Person, address: Address) {
-    // TODO
-  }
-}
diff --git a/continue-0.8.66-vscode/core/autocomplete/context/root-path-context/test/files/typescript/classes.ts b/continue-0.8.66-vscode/core/autocomplete/context/root-path-context/test/files/typescript/classes.ts
deleted file mode 100644
index 8bb8299..0000000
--- a/continue-0.8.66-vscode/core/autocomplete/context/root-path-context/test/files/typescript/classes.ts
+++ /dev/null
@@ -1,9 +0,0 @@
-// @ts-nocheck
-
-class Group extends BaseClass {}
-
-class Group implements FirstInterface {}
-
-class Group extends BaseClass implements FirstInterface, SecondInterface {}
-
-class Group extends BaseClass<User> implements FirstInterface<User> {}
diff --git a/continue-0.8.66-vscode/core/autocomplete/context/root-path-context/test/files/typescript/functions.ts b/continue-0.8.66-vscode/core/autocomplete/context/root-path-context/test/files/typescript/functions.ts
deleted file mode 100644
index bb9d39c..0000000
--- a/continue-0.8.66-vscode/core/autocomplete/context/root-path-context/test/files/typescript/functions.ts
+++ /dev/null
@@ -1,33 +0,0 @@
-// @ts-nocheck
-
-function getAddress(person: Person): Address {
-  // TODO
-}
-
-function getFirstAddress(people: Person[]): Address {
-  // TODO
-}
-
-function logPerson(person: Person) {
-  // TODO
-}
-
-function getHardcodedAddress(): Address {
-  // TODO
-}
-
-function getAddresses(people: Person[]): Address[] {
-  // TODO
-}
-
-function logPersonWithAddress(person: Person<Address>): Person<Address> {
-  // TODO
-}
-
-function logPersonOrAddress(person: Person | Address): Person | Address {
-  // TODO
-}
-
-function logPersonAndAddress(person: Person, address: Address) {
-  // TODO
-}
diff --git a/continue-0.8.66-vscode/core/autocomplete/context/root-path-context/test/files/typescript/generators.ts b/continue-0.8.66-vscode/core/autocomplete/context/root-path-context/test/files/typescript/generators.ts
deleted file mode 100644
index 79811b4..0000000
--- a/continue-0.8.66-vscode/core/autocomplete/context/root-path-context/test/files/typescript/generators.ts
+++ /dev/null
@@ -1,33 +0,0 @@
-// @ts-nocheck
-
-function* getAddress(person: Person): Address {
-  // TODO
-}
-
-function* getFirstAddress(people: Person[]): Address {
-  // TODO
-}
-
-function* logPerson(person: Person) {
-  // TODO
-}
-
-function* getHardcodedAddress(): Address {
-  // TODO
-}
-
-function* getAddresses(people: Person[]): Address[] {
-  // TODO
-}
-
-function* logPersonWithAddress(person: Person<Address>): Person<Address> {
-  // TODO
-}
-
-function* logPersonOrAddress(person: Person | Address): Person | Address {
-  // TODO
-}
-
-function* logPersonAndAddress(person: Person, address: Address) {
-  // TODO
-}
diff --git a/continue-0.8.66-vscode/core/autocomplete/context/root-path-context/test/testCases/index.ts b/continue-0.8.66-vscode/core/autocomplete/context/root-path-context/test/testCases/index.ts
deleted file mode 100644
index 7859fc2..0000000
--- a/continue-0.8.66-vscode/core/autocomplete/context/root-path-context/test/testCases/index.ts
+++ /dev/null
@@ -1,2 +0,0 @@
-export * from "./python";
-export * from "./typescript";
diff --git a/continue-0.8.66-vscode/core/autocomplete/context/root-path-context/test/testCases/python.ts b/continue-0.8.66-vscode/core/autocomplete/context/root-path-context/test/testCases/python.ts
deleted file mode 100644
index 9c8d46e..0000000
--- a/continue-0.8.66-vscode/core/autocomplete/context/root-path-context/test/testCases/python.ts
+++ /dev/null
@@ -1,145 +0,0 @@
-export const FUNCTIONS = [
-  {
-    nodeType: "function_definition with argument and return type",
-    fileName: "python/functions.py",
-    language: "Python",
-    cursorPosition: { line: 15, character: 8 },
-    definitionPositions: [
-      { row: 14, column: 30 }, // Person
-      { row: 14, column: 42 }, // Address
-    ],
-  },
-  {
-    nodeType:
-      "function_definition with generic argument and generic return type",
-    fileName: "python/functions.py",
-    language: "Python",
-    cursorPosition: { line: 18, character: 8 },
-    definitionPositions: [
-      { row: 17, column: 35 }, // Group
-      { row: 17, column: 42 }, // Person
-      { row: 17, column: 53 }, // Group
-      { row: 17, column: 61 }, // Address
-    ],
-  },
-  {
-    nodeType: "function_definition with single argument and None return type",
-    fileName: "python/functions.py",
-    language: "Python",
-    cursorPosition: { line: 21, character: 8 },
-    definitionPositions: [
-      { row: 20, column: 29 }, // Person
-    ],
-  },
-  {
-    nodeType: "function_definition with no arguments and single return type",
-    fileName: "python/functions.py",
-    language: "Python",
-    cursorPosition: { line: 24, character: 8 },
-    definitionPositions: [
-      { row: 23, column: 38 }, // Address
-    ],
-  },
-  {
-    nodeType: "function_definition with Union arguments and Union return type",
-    fileName: "python/functions.py",
-    language: "Python",
-    cursorPosition: { line: 27, character: 8 },
-    definitionPositions: [
-      { row: 26, column: 45 }, // Person
-      { row: 26, column: 54 }, // Address
-      { row: 26, column: 72 }, // Person
-      { row: 26, column: 81 }, // Address
-    ],
-  },
-  {
-    nodeType:
-      "function_definition with multiple arguments and None return type",
-    fileName: "python/functions.py",
-    language: "Python",
-    cursorPosition: { line: 30, character: 8 },
-    definitionPositions: [
-      { row: 29, column: 41 }, // Person
-      { row: 29, column: 59 }, // Address
-    ],
-  },
-  {
-    nodeType: "function_definition with one argument and Generator return type",
-    fileName: "python/functions.py",
-    language: "Python",
-    cursorPosition: { line: 33, character: 9 },
-    definitionPositions: [
-      { row: 32, column: 40 }, // Person
-      { row: 32, column: 62 }, // Address
-    ],
-  },
-  {
-    nodeType: "function_definition inside a class",
-    fileName: "python/functions.py",
-    language: "Python",
-    cursorPosition: { line: 38, character: 12 },
-    definitionPositions: [
-      { row: 37, column: 51 }, // Person
-      { row: 37, column: 69 }, // Address
-    ],
-  },
-  {
-    nodeType: "function_definition of an async function",
-    fileName: "python/functions.py",
-    language: "Python",
-    cursorPosition: { line: 41, character: 8 },
-    definitionPositions: [
-      { row: 40, column: 37 }, // Address
-      { row: 40, column: 48 }, // Person
-    ],
-  },
-];
-
-export const CLASSES = [
-  {
-    nodeType: "class_definition with multiple superclasses",
-    fileName: "python/classes.py",
-    language: "Python",
-    cursorPosition: { line: 1, character: 8 },
-    definitionPositions: [
-      { row: 0, column: 21 }, // BaseClass
-      { row: 0, column: 29 }, // Person
-    ],
-  },
-  {
-    nodeType: "class_definition with multiple superclasses",
-    fileName: "python/classes.py",
-    language: "Python",
-    cursorPosition: { line: 4, character: 8 },
-    definitionPositions: [
-      { row: 3, column: 31 }, // MetaGroup
-    ],
-  },
-  {
-    nodeType: "class_definition with generic superclasses",
-    fileName: "python/classes.py",
-    language: "Python",
-    cursorPosition: { line: 7, character: 8 },
-    definitionPositions: [
-      { row: 6, column: 21 }, // BaseClass
-      { row: 6, column: 29 }, // Address
-      { row: 6, column: 41 }, // Gathering
-      { row: 6, column: 48 }, // Person
-    ],
-  },
-  {
-    nodeType: "class_definition with generic superclasses (built in types)",
-    fileName: "python/classes.py",
-    language: "Python",
-    cursorPosition: { line: 10, character: 8 },
-    definitionPositions: [
-      { row: 9, column: 24 }, // Address
-      { row: 9, column: 33 }, // Person
-    ],
-  },
-];
-
-export const PYTHON_TEST_CASES = [
-  // ...FUNCTIONS,
-  ...CLASSES,
-];
diff --git a/continue-0.8.66-vscode/core/autocomplete/context/root-path-context/test/testCases/typescript.ts b/continue-0.8.66-vscode/core/autocomplete/context/root-path-context/test/testCases/typescript.ts
deleted file mode 100644
index ddda2bf..0000000
--- a/continue-0.8.66-vscode/core/autocomplete/context/root-path-context/test/testCases/typescript.ts
+++ /dev/null
@@ -1,397 +0,0 @@
-const FUNCTIONS = [
-  {
-    nodeType: "function_declaration with a param and a return type",
-    fileName: "typescript/functions.ts",
-    language: "TypeScript",
-    cursorPosition: { line: 3, character: 9 },
-    definitionPositions: [
-      { row: 2, column: 34 }, // Person
-      { row: 2, column: 44 }, // Address
-    ],
-  },
-  {
-    nodeType: "function_declaration with array param",
-    fileName: "typescript/functions.ts",
-    language: "TypeScript",
-    cursorPosition: { line: 7, character: 9 },
-    definitionPositions: [
-      { row: 6, column: 39 }, // Person
-      { row: 6, column: 51 }, // Address
-    ],
-  },
-  {
-    nodeType: "function_declaration without return type",
-    fileName: "typescript/functions.ts",
-    language: "TypeScript",
-    cursorPosition: { line: 11, character: 9 },
-    definitionPositions: [
-      { row: 10, column: 33 }, // Person
-    ],
-  },
-  {
-    nodeType: "function_declaration without params",
-    fileName: "typescript/functions.ts",
-    language: "TypeScript",
-    cursorPosition: { line: 15, character: 9 },
-    definitionPositions: [
-      { row: 14, column: 39 }, // Person
-    ],
-  },
-  {
-    nodeType: "function_declaration with array params and array return type",
-    fileName: "typescript/functions.ts",
-    language: "TypeScript",
-    cursorPosition: { line: 19, character: 9 },
-    definitionPositions: [
-      { row: 18, column: 36 }, // Person
-      { row: 18, column: 48 }, // Address
-    ],
-  },
-  {
-    nodeType:
-      "function_declaration with generic params and generic return type",
-    fileName: "typescript/functions.ts",
-    language: "TypeScript",
-    cursorPosition: { line: 23, character: 9 },
-    definitionPositions: [
-      { row: 22, column: 44 }, // Person
-      { row: 22, column: 52 }, // Address
-      { row: 22, column: 62 }, // Person
-      { row: 22, column: 70 }, // Address
-    ],
-  },
-  {
-    nodeType:
-      "function_declaration with union type params and union return type",
-    fileName: "typescript/functions.ts",
-    language: "TypeScript",
-    cursorPosition: { line: 27, character: 9 },
-    definitionPositions: [
-      { row: 26, column: 42 }, // Person
-      { row: 26, column: 52 }, // Address
-      { row: 26, column: 61 }, // Person
-      { row: 26, column: 71 }, // Address
-    ],
-  },
-  {
-    nodeType: "function_declaration with two arguments",
-    fileName: "typescript/functions.ts",
-    language: "TypeScript",
-    cursorPosition: { line: 31, character: 9 },
-    definitionPositions: [
-      { row: 30, column: 43 }, // Person
-      { row: 30, column: 61 }, // Address
-    ],
-  },
-];
-
-const GENERATORS = [
-  {
-    nodeType: "function_declaration with a param and a return type",
-    fileName: "typescript/generators.ts",
-    language: "TypeScript",
-    cursorPosition: { line: 3, character: 9 },
-    definitionPositions: [
-      { row: 2, column: 35 }, // Person
-      { row: 2, column: 45 }, // Address
-    ],
-  },
-  {
-    nodeType: "function_declaration with array param",
-    fileName: "typescript/generators.ts",
-    language: "TypeScript",
-    cursorPosition: { line: 7, character: 9 },
-    definitionPositions: [
-      { row: 6, column: 40 }, // Person
-      { row: 6, column: 52 }, // Address
-    ],
-  },
-  {
-    nodeType: "function_declaration without return type",
-    fileName: "typescript/generators.ts",
-    language: "TypeScript",
-    cursorPosition: { line: 11, character: 9 },
-    definitionPositions: [
-      { row: 10, column: 34 }, // Person
-    ],
-  },
-  {
-    nodeType: "function_declaration without params",
-    fileName: "typescript/generators.ts",
-    language: "TypeScript",
-    cursorPosition: { line: 15, character: 9 },
-    definitionPositions: [
-      { row: 14, column: 40 }, // Person
-    ],
-  },
-  {
-    nodeType: "function_declaration with array params and array return type",
-    fileName: "typescript/generators.ts",
-    language: "TypeScript",
-    cursorPosition: { line: 19, character: 9 },
-    definitionPositions: [
-      { row: 18, column: 37 }, // Person
-      { row: 18, column: 49 }, // Address
-    ],
-  },
-  {
-    nodeType:
-      "function_declaration with generic params and generic return type",
-    fileName: "typescript/generators.ts",
-    language: "TypeScript",
-    cursorPosition: { line: 23, character: 9 },
-    definitionPositions: [
-      { row: 22, column: 45 }, // Person
-      { row: 22, column: 53 }, // Address
-      { row: 22, column: 63 }, // Person
-      { row: 22, column: 71 }, // Address
-    ],
-  },
-  {
-    nodeType:
-      "function_declaration with union type params and union return type",
-    fileName: "typescript/generators.ts",
-    language: "TypeScript",
-    cursorPosition: { line: 27, character: 9 },
-    definitionPositions: [
-      { row: 26, column: 43 }, // Person
-      { row: 26, column: 53 }, // Address
-      { row: 26, column: 62 }, // Person
-      { row: 26, column: 72 }, // Address
-    ],
-  },
-  {
-    nodeType: "function_declaration with two arguments",
-    fileName: "typescript/generators.ts",
-    language: "TypeScript",
-    cursorPosition: { line: 31, character: 9 },
-    definitionPositions: [
-      { row: 30, column: 44 }, // Person
-      { row: 30, column: 62 }, // Address
-    ],
-  },
-];
-
-const ARROW_FUNCTIONS = [
-  {
-    nodeType: "arrow_function with a param and a return type",
-    fileName: "typescript/arrowFunctions.ts",
-    language: "TypeScript",
-    cursorPosition: { line: 3, character: 9 },
-    definitionPositions: [
-      { row: 2, column: 34 }, // Person
-      { row: 2, column: 44 }, // Address
-    ],
-  },
-  {
-    nodeType: "arrow_function without return type",
-    fileName: "typescript/arrowFunctions.ts",
-    language: "TypeScript",
-    cursorPosition: { line: 7, character: 9 },
-    definitionPositions: [
-      { row: 6, column: 33 }, // Person
-    ],
-  },
-  {
-    nodeType: "arrow_function without params",
-    fileName: "typescript/arrowFunctions.ts",
-    language: "TypeScript",
-    cursorPosition: { line: 11, character: 9 },
-    definitionPositions: [
-      { row: 10, column: 39 }, // Person
-    ],
-  },
-  {
-    nodeType: "arrow_function with array params and array return type",
-    fileName: "typescript/arrowFunctions.ts",
-    language: "TypeScript",
-    cursorPosition: { line: 15, character: 9 },
-    definitionPositions: [
-      { row: 14, column: 36 }, // Person
-      { row: 14, column: 48 }, // Address
-    ],
-  },
-  {
-    nodeType: "arrow_function with generic params and generic return type",
-    fileName: "typescript/arrowFunctions.ts",
-    language: "TypeScript",
-    cursorPosition: { line: 19, character: 9 },
-    definitionPositions: [
-      { row: 18, column: 43 }, // Person
-      { row: 18, column: 51 }, // Address
-      { row: 18, column: 61 }, // Person
-      { row: 18, column: 69 }, // Address
-    ],
-  },
-  {
-    nodeType: "arrow_function with union type params and union return type",
-    fileName: "typescript/arrowFunctions.ts",
-    language: "TypeScript",
-    cursorPosition: { line: 23, character: 9 },
-    definitionPositions: [
-      { row: 22, column: 42 }, // Person
-      { row: 22, column: 52 }, // Address
-      { row: 22, column: 61 }, // Person
-      { row: 22, column: 71 }, // Address
-    ],
-  },
-  {
-    nodeType: "arrow_function with two arguments",
-    fileName: "typescript/arrowFunctions.ts",
-    language: "TypeScript",
-    cursorPosition: { line: 27, character: 11 },
-    definitionPositions: [
-      { row: 26, column: 43 }, // Person
-      { row: 26, column: 61 }, // Address
-    ],
-  },
-];
-
-const CLASS_METHODS = [
-  {
-    nodeType: "method_declaration with a param and a return type",
-    fileName: "typescript/classMethods.ts",
-    language: "TypeScript",
-    cursorPosition: { line: 4, character: 11 },
-    definitionPositions: [
-      { row: 3, column: 33 }, // Person
-      { row: 3, column: 43 }, // Address
-    ],
-  },
-  {
-    nodeType: "method_declaration without arguments",
-    fileName: "typescript/classMethods.ts",
-    language: "TypeScript",
-    cursorPosition: { line: 8, character: 11 },
-    definitionPositions: [
-      { row: 7, column: 32 }, // Address
-    ],
-  },
-  {
-    nodeType: "method_declaration without return type",
-    fileName: "typescript/classMethods.ts",
-    language: "TypeScript",
-    cursorPosition: { line: 12, character: 11 },
-    definitionPositions: [
-      { row: 11, column: 26 }, // Person
-    ],
-  },
-  {
-    nodeType: "method_declaration with array type arguments",
-    fileName: "typescript/classMethods.ts",
-    language: "TypeScript",
-    cursorPosition: { line: 16, character: 11 },
-    definitionPositions: [
-      { row: 15, column: 26 }, // Person
-    ],
-  },
-  {
-    nodeType:
-      "method_declaration with array type arguments and array type return",
-    fileName: "typescript/classMethods.ts",
-    language: "TypeScript",
-    cursorPosition: { line: 20, character: 11 },
-    definitionPositions: [
-      { row: 19, column: 29 }, // Person
-      { row: 19, column: 41 }, // Address
-    ],
-  },
-  {
-    nodeType:
-      "method_declaration with with generic params and generic return type",
-    fileName: "typescript/classMethods.ts",
-    language: "TypeScript",
-    cursorPosition: { line: 24, character: 11 },
-    definitionPositions: [
-      { row: 23, column: 37 }, // Person
-      { row: 23, column: 45 }, // Address
-      { row: 23, column: 55 }, // Person
-      { row: 23, column: 63 }, // Address
-    ],
-  },
-  {
-    nodeType: "method_declaration with union type params and union return type",
-    fileName: "typescript/classMethods.ts",
-    language: "TypeScript",
-    cursorPosition: { line: 28, character: 11 },
-    definitionPositions: [
-      { row: 27, column: 35 }, // Person
-      { row: 27, column: 45 }, // Address
-      { row: 27, column: 54 }, // Person
-      { row: 27, column: 64 }, // Address
-    ],
-  },
-  {
-    nodeType: "method_declaration with two arguments",
-    fileName: "typescript/classMethods.ts",
-    language: "TypeScript",
-    cursorPosition: { line: 32, character: 11 },
-    definitionPositions: [
-      { row: 31, column: 36 }, // Person
-      { row: 31, column: 54 }, // Address
-    ],
-  },
-];
-
-const CLASS_DEFINITIONS = [
-  {
-    nodeType: "class_declaration with base class",
-    fileName: "typescript/classes.ts",
-    language: "TypeScript",
-    cursorPosition: { line: 2, character: 31 },
-    definitionPositions: [
-      { row: 2, column: 29 }, // BaseClass
-    ],
-  },
-  {
-    nodeType: "class_declaration with interface",
-    fileName: "typescript/classes.ts",
-    language: "TypeScript",
-    cursorPosition: { line: 4, character: 39 },
-    definitionPositions: [
-      { row: 4, column: 37 }, // FirstInterface
-    ],
-  },
-  {
-    nodeType: "class_declaration with base class and multiple interfaces",
-    fileName: "typescript/classes.ts",
-    language: "TypeScript",
-    cursorPosition: { line: 6, character: 74 },
-    definitionPositions: [
-      { row: 6, column: 29 }, // BaseClass
-      { row: 6, column: 55 }, // FirstInterface
-      { row: 6, column: 72 }, // SecondInterface
-    ],
-  },
-  {
-    nodeType: "class_declaration with base class and multiple interfaces",
-    fileName: "typescript/classes.ts",
-    language: "TypeScript",
-    cursorPosition: { line: 6, character: 74 },
-    definitionPositions: [
-      { row: 6, column: 29 }, // BaseClass
-      { row: 6, column: 55 }, // FirstInterface
-      { row: 6, column: 72 }, // SecondInterface
-    ],
-  },
-  {
-    nodeType: "class_declaration with generic base class and generic interface",
-    fileName: "typescript/classes.ts",
-    language: "TypeScript",
-    cursorPosition: { line: 8, character: 69 },
-    definitionPositions: [
-      { row: 8, column: 29 }, // BaseClass
-      { row: 8, column: 61 }, // FirstInterface
-      { row: 8, column: 34 }, // User
-      { row: 8, column: 66 }, // User
-    ],
-  },
-];
-
-export const TYPESCRIPT_TEST_CASES = [
-  ...FUNCTIONS,
-  ...GENERATORS,
-  ...ARROW_FUNCTIONS,
-  ...CLASS_METHODS,
-  ...CLASS_DEFINITIONS,
-];
diff --git a/continue-0.8.66-vscode/core/autocomplete/context/root-path-context/test/testUtils.ts b/continue-0.8.66-vscode/core/autocomplete/context/root-path-context/test/testUtils.ts
deleted file mode 100644
index 207b1d6..0000000
--- a/continue-0.8.66-vscode/core/autocomplete/context/root-path-context/test/testUtils.ts
+++ /dev/null
@@ -1,90 +0,0 @@
-import { jest } from "@jest/globals";
-import fs from "fs";
-import path from "path";
-
-import Parser from "web-tree-sitter";
-import { Position } from "../../../..";
-import { testIde } from "../../../../test/fixtures";
-import { getAst, getTreePathAtCursor } from "../../../util/ast";
-import { ImportDefinitionsService } from "../../ImportDefinitionsService";
-import { RootPathContextService } from "../RootPathContextService";
-
-function splitTextAtPosition(
-  fileContent: string,
-  position: Position,
-): [string, string] {
-  const lines = fileContent.split("\n");
-  let currentPos = 0;
-
-  // Calculate position based on the provided line and character
-  for (let i = 0; i < position.line; i++) {
-    currentPos += lines[i].length + 1; // +1 for the newline character
-  }
-  const splitPos = currentPos + position.character;
-
-  return [fileContent.slice(0, splitPos), fileContent.slice(splitPos)];
-}
-
-export async function testRootPathContext(
-  folderName: string,
-  relativeFilepath: string,
-  position: Position,
-  expectedDefinitionPositions: Parser.Point[],
-) {
-  // Create a mocked instance of RootPathContextService
-  const ide = testIde;
-  const importDefinitionsService = new ImportDefinitionsService(ide);
-  const service = new RootPathContextService(importDefinitionsService, ide);
-
-  const getSnippetsMock = jest
-    // @ts-ignore
-    .spyOn(service, "getSnippets")
-    // @ts-ignore
-    .mockImplementation(async (_filepath, _endPosition) => {
-      return [];
-    });
-
-  // Copy the folder to the test directory
-  const folderPath = path.join(
-    __dirname,
-    "autocomplete",
-    "context",
-    "root-path-context",
-    "test",
-    folderName,
-  );
-  const workspaceDir = (await ide.getWorkspaceDirs())[0];
-  const testFolderPath = path.join(workspaceDir, folderName);
-  fs.cpSync(folderPath, testFolderPath, {
-    recursive: true,
-    force: true,
-  });
-
-  // Get results of root path context
-  const startPath = path.join(testFolderPath, relativeFilepath);
-  const [prefix, suffix] = splitTextAtPosition(
-    fs.readFileSync(startPath, "utf8"),
-    position,
-  );
-  const fileContents = prefix + suffix;
-  const ast = await getAst(startPath, fileContents);
-  if (!ast) {
-    throw new Error("AST is undefined");
-  }
-
-  const treePath = await getTreePathAtCursor(ast, prefix.length);
-  await service.getContextForPath(startPath, treePath);
-
-  expect(getSnippetsMock).toHaveBeenCalledTimes(
-    expectedDefinitionPositions.length,
-  );
-
-  expectedDefinitionPositions.forEach((position, index) => {
-    expect(getSnippetsMock).toHaveBeenNthCalledWith(
-      index + 1,
-      expect.any(String), // filepath argument
-      position,
-      expect.any(String), // language argument
-    );
-  });
-}
diff --git a/continue-0.8.66-vscode/core/autocomplete/snippets/getAllSnippets.ts b/continue-0.8.66-vscode/core/autocomplete/snippets/getAllSnippets.ts
index 30d89e7..1096cd0 100644
--- a/continue-0.8.66-vscode/core/autocomplete/snippets/getAllSnippets.ts
+++ b/continue-0.8.66-vscode/core/autocomplete/snippets/getAllSnippets.ts
@@ -9,48 +9,24 @@ import {
   AutocompleteSnippetType,
 } from "./types";
 
-export interface SnippetPayload {
+export interface SnippetPayload { 
   rootPathSnippets: AutocompleteCodeSnippet[];
   importDefinitionSnippets: AutocompleteCodeSnippet[];
-  ideSnippets: AutocompleteCodeSnippet[];
   recentlyEditedRangeSnippets: AutocompleteCodeSnippet[];
   diffSnippets: AutocompleteDiffSnippet[];
   clipboardSnippets: AutocompleteClipboardSnippet[];
+  similarCodeSnippets: AutocompleteCodeSnippet[];
+  similarUsageSnippets: AutocompleteCodeSnippet[];
 }
 
 function racePromise<T>(promise: Promise<T[]>): Promise<T[]> {
   const timeoutPromise = new Promise<T[]>((resolve) => {
-    setTimeout(() => resolve([]), 100);
+    setTimeout(() => resolve([]),1000);
   });
 
   return Promise.race([promise, timeoutPromise]);
 }
 
-// Some IDEs might have special ways of finding snippets (e.g. JetBrains and VS Code have different "LSP-equivalent" systems,
-// or they might separately track recently edited ranges)
-async function getIdeSnippets(
-  helper: HelperVars,
-  ide: IDE,
-  getDefinitionsFromLsp: GetLspDefinitionsFunction,
-): Promise<AutocompleteCodeSnippet[]> {
-  const ideSnippets = await getDefinitionsFromLsp(
-    helper.input.filepath,
-    helper.fullPrefix + helper.fullSuffix,
-    helper.fullPrefix.length,
-    ide,
-    helper.lang,
-  );
-
-  if (helper.options.onlyMyCode) {
-    const workspaceDirs = await ide.getWorkspaceDirs();
-
-    return ideSnippets.filter((snippet) =>
-      workspaceDirs.some((dir) => snippet.filepath.startsWith(dir)),
-    );
-  }
-
-  return ideSnippets;
-}
 
 function getSnippetsFromRecentlyEditedRanges(
   helper: HelperVars,
@@ -68,6 +44,7 @@ function getSnippetsFromRecentlyEditedRanges(
   });
 }
 
+
 const getClipboardSnippets = async (
   ide: IDE,
 ): Promise<AutocompleteClipboardSnippet[]> => {
@@ -82,6 +59,7 @@ const getClipboardSnippets = async (
   });
 };
 
+
 const getDiffSnippets = async (
   ide: IDE,
 ): Promise<AutocompleteDiffSnippet[]> => {
@@ -95,6 +73,7 @@ const getDiffSnippets = async (
   });
 };
 
+
 export const getAllSnippets = async ({
   helper,
   ide,
@@ -106,31 +85,44 @@ export const getAllSnippets = async ({
   getDefinitionsFromLsp: GetLspDefinitionsFunction;
   contextRetrievalService: ContextRetrievalService;
 }): Promise<SnippetPayload> => {
+  // Reuse recently edit snippets of Continue
   const recentlyEditedRangeSnippets =
     getSnippetsFromRecentlyEditedRanges(helper);
 
+  // Reuse diff snippets, clipboard snippets of Continue
+  
+  // I believe that, the root path snippets that have retrieved by Continue's 
+  // way is nonsense and do not support generation process, I need to check if this
+  // observation is true
+
+  // I changed the implementation of ide snippets
   const [
-    rootPathSnippets,
-    importDefinitionSnippets,
-    ideSnippets,
-    diffSnippets,
+    // rootPathSnippets,
+    // importDefinitionSnippets,
+    diffSnippets,                 
     clipboardSnippets,
+    similarCodeSnippets,
+    similarUsageSnippets,
   ] = await Promise.all([
-    racePromise(contextRetrievalService.getRootPathSnippets(helper)),
-    racePromise(
-      contextRetrievalService.getSnippetsFromImportDefinitions(helper),
-    ),
-    racePromise(getIdeSnippets(helper, ide, getDefinitionsFromLsp)),
+    // racePromise(contextRetrievalService.getRootPathSnippets(helper)),
+    // racePromise(
+    //   contextRetrievalService.getSnippetsFromImportDefinitions(helper),
+    // ),
     racePromise(getDiffSnippets(ide)),
     racePromise(getClipboardSnippets(ide)),
+    contextRetrievalService.getSimilarCodeSnippets(helper),
+    contextRetrievalService.getSimilarUsageSnippets(helper, getDefinitionsFromLsp),
   ]);
+  const rootPathSnippets: AutocompleteCodeSnippet[] = [];
+  const importDefinitionSnippets: AutocompleteCodeSnippet[] = [];
 
   return {
     rootPathSnippets,
     importDefinitionSnippets,
-    ideSnippets,
     recentlyEditedRangeSnippets,
     diffSnippets,
     clipboardSnippets,
+    similarCodeSnippets,
+    similarUsageSnippets,
   };
 };
diff --git a/continue-0.8.66-vscode/core/autocomplete/snippets/types.ts b/continue-0.8.66-vscode/core/autocomplete/snippets/types.ts
index e43b598..fce42fb 100644
--- a/continue-0.8.66-vscode/core/autocomplete/snippets/types.ts
+++ b/continue-0.8.66-vscode/core/autocomplete/snippets/types.ts
@@ -14,6 +14,12 @@ export interface AutocompleteCodeSnippet extends BaseAutocompleteSnippet {
   type: AutocompleteSnippetType.Code;
 }
 
+export interface AutocompleteRankedSnippet extends BaseAutocompleteSnippet {
+  filepath?: string;
+  similarityScore: number;
+  copiedAt?: string;
+}
+
 export interface AutocompleteDiffSnippet extends BaseAutocompleteSnippet {
   type: AutocompleteSnippetType.Diff;
 }
diff --git a/continue-0.8.66-vscode/core/autocomplete/templating/filtering.ts b/continue-0.8.66-vscode/core/autocomplete/templating/filtering.ts
index a6cdf09..116bf5e 100644
--- a/continue-0.8.66-vscode/core/autocomplete/templating/filtering.ts
+++ b/continue-0.8.66-vscode/core/autocomplete/templating/filtering.ts
@@ -3,9 +3,13 @@ import { SnippetPayload } from "../snippets";
 import {
   AutocompleteCodeSnippet,
   AutocompleteSnippet,
+  AutocompleteRankedSnippet,
+
 } from "../snippets/types";
 import { HelperVars } from "../util/HelperVars";
 import { isValidSnippet } from "./validation";
+import { LlamaAsyncEncoder } from "../../llm/asyncEncoder";
+import { getWindowArroundCursor, jaccardSimilarity } from "../context/ranking";
 
 const getRemainingTokenCount = (helper: HelperVars): number => {
   const tokenCount = countTokens(helper.prunedCaretWindow, helper.modelName);
@@ -37,27 +41,73 @@ function filterSnippetsAlreadyInCaretWindow(
   );
 }
 
-export const getSnippets = (
+const llamaTokenizer = new LlamaAsyncEncoder();
+
+async function getRankedSnippets(
+  queryText: string,
+  snippets: AutocompleteSnippet[],
+): Promise<AutocompleteRankedSnippet[]> {
+  
+  const encodedQueryText = await llamaTokenizer.encode(queryText);
+  const encodedSnippets = await Promise.all(snippets.map(async (snippet: any) => {
+      const encodedSnippet = await llamaTokenizer.encode(snippet.content);
+      const similarityScore = jaccardSimilarity(encodedQueryText, encodedSnippet);
+      return { ...snippet, similarityScore };
+  }));
+  
+  const ranking = encodedSnippets.sort((a: any, b: any) => b.similarity - a.similarity);
+  const result = ranking.map((snippet: any) => ({
+    ...snippet
+  }));
+  return result;
+}
+
+export const getSnippets = async (
   helper: HelperVars,
   payload: SnippetPayload,
-): AutocompleteSnippet[] => {
-  const snippets = [
-    ...payload.diffSnippets,
-    ...payload.clipboardSnippets,
-    ...shuffleArray(
-      filterSnippetsAlreadyInCaretWindow(
-        [...payload.rootPathSnippets, ...payload.importDefinitionSnippets],
+): Promise<AutocompleteRankedSnippet[]> => {
+  // for (let i = 0; i < payload.diffSnippets.length; i++) {
+  //   payload.diffSnippets[i].content = "===DIFF===\n" + payload.diffSnippets[i].content
+  // }
+  // for (let i = 0; i < payload.clipboardSnippets.length; i++) {
+  //   payload.clipboardSnippets[i].content = "===CLIPBOARD===\n" + payload.clipboardSnippets[i].content
+  // }
+  // for (let i = 0; i < payload.recentlyEditedRangeSnippets.length; i++) {
+  //   payload.recentlyEditedRangeSnippets[i].content = "===RECENTLY===\n" + payload.recentlyEditedRangeSnippets[i].content
+  // }
+  // for (let i = 0; i < payload.similarCodeSnippets.length; i++) {
+  //   payload.similarCodeSnippets[i].content = "===CODE===\n" + payload.similarCodeSnippets[i].content
+  // }
+  // for (let i = 0; i < payload.similarUsageSnippets.length; i++) {
+  //   payload.similarUsageSnippets[i].content = "===USAGE===\n" + payload.similarUsageSnippets[i].content
+  // }
+
+  const filteredSnippets = filterSnippetsAlreadyInCaretWindow(
+        [ ...payload.rootPathSnippets, 
+          ...payload.importDefinitionSnippets,
+          ...payload.recentlyEditedRangeSnippets,
+          ...payload.similarCodeSnippets,
+          ...payload.similarUsageSnippets,
+        ],
         helper.prunedCaretWindow,
-      ),
-    ),
-  ];
+  )
+
+  const queryText = await getWindowArroundCursor(helper.cursor, helper.fileLines, llamaTokenizer, 128);
+  const rankedSnippets = await getRankedSnippets(
+    queryText,
+    [
+      ...filteredSnippets,
+      ...payload.diffSnippets,
+      ...payload.clipboardSnippets,
+    ],
+  );
 
   const finalSnippets = [];
 
   let remainingTokenCount = getRemainingTokenCount(helper);
 
-  while (remainingTokenCount > 0 && snippets.length > 0) {
-    const snippet = snippets.shift();
+  while (remainingTokenCount > 0 && rankedSnippets.length > 0) {
+    const snippet = rankedSnippets.shift();
     if (!snippet || !isValidSnippet(snippet)) {
       continue;
     }
diff --git a/continue-0.8.66-vscode/core/autocomplete/templating/index.ts b/continue-0.8.66-vscode/core/autocomplete/templating/index.ts
index 5715e30..4072d8b 100644
--- a/continue-0.8.66-vscode/core/autocomplete/templating/index.ts
+++ b/continue-0.8.66-vscode/core/autocomplete/templating/index.ts
@@ -13,6 +13,7 @@ import {
 import { getSnippets } from "./filtering";
 import { formatSnippets } from "./formatting";
 import { getStopTokens } from "./getStopTokens";
+import { AutocompleteSnippet } from "../snippets/types";
 
 function getTemplate(helper: HelperVars): AutocompleteTemplate {
   if (helper.options.template) {
@@ -45,7 +46,7 @@ function renderStringTemplate(
   });
 }
 
-export function renderPrompt({
+export async function renderPrompt({
   snippetPayload,
   workspaceDirs,
   helper,
@@ -53,12 +54,12 @@ export function renderPrompt({
   snippetPayload: SnippetPayload;
   workspaceDirs: string[];
   helper: HelperVars;
-}): {
+}): Promise<{
   prompt: string;
   prefix: string;
   suffix: string;
   completionOptions: Partial<CompletionOptions> | undefined;
-} {
+}> {
   // If prefix is manually passed
   let prefix = helper.input.manuallyPassPrefix || helper.prunedPrefix;
   let suffix = helper.input.manuallyPassPrefix ? "" : helper.prunedSuffix;
@@ -71,8 +72,24 @@ export function renderPrompt({
   const { template, compilePrefixSuffix, completionOptions } =
     getTemplate(helper);
 
-  const snippets = getSnippets(helper, snippetPayload);
+  const rankedSnippets = await getSnippets(helper, snippetPayload);
 
+  // for (const sp of rankedSnippets) {
+  //   console.log(sp.similarityScore);
+  //   console.log("----");
+  //   console.log(sp.content);
+  //   console.log("============================");
+  // }
+
+  const snippets = rankedSnippets.map((snippet) => {
+    return {
+      filepath: "filepath" in snippet ? snippet.filepath : "Untitled.txt",
+      content: snippet.content,
+      type: snippet.type,
+    } as AutocompleteSnippet;
+  });
+
+  
   // Some models have prompts that need two passes. This lets us pass the compiled prefix/suffix
   // into either the 2nd template to generate a raw string, or to pass prefix, suffix to a FIM endpoint
   if (compilePrefixSuffix) {
diff --git a/continue-0.8.66-vscode/core/autocomplete/templating/validation.ts b/continue-0.8.66-vscode/core/autocomplete/templating/validation.ts
index dad55dc..9c36c67 100644
--- a/continue-0.8.66-vscode/core/autocomplete/templating/validation.ts
+++ b/continue-0.8.66-vscode/core/autocomplete/templating/validation.ts
@@ -1,16 +1,14 @@
 import {
-  AutocompleteClipboardSnippet,
-  AutocompleteSnippet,
-  AutocompleteSnippetType,
+  AutocompleteRankedSnippet,
 } from "../snippets/types";
 
 const MAX_CLIPBOARD_AGE = 5 * 60 * 1000;
 
 const isValidClipboardSnippet = (
-  snippet: AutocompleteClipboardSnippet,
+  snippet: AutocompleteRankedSnippet,
 ): boolean => {
   const currDate = new Date();
-
+  if (!snippet.copiedAt) return false;
   const isTooOld =
     currDate.getTime() - new Date(snippet.copiedAt).getTime() >
     MAX_CLIPBOARD_AGE;
@@ -18,10 +16,10 @@ const isValidClipboardSnippet = (
   return !isTooOld;
 };
 
-export const isValidSnippet = (snippet: AutocompleteSnippet): boolean => {
+export const isValidSnippet = (snippet: AutocompleteRankedSnippet): boolean => {
   if (snippet.content.trim() === "") return false;
 
-  if (snippet.type === AutocompleteSnippetType.Clipboard) {
+  if (snippet.copiedAt) {
     return isValidClipboardSnippet(snippet);
   }
 
diff --git a/continue-0.8.66-vscode/core/autocomplete/types.ts b/continue-0.8.66-vscode/core/autocomplete/types.ts
index 23f7625..2fb043e 100644
--- a/continue-0.8.66-vscode/core/autocomplete/types.ts
+++ b/continue-0.8.66-vscode/core/autocomplete/types.ts
@@ -1,6 +1,7 @@
 import { IDE, RangeInFileWithContents } from "../index";
 import { AutocompleteLanguageInfo } from "./constants/AutocompleteLanguageInfo";
-import { AutocompleteCodeSnippet } from "./snippets/types";
+import { SymbolUsage } from "../index";
+import { RangeInFile } from "../index";
 
 /**
  * @deprecated This type should be removed in the future or renamed.
@@ -17,4 +18,4 @@ export type GetLspDefinitionsFunction = (
   cursorIndex: number,
   ide: IDE,
   lang: AutocompleteLanguageInfo,
-) => Promise<AutocompleteCodeSnippet[]>;
+) => Promise<SymbolUsage[]>;
diff --git a/continue-0.8.66-vscode/core/autocomplete/util/HelperVars.ts b/continue-0.8.66-vscode/core/autocomplete/util/HelperVars.ts
index 0470384..9b93c7d 100644
--- a/continue-0.8.66-vscode/core/autocomplete/util/HelperVars.ts
+++ b/continue-0.8.66-vscode/core/autocomplete/util/HelperVars.ts
@@ -11,8 +11,8 @@ import {
 import { constructInitialPrefixSuffix } from "../templating/constructPrefixSuffix";
 
 import { AstPath, getAst, getTreePathAtCursor } from "./ast";
-import { AutocompleteInput } from "./types";
-
+import { AutocompleteInput} from "./types";
+import { Position } from "../..";
 /**
  * A collection of variables that are often accessed throughout the autocomplete pipeline
  * It's noisy to re-calculate all the time or inject them into each function
@@ -20,7 +20,7 @@ import { AutocompleteInput } from "./types";
 export class HelperVars {
   lang: AutocompleteLanguageInfo;
   treePath: AstPath | undefined;
-
+  private _cursor: Position | undefined;
   private _fileContents: string | undefined;
   private _fileLines: string[] | undefined;
   private _fullPrefix: string | undefined;
@@ -58,6 +58,7 @@ export class HelperVars {
     const { prunedPrefix, prunedSuffix } = this.prunePrefixSuffix();
     this._prunedPrefix = prunedPrefix;
     this._prunedSuffix = prunedSuffix;
+    this._cursor = this.input.pos;
 
     try {
       const ast = await getAst(this.filepath, fullPrefix + fullSuffix);
@@ -138,6 +139,15 @@ export class HelperVars {
     return this._fileLines;
   }
 
+  get cursor(): Position {
+    if (this._cursor === undefined) {
+      throw new Error(
+        "HelperVars must be initialized before accessing cursor",
+      );
+    }
+    return this._cursor;
+  }
+
   get fullPrefix(): string {
     if (this._fullPrefix === undefined) {
       throw new Error(
diff --git a/continue-0.8.66-vscode/core/core.ts b/continue-0.8.66-vscode/core/core.ts
index 61da87d..e8af322 100644
--- a/continue-0.8.66-vscode/core/core.ts
+++ b/continue-0.8.66-vscode/core/core.ts
@@ -807,6 +807,7 @@ export class Core {
   }
 
   private indexingCancellationController: AbortController | undefined;
+  
   private async sendIndexingErrorTelemetry(update: IndexingProgressUpdate) {
     console.debug(
       "Indexing failed with error: ",
diff --git a/continue-0.8.66-vscode/core/index.d.ts b/continue-0.8.66-vscode/core/index.d.ts
index 148401c..8b6e7a5 100644
--- a/continue-0.8.66-vscode/core/index.d.ts
+++ b/continue-0.8.66-vscode/core/index.d.ts
@@ -264,6 +264,11 @@ export interface RangeInFile {
   range: Range;
 }
 
+export interface SymbolUsage {
+  symbol?: string;
+  usages?: RangeInFile[];
+}
+
 export interface Location {
   filepath: string;
   position: Position;
diff --git a/continue-0.8.66-vscode/core/indexing/CodebaseIndexer.ts b/continue-0.8.66-vscode/core/indexing/CodebaseIndexer.ts
index 4b2138d..7fd4901 100644
--- a/continue-0.8.66-vscode/core/indexing/CodebaseIndexer.ts
+++ b/continue-0.8.66-vscode/core/indexing/CodebaseIndexer.ts
@@ -462,4 +462,5 @@ export class CodebaseIndexer {
     const path = filepath.split(pathSep);
     return path[path.length - 1];
   }
+
 }
diff --git a/continue-0.8.66-vscode/core/package-lock.json b/continue-0.8.66-vscode/core/package-lock.json
index 4117d99..dedaf7d 100644
--- a/continue-0.8.66-vscode/core/package-lock.json
+++ b/continue-0.8.66-vscode/core/package-lock.json
@@ -34,6 +34,7 @@
         "fastest-levenshtein": "^1.0.16",
         "follow-redirects": "^1.15.5",
         "google-auth-library": "^9.14.2",
+        "gpt-tokenizer": "^2.8.1",
         "handlebars": "^4.7.8",
         "http-proxy-agent": "^7.0.1",
         "https-proxy-agent": "^7.0.3",
@@ -67,6 +68,7 @@
         "tree-sitter-wasms": "^0.1.11",
         "uuid": "^9.0.1",
         "vectordb": "^0.4.20",
+        "vscode": "^1.1.37",
         "web-tree-sitter": "^0.21.0",
         "win-ca": "^3.5.1",
         "wink-nlp-utils": "^2.1.0",
@@ -6447,6 +6449,11 @@
         "node": ">=8"
       }
     },
+    "node_modules/browser-stdout": {
+      "version": "1.3.1",
+      "resolved": "https://registry.npmjs.org/browser-stdout/-/browser-stdout-1.3.1.tgz",
+      "integrity": "sha512-qhAVI1+Av2X7qelOfAIYwXONood6XlZE/fXaBSmW/T5SzLAmCgzi+eiWE7fUvbHaeNBQH13UftjpXxsfLkMpgw=="
+    },
     "node_modules/browserslist": {
       "version": "4.24.2",
       "resolved": "https://registry.npmjs.org/browserslist/-/browserslist-4.24.2.tgz",
@@ -6539,8 +6546,7 @@
     "node_modules/buffer-from": {
       "version": "1.1.2",
       "resolved": "https://registry.npmjs.org/buffer-from/-/buffer-from-1.1.2.tgz",
-      "integrity": "sha512-E+XQCRwSbaaiChtv6k6Dwgc+bx+Bs6vuKJHHl5kox/BaKbhiXzqQOwK4cO22yElGp2OCmjwVhT3HmxgyPGnJfQ==",
-      "dev": true
+      "integrity": "sha512-E+XQCRwSbaaiChtv6k6Dwgc+bx+Bs6vuKJHHl5kox/BaKbhiXzqQOwK4cO22yElGp2OCmjwVhT3HmxgyPGnJfQ=="
     },
     "node_modules/bytes": {
       "version": "3.1.2",
@@ -7869,6 +7875,19 @@
         "url": "https://github.com/sponsors/ljharb"
       }
     },
+    "node_modules/es6-promise": {
+      "version": "4.2.8",
+      "resolved": "https://registry.npmjs.org/es6-promise/-/es6-promise-4.2.8.tgz",
+      "integrity": "sha512-HJDGx5daxeIvxdBxvG2cb9g4tEvwIk3i8+nhX0yGrYmZUzbkdg8QbDevheDB8gd0//uPj4c1EQua8Q+MViT0/w=="
+    },
+    "node_modules/es6-promisify": {
+      "version": "5.0.0",
+      "resolved": "https://registry.npmjs.org/es6-promisify/-/es6-promisify-5.0.0.tgz",
+      "integrity": "sha512-C+d6UdsYDk0lMebHNR4S2NybQMMngAOnOwYBQjTOiv0MkoJMP0Myw2mgpDLBcpfCmRLxyFqYhS/CfOENq4SJhQ==",
+      "dependencies": {
+        "es6-promise": "^4.0.3"
+      }
+    },
     "node_modules/esbuild": {
       "version": "0.17.19",
       "resolved": "https://registry.npmjs.org/esbuild/-/esbuild-0.17.19.tgz",
@@ -9155,6 +9174,11 @@
         "url": "https://github.com/sponsors/ljharb"
       }
     },
+    "node_modules/gpt-tokenizer": {
+      "version": "2.8.1",
+      "resolved": "https://registry.npmjs.org/gpt-tokenizer/-/gpt-tokenizer-2.8.1.tgz",
+      "integrity": "sha512-8+a9ojzqfgiF3TK4oivGYjlycD8g5igLt8NQw3ndOIgLVKSGJDhUDNAfYSbtyyuTkha3R/R9F8XrwC7/B5TKfQ=="
+    },
     "node_modules/graceful-fs": {
       "version": "4.2.11",
       "resolved": "https://registry.npmjs.org/graceful-fs/-/graceful-fs-4.2.11.tgz",
@@ -9231,6 +9255,14 @@
         "graphology-types": ">=0.23.0"
       }
     },
+    "node_modules/growl": {
+      "version": "1.10.5",
+      "resolved": "https://registry.npmjs.org/growl/-/growl-1.10.5.tgz",
+      "integrity": "sha512-qBr4OuELkhPenW6goKVXiv47US3clb3/IbuWF9KNKEijAy9oeHxU9IgzjvJhHkUzhaj7rOUD7+YGWqUjLp5oSA==",
+      "engines": {
+        "node": ">=4.x"
+      }
+    },
     "node_modules/gtoken": {
       "version": "7.1.0",
       "resolved": "https://registry.npmjs.org/gtoken/-/gtoken-7.1.0.tgz",
@@ -12007,6 +12039,146 @@
         "obliterator": "^2.0.1"
       }
     },
+    "node_modules/mocha": {
+      "version": "5.2.0",
+      "resolved": "https://registry.npmjs.org/mocha/-/mocha-5.2.0.tgz",
+      "integrity": "sha512-2IUgKDhc3J7Uug+FxMXuqIyYzH7gJjXECKe/w43IGgQHTSj3InJi+yAA7T24L9bQMRKiUEHxEX37G5JpVUGLcQ==",
+      "dependencies": {
+        "browser-stdout": "1.3.1",
+        "commander": "2.15.1",
+        "debug": "3.1.0",
+        "diff": "3.5.0",
+        "escape-string-regexp": "1.0.5",
+        "glob": "7.1.2",
+        "growl": "1.10.5",
+        "he": "1.1.1",
+        "minimatch": "3.0.4",
+        "mkdirp": "0.5.1",
+        "supports-color": "5.4.0"
+      },
+      "bin": {
+        "_mocha": "bin/_mocha",
+        "mocha": "bin/mocha"
+      },
+      "engines": {
+        "node": ">= 4.0.0"
+      }
+    },
+    "node_modules/mocha/node_modules/brace-expansion": {
+      "version": "1.1.11",
+      "resolved": "https://registry.npmjs.org/brace-expansion/-/brace-expansion-1.1.11.tgz",
+      "integrity": "sha512-iCuPHDFgrHX7H2vEI/5xpz07zSHB00TpugqhmYtVmMO6518mCuRMoOYFldEBl0g187ufozdaHgWKcYFb61qGiA==",
+      "dependencies": {
+        "balanced-match": "^1.0.0",
+        "concat-map": "0.0.1"
+      }
+    },
+    "node_modules/mocha/node_modules/commander": {
+      "version": "2.15.1",
+      "resolved": "https://registry.npmjs.org/commander/-/commander-2.15.1.tgz",
+      "integrity": "sha512-VlfT9F3V0v+jr4yxPc5gg9s62/fIVWsd2Bk2iD435um1NlGMYdVCq+MjcXnhYq2icNOizHr1kK+5TI6H0Hy0ag=="
+    },
+    "node_modules/mocha/node_modules/debug": {
+      "version": "3.1.0",
+      "resolved": "https://registry.npmjs.org/debug/-/debug-3.1.0.tgz",
+      "integrity": "sha512-OX8XqP7/1a9cqkxYw2yXss15f26NKWBpDXQd0/uK/KPqdQhxbPa994hnzjcE2VqQpDslf55723cKPUOGSmMY3g==",
+      "dependencies": {
+        "ms": "2.0.0"
+      }
+    },
+    "node_modules/mocha/node_modules/diff": {
+      "version": "3.5.0",
+      "resolved": "https://registry.npmjs.org/diff/-/diff-3.5.0.tgz",
+      "integrity": "sha512-A46qtFgd+g7pDZinpnwiRJtxbC1hpgf0uzP3iG89scHk0AUC7A1TGxf5OiiOUv/JMZR8GOt8hL900hV0bOy5xA==",
+      "engines": {
+        "node": ">=0.3.1"
+      }
+    },
+    "node_modules/mocha/node_modules/escape-string-regexp": {
+      "version": "1.0.5",
+      "resolved": "https://registry.npmjs.org/escape-string-regexp/-/escape-string-regexp-1.0.5.tgz",
+      "integrity": "sha512-vbRorB5FUQWvla16U8R/qgaFIya2qGzwDrNmCZuYKrbdSUMG6I1ZCGQRefkRVhuOkIGVne7BQ35DSfo1qvJqFg==",
+      "engines": {
+        "node": ">=0.8.0"
+      }
+    },
+    "node_modules/mocha/node_modules/glob": {
+      "version": "7.1.2",
+      "resolved": "https://registry.npmjs.org/glob/-/glob-7.1.2.tgz",
+      "integrity": "sha512-MJTUg1kjuLeQCJ+ccE4Vpa6kKVXkPYJ2mOCQyUuKLcLQsdrMCpBPUi8qVE6+YuaJkozeA9NusTAw3hLr8Xe5EQ==",
+      "deprecated": "Glob versions prior to v9 are no longer supported",
+      "dependencies": {
+        "fs.realpath": "^1.0.0",
+        "inflight": "^1.0.4",
+        "inherits": "2",
+        "minimatch": "^3.0.4",
+        "once": "^1.3.0",
+        "path-is-absolute": "^1.0.0"
+      },
+      "engines": {
+        "node": "*"
+      }
+    },
+    "node_modules/mocha/node_modules/has-flag": {
+      "version": "3.0.0",
+      "resolved": "https://registry.npmjs.org/has-flag/-/has-flag-3.0.0.tgz",
+      "integrity": "sha512-sKJf1+ceQBr4SMkvQnBDNDtf4TXpVhVGateu0t918bl30FnbE2m4vNLX+VWe/dpjlb+HugGYzW7uQXH98HPEYw==",
+      "engines": {
+        "node": ">=4"
+      }
+    },
+    "node_modules/mocha/node_modules/he": {
+      "version": "1.1.1",
+      "resolved": "https://registry.npmjs.org/he/-/he-1.1.1.tgz",
+      "integrity": "sha512-z/GDPjlRMNOa2XJiB4em8wJpuuBfrFOlYKTZxtpkdr1uPdibHI8rYA3MY0KDObpVyaes0e/aunid/t88ZI2EKA==",
+      "bin": {
+        "he": "bin/he"
+      }
+    },
+    "node_modules/mocha/node_modules/minimatch": {
+      "version": "3.0.4",
+      "resolved": "https://registry.npmjs.org/minimatch/-/minimatch-3.0.4.tgz",
+      "integrity": "sha512-yJHVQEhyqPLUTgt9B83PXu6W3rx4MvvHvSUvToogpwoGDOUQ+yDrR0HRot+yOCdCO7u4hX3pWft6kWBBcqh0UA==",
+      "dependencies": {
+        "brace-expansion": "^1.1.7"
+      },
+      "engines": {
+        "node": "*"
+      }
+    },
+    "node_modules/mocha/node_modules/minimist": {
+      "version": "0.0.8",
+      "resolved": "https://registry.npmjs.org/minimist/-/minimist-0.0.8.tgz",
+      "integrity": "sha512-miQKw5Hv4NS1Psg2517mV4e4dYNaO3++hjAvLOAzKqZ61rH8NS1SK+vbfBWZ5PY/Me/bEWhUwqMghEW5Fb9T7Q=="
+    },
+    "node_modules/mocha/node_modules/mkdirp": {
+      "version": "0.5.1",
+      "resolved": "https://registry.npmjs.org/mkdirp/-/mkdirp-0.5.1.tgz",
+      "integrity": "sha512-SknJC52obPfGQPnjIkXbmA6+5H15E+fR+E4iR2oQ3zzCLbd7/ONua69R/Gw7AgkTLsRG+r5fzksYwWe1AgTyWA==",
+      "deprecated": "Legacy versions of mkdirp are no longer supported. Please update to mkdirp 1.x. (Note that the API surface has changed to use Promises in 1.x.)",
+      "dependencies": {
+        "minimist": "0.0.8"
+      },
+      "bin": {
+        "mkdirp": "bin/cmd.js"
+      }
+    },
+    "node_modules/mocha/node_modules/ms": {
+      "version": "2.0.0",
+      "resolved": "https://registry.npmjs.org/ms/-/ms-2.0.0.tgz",
+      "integrity": "sha512-Tpp60P6IUJDTuOq/5Z8cdskzJujfwqfOTkrwIwj7IRISpnkJnT6SyJ4PCPnGMoFjC9ddhal5KVIYtAt97ix05A=="
+    },
+    "node_modules/mocha/node_modules/supports-color": {
+      "version": "5.4.0",
+      "resolved": "https://registry.npmjs.org/supports-color/-/supports-color-5.4.0.tgz",
+      "integrity": "sha512-zjaXglF5nnWpsq470jSv6P9DwPvgLkuapYmfDm3JWOm0vkNTVF2tI4UrN2r6jH1qM/uc/WtxYY1hYoA2dOKj5w==",
+      "dependencies": {
+        "has-flag": "^3.0.0"
+      },
+      "engines": {
+        "node": ">=4"
+      }
+    },
     "node_modules/ms": {
       "version": "2.1.3",
       "resolved": "https://registry.npmjs.org/ms/-/ms-2.1.3.tgz",
@@ -14495,7 +14667,6 @@
       "version": "0.5.13",
       "resolved": "https://registry.npmjs.org/source-map-support/-/source-map-support-0.5.13.tgz",
       "integrity": "sha512-SHSKFHadjVA5oR4PPqhtAVdcBWwRYVd6g6cAXnIbRiIwc2EhPrTuKUBdSLvlEKyIP3GCf89fltvcZiP9MMFA1w==",
-      "dev": true,
       "dependencies": {
         "buffer-from": "^1.0.0",
         "source-map": "^0.6.0"
@@ -15733,6 +15904,140 @@
       "resolved": "https://registry.npmjs.org/core-util-is/-/core-util-is-1.0.2.tgz",
       "integrity": "sha512-3lqz5YjWTYnW6dlDa5TLaTCcShfar1e40rmcJVwCBJC6mWlFuj0eCHIElmG1g5kyuJ/GD+8Wn4FFCcz4gJPfaQ=="
     },
+    "node_modules/vscode": {
+      "version": "1.1.37",
+      "resolved": "https://registry.npmjs.org/vscode/-/vscode-1.1.37.tgz",
+      "integrity": "sha512-vJNj6IlN7IJPdMavlQa1KoFB3Ihn06q1AiN3ZFI/HfzPNzbKZWPPuiU+XkpNOfGU5k15m4r80nxNPlM7wcc0wg==",
+      "deprecated": "This package is deprecated in favor of @types/vscode and vscode-test. For more information please read: https://code.visualstudio.com/updates/v1_36#_splitting-vscode-package-into-typesvscode-and-vscodetest",
+      "dependencies": {
+        "glob": "^7.1.2",
+        "http-proxy-agent": "^4.0.1",
+        "https-proxy-agent": "^5.0.0",
+        "mocha": "^5.2.0",
+        "semver": "^5.4.1",
+        "source-map-support": "^0.5.0",
+        "vscode-test": "^0.4.1"
+      },
+      "bin": {
+        "vscode-install": "bin/install"
+      },
+      "engines": {
+        "node": ">=8.9.3"
+      }
+    },
+    "node_modules/vscode-test": {
+      "version": "0.4.3",
+      "resolved": "https://registry.npmjs.org/vscode-test/-/vscode-test-0.4.3.tgz",
+      "integrity": "sha512-EkMGqBSefZH2MgW65nY05rdRSko15uvzq4VAPM5jVmwYuFQKE7eikKXNJDRxL+OITXHB6pI+a3XqqD32Y3KC5w==",
+      "deprecated": "This package has been renamed to @vscode/test-electron, please update to the new name",
+      "dependencies": {
+        "http-proxy-agent": "^2.1.0",
+        "https-proxy-agent": "^2.2.1"
+      },
+      "engines": {
+        "node": ">=8.9.3"
+      }
+    },
+    "node_modules/vscode-test/node_modules/agent-base": {
+      "version": "4.3.0",
+      "resolved": "https://registry.npmjs.org/agent-base/-/agent-base-4.3.0.tgz",
+      "integrity": "sha512-salcGninV0nPrwpGNn4VTXBb1SOuXQBiqbrNXoeizJsHrsL6ERFM2Ne3JUSBWRE6aeNJI2ROP/WEEIDUiDe3cg==",
+      "dependencies": {
+        "es6-promisify": "^5.0.0"
+      },
+      "engines": {
+        "node": ">= 4.0.0"
+      }
+    },
+    "node_modules/vscode-test/node_modules/debug": {
+      "version": "3.1.0",
+      "resolved": "https://registry.npmjs.org/debug/-/debug-3.1.0.tgz",
+      "integrity": "sha512-OX8XqP7/1a9cqkxYw2yXss15f26NKWBpDXQd0/uK/KPqdQhxbPa994hnzjcE2VqQpDslf55723cKPUOGSmMY3g==",
+      "dependencies": {
+        "ms": "2.0.0"
+      }
+    },
+    "node_modules/vscode-test/node_modules/http-proxy-agent": {
+      "version": "2.1.0",
+      "resolved": "https://registry.npmjs.org/http-proxy-agent/-/http-proxy-agent-2.1.0.tgz",
+      "integrity": "sha512-qwHbBLV7WviBl0rQsOzH6o5lwyOIvwp/BdFnvVxXORldu5TmjFfjzBcWUWS5kWAZhmv+JtiDhSuQCp4sBfbIgg==",
+      "dependencies": {
+        "agent-base": "4",
+        "debug": "3.1.0"
+      },
+      "engines": {
+        "node": ">= 4.5.0"
+      }
+    },
+    "node_modules/vscode-test/node_modules/https-proxy-agent": {
+      "version": "2.2.4",
+      "resolved": "https://registry.npmjs.org/https-proxy-agent/-/https-proxy-agent-2.2.4.tgz",
+      "integrity": "sha512-OmvfoQ53WLjtA9HeYP9RNrWMJzzAz1JGaSFr1nijg0PVR1JaD/xbJq1mdEIIlxGpXp9eSe/O2LgU9DJmTPd0Eg==",
+      "dependencies": {
+        "agent-base": "^4.3.0",
+        "debug": "^3.1.0"
+      },
+      "engines": {
+        "node": ">= 4.5.0"
+      }
+    },
+    "node_modules/vscode-test/node_modules/ms": {
+      "version": "2.0.0",
+      "resolved": "https://registry.npmjs.org/ms/-/ms-2.0.0.tgz",
+      "integrity": "sha512-Tpp60P6IUJDTuOq/5Z8cdskzJujfwqfOTkrwIwj7IRISpnkJnT6SyJ4PCPnGMoFjC9ddhal5KVIYtAt97ix05A=="
+    },
+    "node_modules/vscode/node_modules/@tootallnate/once": {
+      "version": "1.1.2",
+      "resolved": "https://registry.npmjs.org/@tootallnate/once/-/once-1.1.2.tgz",
+      "integrity": "sha512-RbzJvlNzmRq5c3O09UipeuXno4tA1FE6ikOjxZK0tuxVv3412l64l5t1W5pj4+rJq9vpkm/kwiR07aZXnsKPxw==",
+      "engines": {
+        "node": ">= 6"
+      }
+    },
+    "node_modules/vscode/node_modules/agent-base": {
+      "version": "6.0.2",
+      "resolved": "https://registry.npmjs.org/agent-base/-/agent-base-6.0.2.tgz",
+      "integrity": "sha512-RZNwNclF7+MS/8bDg70amg32dyeZGZxiDuQmZxKLAlQjr3jGyLx+4Kkk58UO7D2QdgFIQCovuSuZESne6RG6XQ==",
+      "dependencies": {
+        "debug": "4"
+      },
+      "engines": {
+        "node": ">= 6.0.0"
+      }
+    },
+    "node_modules/vscode/node_modules/http-proxy-agent": {
+      "version": "4.0.1",
+      "resolved": "https://registry.npmjs.org/http-proxy-agent/-/http-proxy-agent-4.0.1.tgz",
+      "integrity": "sha512-k0zdNgqWTGA6aeIRVpvfVob4fL52dTfaehylg0Y4UvSySvOq/Y+BOyPrgpUrA7HylqvU8vIZGsRuXmspskV0Tg==",
+      "dependencies": {
+        "@tootallnate/once": "1",
+        "agent-base": "6",
+        "debug": "4"
+      },
+      "engines": {
+        "node": ">= 6"
+      }
+    },
+    "node_modules/vscode/node_modules/https-proxy-agent": {
+      "version": "5.0.1",
+      "resolved": "https://registry.npmjs.org/https-proxy-agent/-/https-proxy-agent-5.0.1.tgz",
+      "integrity": "sha512-dFcAjpTQFgoLMzC2VwU+C/CbS7uRL0lWmxDITmqm7C+7F0Odmj6s9l6alZc6AELXhrnggM2CeWSXHGOdX2YtwA==",
+      "dependencies": {
+        "agent-base": "6",
+        "debug": "4"
+      },
+      "engines": {
+        "node": ">= 6"
+      }
+    },
+    "node_modules/vscode/node_modules/semver": {
+      "version": "5.7.2",
+      "resolved": "https://registry.npmjs.org/semver/-/semver-5.7.2.tgz",
+      "integrity": "sha512-cBznnQ9KjJqU67B52RMC65CMarK2600WFnbkcaiwWq3xy/5haFJlshgnpjovMVJ+Hff49d8GEn0b87C5pDQ10g==",
+      "bin": {
+        "semver": "bin/semver"
+      }
+    },
     "node_modules/w3c-xmlserializer": {
       "version": "5.0.0",
       "resolved": "https://registry.npmjs.org/w3c-xmlserializer/-/w3c-xmlserializer-5.0.0.tgz",
diff --git a/continue-0.8.66-vscode/core/package.json b/continue-0.8.66-vscode/core/package.json
index eb80536..00c8502 100644
--- a/continue-0.8.66-vscode/core/package.json
+++ b/continue-0.8.66-vscode/core/package.json
@@ -66,6 +66,7 @@
     "fastest-levenshtein": "^1.0.16",
     "follow-redirects": "^1.15.5",
     "google-auth-library": "^9.14.2",
+    "gpt-tokenizer": "^2.8.1",
     "handlebars": "^4.7.8",
     "http-proxy-agent": "^7.0.1",
     "https-proxy-agent": "^7.0.3",
@@ -99,6 +100,7 @@
     "tree-sitter-wasms": "^0.1.11",
     "uuid": "^9.0.1",
     "vectordb": "^0.4.20",
+    "vscode": "^1.1.37",
     "web-tree-sitter": "^0.21.0",
     "win-ca": "^3.5.1",
     "wink-nlp-utils": "^2.1.0",
diff --git a/continue-0.8.66-vscode/core/util/parameters.ts b/continue-0.8.66-vscode/core/util/parameters.ts
index a7a11b5..682756b 100644
--- a/continue-0.8.66-vscode/core/util/parameters.ts
+++ b/continue-0.8.66-vscode/core/util/parameters.ts
@@ -7,7 +7,7 @@ export const DEFAULT_AUTOCOMPLETE_OPTS: TabAutocompleteOptions = {
   prefixPercentage: 0.3,
   maxSuffixPercentage: 0.2,
   debounceDelay: 350,
-  multilineCompletions: "auto",
+  multilineCompletions: "never",
   // @deprecated TO BE REMOVED
   slidingWindowPrefixPercentage: 0.75,
   // @deprecated TO BE REMOVED
diff --git a/continue-0.8.66-vscode/extensions/vscode/package-lock.json b/continue-0.8.66-vscode/extensions/vscode/package-lock.json
index ba48c08..6eca8ab 100644
--- a/continue-0.8.66-vscode/extensions/vscode/package-lock.json
+++ b/continue-0.8.66-vscode/extensions/vscode/package-lock.json
@@ -125,6 +125,7 @@
         "fastest-levenshtein": "^1.0.16",
         "follow-redirects": "^1.15.5",
         "google-auth-library": "^9.14.2",
+        "gpt-tokenizer": "^2.8.1",
         "handlebars": "^4.7.8",
         "http-proxy-agent": "^7.0.1",
         "https-proxy-agent": "^7.0.3",
@@ -158,6 +159,7 @@
         "tree-sitter-wasms": "^0.1.11",
         "uuid": "^9.0.1",
         "vectordb": "^0.4.20",
+        "vscode": "^1.1.37",
         "web-tree-sitter": "^0.21.0",
         "win-ca": "^3.5.1",
         "wink-nlp-utils": "^2.1.0",
diff --git a/continue-0.8.66-vscode/extensions/vscode/package.json b/continue-0.8.66-vscode/extensions/vscode/package.json
index 65bfdd7..95ea48a 100644
--- a/continue-0.8.66-vscode/extensions/vscode/package.json
+++ b/continue-0.8.66-vscode/extensions/vscode/package.json
@@ -718,4 +718,4 @@
     "ws": "^8.13.0",
     "yarn": "^1.22.21"
   }
-}
+}
\ No newline at end of file
diff --git a/continue-0.8.66-vscode/extensions/vscode/src/VsCodeIde.ts b/continue-0.8.66-vscode/extensions/vscode/src/VsCodeIde.ts
index 9e23735..70d0a41 100644
--- a/continue-0.8.66-vscode/extensions/vscode/src/VsCodeIde.ts
+++ b/continue-0.8.66-vscode/extensions/vscode/src/VsCodeIde.ts
@@ -13,7 +13,7 @@ import {
 } from "core/util/paths";
 import * as vscode from "vscode";
 
-import { executeGotoProvider } from "./autocomplete/lsp";
+import { executeGotoProvider} from "./autocomplete/lsp";
 import { DiffManager } from "./diff/horizontal";
 import { Repository } from "./otherExtensions/git";
 import { VsCodeIdeUtils } from "./util/ideUtils";
@@ -70,6 +70,17 @@ class VsCodeIde implements IDE {
     return result;
   }
 
+  async gotoReferences(location: Location): Promise<RangeInFile[]> {
+    const result = await executeGotoProvider({
+      uri: location.filepath,
+      line: location.position.line,
+      character: location.position.character,
+      name: "vscode.executeReferenceProvider",
+    });
+
+    return result;
+  }
+
   onDidChangeActiveTextEditor(callback: (filepath: string) => void): void {
     vscode.window.onDidChangeActiveTextEditor((editor) => {
       if (editor) {
diff --git a/continue-0.8.66-vscode/extensions/vscode/src/autocomplete/completionProvider.ts b/continue-0.8.66-vscode/extensions/vscode/src/autocomplete/completionProvider.ts
index 2a2f41a..ceda932 100644
--- a/continue-0.8.66-vscode/extensions/vscode/src/autocomplete/completionProvider.ts
+++ b/continue-0.8.66-vscode/extensions/vscode/src/autocomplete/completionProvider.ts
@@ -10,7 +10,6 @@ const Diff = require("diff");
 
 import { showFreeTrialLoginMessage } from "../util/messages";
 import { VsCodeWebviewProtocol } from "../webviewProtocol";
-
 import { getDefinitionsFromLsp } from "./lsp";
 import { RecentlyEditedTracker } from "./recentlyEdited";
 import {
diff --git a/continue-0.8.66-vscode/extensions/vscode/src/autocomplete/lsp.ts b/continue-0.8.66-vscode/extensions/vscode/src/autocomplete/lsp.ts
index 08b16ac..3d95a4d 100644
--- a/continue-0.8.66-vscode/extensions/vscode/src/autocomplete/lsp.ts
+++ b/continue-0.8.66-vscode/extensions/vscode/src/autocomplete/lsp.ts
@@ -1,16 +1,11 @@
 import { AutocompleteLanguageInfo } from "core/autocomplete/constants/AutocompleteLanguageInfo";
 import { getAst, getTreePathAtCursor } from "core/autocomplete/util/ast";
-import {
-  FUNCTION_BLOCK_NODE_TYPES,
-  FUNCTION_DECLARATION_NODE_TYPEs,
-} from "core/indexing/chunk/code";
 import { intersection } from "core/util/ranges";
 import * as vscode from "vscode";
 
-import type { IDE, Range, RangeInFile, RangeInFileWithContents } from "core";
+import type { IDE, Range, RangeInFile, RangeInFileWithContents, SymbolUsage } from "core";
 import type Parser from "web-tree-sitter";
 import {
-  AutocompleteSnippetDeprecated,
   GetLspDefinitionsFunction,
 } from "core/autocomplete/types";
 import {
@@ -208,63 +203,42 @@ export async function getDefinitionsForNode(
   node: Parser.SyntaxNode,
   ide: IDE,
   lang: AutocompleteLanguageInfo,
-): Promise<RangeInFileWithContents[]> {
-  const ranges: (RangeInFile | RangeInFileWithContents)[] = [];
+): Promise<SymbolUsage> {
   switch (node.type) {
-    case "call_expression": {
-      // function call -> function definition
-      const [funDef] = await executeGotoProvider({
+    case "call_expression":                 // function call typescript 
+    case "method_invocation":               // function call java
+    case "call":                            // function call, new object python
+    case "new_expression":                  // new object typescript
+    case "object_creation_expression":      // new object java
+    {
+      const symbol = node.text;
+      const [defSymbol] = await executeGotoProvider({
         uri,
         line: node.startPosition.row,
         character: node.startPosition.column,
         name: "vscode.executeDefinitionProvider",
       });
-      if (!funDef) {
-        return [];
-      }
-
-      // Don't display a function of more than 15 lines
-      // We can of course do something smarter here eventually
-      let funcText = await ide.readRangeInFile(funDef.filepath, funDef.range);
-      if (funcText.split("\n").length > 15) {
-        let truncated = false;
-        const funRootAst = await getAst(funDef.filepath, funcText);
-        if (funRootAst) {
-          const [funNode] = findChildren(
-            funRootAst?.rootNode,
-            (node) => FUNCTION_DECLARATION_NODE_TYPEs.includes(node.type),
-            1,
-          );
-          if (funNode) {
-            const [statementBlockNode] = findChildren(
-              funNode,
-              (node) => FUNCTION_BLOCK_NODE_TYPES.includes(node.type),
-              1,
-            );
-            if (statementBlockNode) {
-              funcText = funRootAst.rootNode.text
-                .slice(0, statementBlockNode.startIndex)
-                .trim();
-              truncated = true;
-            }
-          }
-        }
-        if (!truncated) {
-          funcText = funcText.split("\n")[0];
-        }
+      if (!defSymbol) {
+        return {symbol: symbol, usages: []};
       }
 
-      ranges.push(funDef);
+      // defSymbol: filepath, range
+      const symbolUsages = await executeGotoProvider({
+        uri: defSymbol.filepath,
+        line: defSymbol.range.end.line,
+        character: defSymbol.range.end.character,
+        name: "vscode.executeReferenceProvider"
+      });
 
-      const typeDefs = await crawlTypes(
-        {
-          ...funDef,
-          contents: funcText,
-        },
-        ide,
-      );
-      ranges.push(...typeDefs);
-      break;
+      // Similar usages should not be the symbol definition itself, or the symbol usage itself
+      const filteredSymbolUsages = symbolUsages.filter((symbolUsage) => {
+        return ((symbolUsage.filepath !== defSymbol.filepath 
+                  || symbolUsage.range.start.line !== defSymbol.range.start.line)
+                && (symbolUsage.filepath !== uri
+                  || symbolUsage.range.start.line !== node.startPosition.row)
+                );
+      });
+      return {symbol: symbol, usages: filteredSymbolUsages};
     }
     case "variable_declarator":
       // variable assignment -> variable definition/type
@@ -272,67 +246,11 @@ export async function getDefinitionsForNode(
       break;
     case "impl_item":
       // impl of trait -> trait definition
-      break;
-    case "new_expression":
-      // In 'new MyClass(...)', "MyClass" is the classNameNode
-      const classNameNode = node.children.find(
-        (child) => child.type === "identifier",
-      );
-      const [classDef] = await executeGotoProvider({
-        uri,
-        line: (classNameNode ?? node).endPosition.row,
-        character: (classNameNode ?? node).endPosition.column,
-        name: "vscode.executeDefinitionProvider",
-      });
-      if (!classDef) {
-        break;
-      }
-      const contents = await ide.readRangeInFile(
-        classDef.filepath,
-        classDef.range,
-      );
-
-      ranges.push({
-        ...classDef,
-        contents: `${
-          classNameNode?.text
-            ? `${lang.singleLineComment} ${classNameNode.text}:\n`
-            : ""
-        }${contents.trim()}`,
-      });
-
-      const definitions = await crawlTypes({ ...classDef, contents }, ide);
-      ranges.push(...definitions.filter(Boolean));
-
       break;
     case "":
-      // function definition -> implementations?
       break;
   }
-  return await Promise.all(
-    ranges.map(async (rif) => {
-      // Convert the VS Code Range type to ours
-      const range: Range = {
-        start: {
-          line: rif.range.start.line,
-          character: rif.range.start.character,
-        },
-        end: {
-          line: rif.range.end.line,
-          character: rif.range.end.character,
-        },
-      };
-      rif.range = range;
-
-      if (!isRifWithContents(rif)) {
-        return {
-          ...rif,
-          contents: await ide.readRangeInFile(rif.filepath, rif.range),
-        };
-      }
-      return rif;
-    }),
-  );
+  return {};
 }
 
 /**
@@ -347,7 +265,7 @@ export const getDefinitionsFromLsp: GetLspDefinitionsFunction = async (
   cursorIndex: number,
   ide: IDE,
   lang: AutocompleteLanguageInfo,
-): Promise<AutocompleteCodeSnippet[]> => {
+): Promise<SymbolUsage[]> => {
   try {
     const ast = await getAst(filepath, contents);
     if (!ast) {
@@ -359,7 +277,7 @@ export const getDefinitionsFromLsp: GetLspDefinitionsFunction = async (
       return [];
     }
 
-    const results: RangeInFileWithContents[] = [];
+    const results: SymbolUsage[] = [];
     for (const node of treePath.reverse()) {
       const definitions = await getDefinitionsForNode(
         filepath,
@@ -367,14 +285,10 @@ export const getDefinitionsFromLsp: GetLspDefinitionsFunction = async (
         ide,
         lang,
       );
-      results.push(...definitions);
+      results.push(definitions);
     }
-
-    return results.map((result) => ({
-      filepath: result.filepath,
-      content: result.contents,
-      type: AutocompleteSnippetType.Code,
-    }));
+    return results;
+    
   } catch (e) {
     console.warn("Error getting definitions from LSP: ", e);
     return [];
diff --git a/continue-0.8.66-vscode/gui/package-lock.json b/continue-0.8.66-vscode/gui/package-lock.json
index 9ff6fc7..ad270b6 100644
--- a/continue-0.8.66-vscode/gui/package-lock.json
+++ b/continue-0.8.66-vscode/gui/package-lock.json
@@ -128,6 +128,7 @@
         "fastest-levenshtein": "^1.0.16",
         "follow-redirects": "^1.15.5",
         "google-auth-library": "^9.14.2",
+        "gpt-tokenizer": "^2.8.1",
         "handlebars": "^4.7.8",
         "http-proxy-agent": "^7.0.1",
         "https-proxy-agent": "^7.0.3",
@@ -161,6 +162,7 @@
         "tree-sitter-wasms": "^0.1.11",
         "uuid": "^9.0.1",
         "vectordb": "^0.4.20",
+        "vscode": "^1.1.37",
         "web-tree-sitter": "^0.21.0",
         "win-ca": "^3.5.1",
         "wink-nlp-utils": "^2.1.0",
diff --git a/continue-0.8.66-vscode/manual-testing-sandbox/nested-folder/helloNested.py b/continue-0.8.66-vscode/manual-testing-sandbox/nested-folder/helloNested.py
index b43d5d8..52d90d7 100644
--- a/continue-0.8.66-vscode/manual-testing-sandbox/nested-folder/helloNested.py
+++ b/continue-0.8.66-vscode/manual-testing-sandbox/nested-folder/helloNested.py
@@ -8,8 +8,14 @@ def main(a: Vector):
 
 
 class MyClass:
+    def __init__(self):
+        pass
+
     def test(a: Vector) -> Vector:
         return a
 
+    def sort_func(self, a: Vector) -> Vector:
+        return sorted(a)
+        
 
 raise Exception("This is an error")
diff --git a/continue-0.8.66-vscode/manual-testing-sandbox/test.js b/continue-0.8.66-vscode/manual-testing-sandbox/test.js
index c6cd3ad..d59c9e2 100644
--- a/continue-0.8.66-vscode/manual-testing-sandbox/test.js
+++ b/continue-0.8.66-vscode/manual-testing-sandbox/test.js
@@ -18,11 +18,6 @@ class Calculator {
     return this;
   }
 
-  hello() {
-    console.log("Hello");
-
-  }
-
   divide(number) {
     if (number === 0) {
       throw new Error("Cannot divide by zero");
@@ -39,4 +34,8 @@ class Calculator {
     this.result = 0;
     return this;
   }
+
+  hallo() {
+
+  }
 }
